{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Welcome to Pengfei doc center","text":"<p>This website is build by using <code>mkdocs</code>. For more information about <code>mkdocs</code>, please visit mkdocs.org.</p>"},{"location":"#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"adminsys/core/Systemd%28serviced%29/","title":"Systemd in Linux","text":"<p>In Debian (and other Linux distributions), we use systemd to manage services which should run as <code>background process</code> We use a <code>unit file</code> to define how the service should be start/stop/restart, and how to monitor the service status.  After editing and enabling the <code>unit</code> file, these services can be controlled by using the systemctl command.</p> <p>Systemd is developed to replace the old SysV init. </p>"},{"location":"adminsys/core/Systemd%28serviced%29/#what-is-a-service-in-linux","title":"What is a service in linux","text":"<p>A service is usually a <code>long running daemon (background program) process</code> like nginx, postgresql, or ssh.</p> <p>Each service has a corresponding <code>unit file</code> that tells <code>systemd</code> how to <code>start, stop, restart, or monitor it</code>.</p> <p>The Unit files live in:</p> <ul> <li><code>/lib/systemd/system/</code>: (packaged services)</li> <li><code>/etc/systemd/system/</code>: (local overrides/custom services)</li> </ul>"},{"location":"adminsys/core/Systemd%28serviced%29/#useful-systemd-commands","title":"Useful systemd commands","text":"<pre><code># list all active services\nsystemctl list-units --type=service\n\n# list all service(active and inactive)\nsystemctl list-units --type=service --all\n\n# start a service immediately\nsystemctl start ssh\n\n# stop immediately\nsystemctl stop ssh\n\n# restart \nsystemctl restart ssh\n\n# check service status\nsystemctl status ssh\n\n# Enable/disable a service at boot\nsystemctl enable/disable ssh\n\n# check if a service is enabled at boot\nsystemctl is-enabled ssh\n</code></pre>"},{"location":"adminsys/core/Systemd%28serviced%29/#why-we-use-systemd","title":"Why we use systemd","text":"<p>Compared to a bash script, the systemd has the below advantages: - Automatic management: Starts at boot, restarts if it fails. - Dependency awareness: Can wait for network/storage service before starting. - Logging integration: Logs go to journalctl -u postgresql. - Resource control: Built-in cgroups support (limit memory, CPU, I/O). - Monitoring tools: systemctl status postgresql shows PID, uptime, logs. - Unified interface: Consistent commands across all services.</p> <p>It has few disadvantages: - Less transparent: Logic hidden inside systemd unit file, not just a simple script. - Steeper learning curve: You need to learn how to write <code>unit files</code> and systemd internals. - Systemd dependency: If OS does not have it, the unit file won\u2019t work. - Overhead for simple cases \u2013 For a single local process, systemd may feel like \u201coverkill.\u201d</p>"},{"location":"adminsys/core/Systemd%28serviced%29/#systemd-unit-file","title":"Systemd Unit file","text":"<p>There is a more detailed doc on unit file here</p> <p>A systemd unit file is structured into <code>sections</code>. The three most common are [Unit], [Service], and [Install].  Each has a distinct purpose: - [Unit]: metadata + dependencies. When and under what conditions should this service start? - [Service]: execution details. How do we start, stop, restart, and monitor this process? - [Install]: startup integration. Should this run automatically at boot, and in which boot mode?</p>"},{"location":"adminsys/core/Systemd%28serviced%29/#unit-section","title":"[Unit] section","text":"<p>The unit section defines <code>metadata and dependencies</code> for the service. Below are the most common attributes of this section: - Description: Human-readable description of the service. - Documentation: Optional links to docs. - After: Order dependency (start this service after something else, e.g. network.target). - Requires: Hard dependency (if required service fails, this one stops too). - Wants: Soft dependency (preferred, but doesn\u2019t stop if missing).</p> <p>For example, the below conf means: - The <code>OpenMetadata Service</code> starts after the network stack is ready. - It needs <code>PostgreSQL and elasticsearch</code>; if PostgreSQL or elasticsearch fails, OpenMetadata stops too.</p> <pre><code>[Unit]\nDescription=OpenMetadata Service\nAfter=network.target\nRequires=postgresql.service, elasticsearch.service\n</code></pre>"},{"location":"adminsys/core/Systemd%28serviced%29/#service-section","title":"[Service] section","text":"<p>The service section defines how the actual service runs.</p> <ul> <li>ExecStart: The actual command to start the service.</li> <li>ExecStop: Command to stop it.</li> <li>ExecReload: Command to reload config without restart.</li> <li>WorkingDirectory: Where the service runs.</li> <li>User=/Group: Run as specific user/group (not root).</li> <li>Restart: Restart policy (no, on-failure, always).</li> <li>RestartSec: Delay before restart.</li> <li>Environment: Set environment variables.</li> <li>StandardOutput=/StandardError: Where logs go (journal, file, etc.).</li> <li>Type: How the service runs:          - simple: Default, process runs in foreground.          - forking: For daemons that fork themselves (e.g. old scripts).           - oneshot: For short-lived tasks (runs once, exits).</li> </ul> <pre><code>[Service]\nUser=openmeta\nGroup=openmeta\nWorkingDirectory=/opt/openmetadata\nExecStart=/opt/openmetadata/openmetadata.sh start\nExecStop=/opt/openmetadata/openmetadata.sh stop\nRestart=on-failure\nRestartSec=5\nStandardOutput=journal\nStandardError=journal\n</code></pre> <p>The user openmeta must exist, otherwise the service will not start. </p>"},{"location":"adminsys/core/Systemd%28serviced%29/#run-service-with-dedicated-user-and-group","title":"Run service with dedicated user and group","text":"<p>If we don't specify <code>User/group</code>, systemd will run the service as root with the user default group(e.g. root).  This can cause serious security problems. The best practice is that we always create a dedicated system user account and group.</p> <pre><code># create a system group\nsudo groupadd --system openmeta\n# create a system user with no login shell, no home dir.\nsudo useradd --system --no-create-home --shell /usr/sbin/nologin --gid openmeta openmeta\n</code></pre>"},{"location":"adminsys/core/Systemd%28serviced%29/#install-section","title":"[Install] section","text":"<p>The install section defines how the service integrates into system startup. - WantedBy: Which target this service should be part of when enabled.     - multi-user.target: Typical for servers (like runlevel 3 in SysV).     - graphical.target: For desktop services (like runlevel 5).</p> <ul> <li>RequiredBy: Like WantedBy, but hard dependency.</li> </ul> <p>For example, the below config means: When you run systemctl enable openmetadata.service, systemd creates symlinks  so the service starts automatically in multi-user mode (normal boot without GUI).</p> <pre><code>[Install]\nWantedBy=multi-user.target\n</code></pre>"},{"location":"adminsys/core/Systemd%28serviced%29/#full-example","title":"Full example","text":"<p>The below unit file shows how to run openmetadata as systemd service</p> <pre><code>[Unit]\nDescription=OpenMetadata Service\nAfter=network.target\nWants=network.target\nRequires=postgresql.service elasticsearch.service\n\n[Service]\nType=forking\n# Run as non-root user\nUser=openmeta\nGroup=openmeta\nWorkingDirectory=/opt/\n\n# load env var\nEnvironmentFile=-/opt/openmetadata/conf/openmetadata-env.sh\n\n# How to start and stop\nExecStart=/opt/openmetadata/openmetadata.sh start\nExecStop=/opt/openmetadata/openmetadata.sh stop\n\n# checking service health.\nExecReload=/opt/openmetadata/openmetadata.sh status\n# Optional: status and clean hooks\nExecStartPre=/opt/openmetadata/openmetadata.sh clean\n\n# Restart policy if the service crashes\nRestart=on-failure\nRestartSec=5\n\n# Logging: send stdout/stderr to systemd journal\nStandardOutput=journal\nStandardError=journal\n\n[Install]\nWantedBy=multi-user.target\n</code></pre> <p>We suppose the openmetadata app is installed under <code>/opt/openmetadata</code></p>"},{"location":"adminsys/db_management/mariadb/Installation/","title":"Maria DB installation","text":""},{"location":"adminsys/db_management/mariadb/Installation/#1-installation","title":"1. Installation","text":""},{"location":"adminsys/db_management/mariadb/Installation/#step-1","title":"Step 1:","text":"<p>Install software-properties-common if missing:</p> <pre><code>sudo apt update\nsudo apt install software-properties-common\n</code></pre>"},{"location":"adminsys/db_management/mariadb/Installation/#step-2","title":"Step 2:","text":"<p>Run the command below to add Repository Key to the system</p> <pre><code>Import MariaDB gpg key and repo\nsudo apt-key adv --recv-keys --keyserver hkp://keyserver.ubuntu.com:80 0xF1656F24C74CD1D8\n\n# Add the apt repository\n# Note the below apt-repository url is for ubuntu, for other distribution you may need to change the url\nsudo add-apt-repository \"deb [arch=amd64,arm64,ppc64el] http://mariadb.mirror.liquidtelecom.com/repo/10.4/ubuntu $(lsb_release -cs) main\"\n\nsudo apt update\nsudo apt -y install mariadb-server mariadb-client\n\n# You will be prompted to provide MariaDB root password, after the above command.\n# If you didn\u2019t receive password set prompt, then manually run the MySQL hardening script.\nsudo mysql_secure_installation \n\nNOTE: RUNNING ALL PARTS OF THIS SCRIPT IS RECOMMENDED FOR ALL MariaDB\n      SERVERS IN PRODUCTION USE!  PLEASE READ EACH STEP CAREFULLY!\n\nIn order to log into MariaDB to secure it, we'll need the current\npassword for the root user. If you've just installed MariaDB, and\nhaven't set the root password yet, you should just press enter here.\n\nEnter current password for root (enter for none): \nOK, successfully used password, moving on...\n\nSetting the root password or using the unix_socket ensures that nobody\ncan log into the MariaDB root user without the proper authorisation.\n\nYou already have your root account protected, so you can safely answer 'n'.\n\nSwitch to unix_socket authentication [Y/n] y\nEnabled successfully!\nReloading privilege tables..\n ... Success!\n\n\nYou already have your root account protected, so you can safely answer 'n'.\n\nChange the root password? [Y/n] y\nNew password: \nRe-enter new password: \nPassword updated successfully!\nReloading privilege tables..\n ... Success!\n\n\nBy default, a MariaDB installation has an anonymous user, allowing anyone\nto log into MariaDB without having to have a user account created for\nthem.  This is intended only for testing, and to make the installation\ngo a bit smoother.  You should remove them before moving into a\nproduction environment.\n\nRemove anonymous users? [Y/n] y\n ... Success!\n\nNormally, root should only be allowed to connect from 'localhost'.  This\nensures that someone cannot guess at the root password from the network.\n\nDisallow root login remotely? [Y/n] y\n ... Success!\n\nBy default, MariaDB comes with a database named 'test' that anyone can\naccess.  This is also intended only for testing, and should be removed\nbefore moving into a production environment.\n\nRemove test database and access to it? [Y/n] y\n - Dropping test database...\n ... Success!\n - Removing privileges on test database...\n ... Success!\n\nReloading the privilege tables will ensure that all changes made so far\nwill take effect immediately.\n\nReload privilege tables now? [Y/n] y\n ... Success!\n\nCleaning up...\n\nAll done!  If you've completed all of the above steps, your MariaDB\ninstallation should now be secure.\n\nThanks for using MariaDB!\n</code></pre> <p>If you are not able to set up root password, you can follow</p>"},{"location":"adminsys/db_management/mariadb/Installation/#step-3-test-the-mariadb-installation","title":"Step 3: Test the mariaDB installation","text":"<pre><code># check daemon status\nsudo systemctl status mysql\n\n# connect to the server via mysql client\nmysql -u root -p\n\n# check your installation version\nSELECT VERSION();\n\n# exit the sql terminal\nQUIT\n</code></pre>"},{"location":"adminsys/db_management/mariadb/Installation/#2-removepurge-old-installation","title":"2. Remove/Purge old installation","text":"<p>If you already have one installation of mysql or mariadb, and you need to install a new one. It's recommended to remove and purge all the dependencies of the old installation. Because you will have many conflicts which are not  expected.</p> <p>Just follow the below steps</p> <pre><code># 1. make sure that MySQL service is stopped.\nsudo systemctl stop mysql\n\n# 2. Remove MySQL related all packages completely.\nsudo apt-get purge mysql-server mysql-client mysql-common mysql-server-core-* mysql-client-core-*\n\n# 3. Remove MySQL configuration and data. If you have changed database location in your MySQL configuration, \n#    you need to replace /var/lib/mysql according to it.\nsudo rm -rf /etc/mysql /var/lib/mysql\n\n# 4. (Optional but recommended) Remove unnecessary packages.\nsudo apt autoremove\n\n# 5. (Optional) Remove apt cache.\nsudo apt autoclean\n</code></pre>"},{"location":"adminsys/db_management/mariadb/Installation/#3-recover-your-root-password","title":"3. Recover your root password","text":"<p>Do not do this if you have other options. <code>You must have access to the Linux server running MySQL or MariaDB with a sudo user.</code></p> <pre><code># Identifying the Database Version\nmysql --version\n\n# Stopping the Database Server\nsudo systemctl stop mysql/mariadb\n\n# Restarting the Database Server Without Permission Checking\nsudo mysqld_safe --skip-grant-tables --skip-networking &amp;\n# note this will run the mysqld in the background, if you want to check the status, you can use\njobs\n# when you have the job id, you can use \nfg %&lt;job-id&gt;\n\n\n# Now you can connect to the database as the root user, which should not ask for a password.\nmysql -u root\n\n# For MySQL 5.7.6 and newer as well as MariaDB 10.1.20 and newer, use the following command.\n# don't forget to change the new_password to a value which you want\nALTER USER 'root'@'localhost' IDENTIFIED BY 'new_password';\n\n# For MySQL 5.7.5 and older as well as MariaDB 10.1.20 and older, use:\nSET PASSWORD FOR 'root'@'localhost' = PASSWORD('new_password');\n\n# In either case, you should see confirmation that the command has been successfully executed.\nOutput\nQuery OK, 0 rows affected (0.00 sec)\n\n# kill the mysqld unsafe daemon\nsudo kill `cat /var/run/mysqld/mysqld.pid`\n# for MariaDB\nsudo kill `/var/run/mariadb/mariadb.pid`\n\n# Restart the Database Server Normally\nsudo systemctl start mysql/mariadb\n\n# connect to the server with the new password\nmysql -u root -p\n</code></pre>"},{"location":"adminsys/db_management/mariadb/Installation/#4-change-innodb_page_size","title":"4. Change innodb_page_size","text":"<p>When we encounter Row Size Too Large Errors with InnoDB error, we may need to increase the innodb_page_size</p> <p>To learn more details of this bug, you can visit this page https://mariadb.com/kb/en/troubleshooting-row-size-too-large-errors-with-innodb/</p> <pre><code># get a sql terminal\nmysql -u root -p\n\n# get the current database innodb_page_size\nshow variables like '%innodb_page_size%';\nexit;\n\n# stop the db daemon\nsudo systemctl stop mysql\n\n# backup the system database (e.g. innodb) data and log files\n# in debian os, the data ibdata1 and the log files (ib_logfile0 &amp; ib_logfile1) are located at /var/lib/mysql\ncd /var/lib/mysql/\nsudo mkdir /tmp/innodb_bkp\nsudo mv ibdata1 /tmp/innodb_bkp\nsudo sudo mv ib_logfile* /tmp/innodb_bkp\n\n# now change the innodb_page_size value\n# in debian, the mysql/mariadb conf file are located /etc/mysql/my.cnf\n# you can add the below line in the [mysqld]\n# suppose we want to put 8k, the default value for MariaDB-1:10.4.33 is 16k\n[mysqld]\ninnodb_page_size=8k\n\n# restart the mysql daemon\nsudo systemctl start mysql\n</code></pre> <p>after changing the innodb_page_size, the existing database may not work properly, so you may need to export/import   the existing database for safety.</p>"},{"location":"adminsys/db_management/mariadb/Management/","title":"Manage a mysql/mariadb database","text":""},{"location":"adminsys/db_management/mariadb/Management/#basic-commands","title":"Basic commands","text":"<pre><code># create a database\ncreate database &lt;db_name&gt;;\n\n# create a user with a password\nCREATE USER 'username'@'hostname' IDENTIFIED BY 'password';\n\n# Here\u2019s an example which allows user \u2018matthew\u2019 to connect from any host.\nCREATE USER 'matthew'@'%' IDENTIFIED BY 'supersecretpassword';\n\n# After creating the user, you will need to grant the necessary privileges to the user. \n# This is done using the GRANT statement, which has the following form:\nGRANT priv_type ON priv_level TO 'username'@'hostname';\n# priv_type is the type of privilege which you want to grant (such as SELECT, INSERT, UPDATE, etc.), \n# priv_level is the level at which the privilege should apply (such as a specific database or table), \n# and username and hostname with the values you used in the CREATE USER statement.\n\n# Here is an example of granting ALL permissions on all databases to our user, Matthew:\nGRANT ALL PRIVILEGES ON * . * TO 'matthew'@'%';\n\n# After granting the necessary privileges to the user, you can use the FLUSH PRIVILEGES statement to make the \n# changes take effect. This statement has the following form:\nFLUSH PRIVILEGES;\n</code></pre>"},{"location":"adminsys/db_management/mariadb/Management/#enable-remote-access","title":"Enable remote access","text":""},{"location":"adminsys/db_management/mariadb/Management/#step1-update-server-bind-address","title":"Step1: Update server bind address","text":"<p>By default, mysql/mariadb only listens to local host, and forbid all remote access. To enable it, you need to change the default config.</p> <pre><code># verify current stat\nnetstat -ant | grep 3306\n\n# you should see something like this\ntcp        0      0 127.0.0.1:3306          0.0.0.0:*               LISTEN      3731352/mysqld  \n\n# change the default config\nsudo vim /etc/mysql/my.cnf\n\n# find the line bind-address = 127.0.0.1 and change it to \nbind-address = 0.0.0.0\n\n# restart the service \nsudo systemctl restart mysql/mariadb\n\n# check the new bind ip\n$ netstat -ant | grep 3306\n\ntcp        0      0 0.0.0.0:3306            0.0.0.0:*               LISTEN\n</code></pre>"},{"location":"adminsys/db_management/mariadb/Management/#step2-update-user-authorization","title":"Step2: Update user authorization","text":"<p>By default, mysql set an acl for each user to a database with a list of authorize ip. If user try to connect to a server with an authorized ip address, the connexion will be denied.</p> <p>Below is an example to set proper acl to allow user to connect to a database with an authorized IP address.</p> <pre><code># First, log in to the MySQL/MariaDB server with the root privilege:\n\n$ mysql -u admin -p\n\n# create a new db\nMariaDB [(none)]&gt; CREATE DATABASE wpdb;\n\n# create a user \nMariaDB [(none)]&gt; CREATE USER  'wpuser'@'localhost' IDENTIFIED BY 'password';\n\n\n# you will need to grant permissions to the remote system with IP address 208.117.84.50 to connect to the database named wpdb as user wpuser. You can do it with the following command:\nMariaDB [(none)]&gt; GRANT ALL ON wpdb.* to 'wpuser'@'208.117.84.50' IDENTIFIED BY 'password' WITH GRANT OPTION;\n\n# Next, flush the privileges and exit from the MariaDB shell with the following command:\n\nMariaDB [(none)]&gt; FLUSH PRIVILEGES;\nMariaDB [(none)]&gt; EXIT;\n\n# If you want to grant remote access on all databases for wpuser, run the following command:\nMariaDB [(none)]&gt; GRANT ALL ON *.* to 'wpuser'@'208.117.84.50' IDENTIFIED BY 'password' WITH GRANT OPTION;\n\n# If you want to grant access to all remote IP addresses on wpdb as wpuser, use % instead of IP address (208.117.84.50) as shown below:\nMariaDB [(none)]&gt; GRANT ALL ON wpdb.* to 'wpuser'@'%' IDENTIFIED BY 'password' WITH GRANT OPTION;\n\n# If you want to grant access to all IP addresses in the subnet 208.117.84.0/24 on wpdb as user wpuser, run the following command:\nMariaDB [(none)]&gt; GRANT ALL ON wpdb.* to 'wpuser'@'208.117.84.%' IDENTIFIED BY 'password' WITH GRANT OPTION;\n</code></pre> <p>A brief explanation of each parameter is shown below:</p> <ul> <li>wpdb: It is the name of the MariaDB database that the user wants to connect to.</li> <li>wpuser: It is the name of the MariaDB database user.</li> <li>208.117.84.50: It is the IP address of the remote system from which the user wants to connect.</li> <li>password: It is the password of the database user.</li> </ul>"},{"location":"adminsys/db_management/mariadb/Management/#test-connection-from-remote-server","title":"Test connection from remote server","text":"<pre><code>$ sudo apt-get install mariadb-client -y\n\n# Once the installation is completed, connect to the MariaDB server by running the following command on the remote system:\nmysql -u &lt;uid&gt; -h &lt;db-ip&gt; -p\n</code></pre>"},{"location":"adminsys/os_setup/01.Lang_support/","title":"Debian server language support management","text":""},{"location":"adminsys/os_setup/01.Lang_support/#1-add-new-language-support","title":"1. Add new language support","text":"<pre><code># check installed language\nsudo locale -a\n\n# install a new language support\nsudo locale-gen en_US.UTF-8\n</code></pre>"},{"location":"adminsys/os_setup/01.Lang_support/#2-change-the-default-language-support","title":"2. Change the default language support","text":"<pre><code>sudo vim /etc/default/locale\n\n# add the below lines\nLANG=en_US.UTF-8\nLANGUAGE=\"en_US:en\"\nLC_ADDRESS=en_US.UTF-8\nLC_NAME=en_US.UTF-8\nLC_MONETARY=en_US.UTF-8\nLC_PAPER=en_US.UTF-8\nLC_IDENTIFICATION=en_US.UTF-8\nLC_TELEPHONE=en_US.UTF-8\nLC_MEASUREMENT=en_US.UTF-8\nLC_TIME=en_US.UTF-8\nLC_NUMERIC=en_US.UTF-8\n\n\n# load the new config\nsource /etc/default/locale\n\n# update the language support by using the default config\nsudo update-locale LANG=en_US.UTF-8\n</code></pre>"},{"location":"adminsys/os_setup/02.Add_debian_backports_repo/","title":"Add debian backports repo","text":"<p>The </p> <pre><code># add the backports repo to the source.list.d dir\necho \"deb http://deb.debian.org/debian bullseye-backports main\" | sudo tee /etc/apt/sources.list.d/bullseye-backports.list\n\n# update the repo index\nsudo apt update\n\n# install a package by using the backports repo\nsudo apt -t bullseye-backports install openssl\n</code></pre>"},{"location":"adminsys/os_setup/03.Remote_Desktop_access/","title":"Remote desktop access","text":"<p>If your linux runs on cloud, and you wish access this server's desktop interface, the below tutorial can help you. I have tested three solutions: - X2go: https://wiki.x2go.org/doku.php - Nomachine: https://www.nomachine.com/ - xrdp:</p>"},{"location":"adminsys/os_setup/03.Remote_Desktop_access/#x2go-and-nomachine","title":"X2go and nomachine","text":"<p>If you have no other choice, these two solutions can be your last hope. They both have many bugs. The screen resolution for example is a pain in the ass to setup correctly. Nomachine also requires admin rights on both client and server.</p> <p>You can follow their official doc to install them.</p>"},{"location":"adminsys/os_setup/03.Remote_Desktop_access/#xrdp","title":"Xrdp","text":"<p>xrdp is a free and open-source implementation of <code>Microsoft RDP (Remote Desktop Protocol) server</code> that enables operating  systems other than Microsoft Windows (such as Linux and BSD-style operating systems) to provide a fully functional  <code>RDP-compatible remote desktop</code> experience. It works by bridging graphics from the X Window System to the  client and relaying controls from the client back to X Window Server.</p> <p>The initial versions of the XRDP project relied on a <code>local VNC server installation</code>. Due to the <code>slow performance</code> of  forwarding to a VNC server, the developers introduced the X11rdp mode,  resulting in improved draw times and  an overall better user experience. In 2019, the XRDP developers announced the xorgxrdp project as the replacement  to the <code>X11rdp mode</code>, which is the default mode that XRDP uses in new installations.</p> <p>You can visit their github page, if you are interested in how it works.</p>"},{"location":"adminsys/os_setup/03.Remote_Desktop_access/#xrdp-server-side-installation","title":"Xrdp server side installation","text":"<p>This tutorial is tested under ubuntu 24.</p> <pre><code># Step 1 \u2013 Update Ubuntu\nsudo apt-get update -y\n\nsudo apt-get upgrade #optional\n\n# Step 2 \u2013 Install XRDP\nsudo apt install xrdp -y\nsudo systemctl status \n\n# Step 3 \u2013 Configure SSL\n# xrdp daemon is lanuched by the service account xrdp, it requires certain privilege to access SSL/TLS certificates stored on the system.\n# The below command add user xrdp to the group ssl-cert\nsudo adduser xrdp ssl-cert\n\n# restart the deamon\nsudo systemctl restart xrdp\n\n# Add a Firewall Rule to allow inbound and outbound traffic on port 3389\nsudo ufw allow from 192.168.0.0/24 to any port 3389\nsudo ufw allow 3389\nsudo ufw reload \n\n# Step 4 \u2013 Test the XRDP connection\n</code></pre>"},{"location":"adminsys/os_setup/03.Remote_Desktop_access/#xrdp-client-side-installation-and-configuration","title":"Xrdp client side installation and configuration","text":"<p>The client side installation happens on the pc which you want to use to connect to the server.</p>"},{"location":"adminsys/os_setup/03.Remote_Desktop_access/#for-windows","title":"For Windows:","text":"<ol> <li>Search for \u201cRemote Desktop Connection\u201d: You can do this by typing \u201cRemote Desktop Connection\u201d in the Windows search bar.</li> <li>Open the Remote Desktop Connection application: Click on the application in the search results. You should see below GUI. </li> </ol> <p> 3. Enter the Computer\u2019s IP Address or Hostname: In the Remote Desktop Connection window, you\u2019ll need to enter the  IP address or hostname of the computer you want to connect to. 4. Click \u201cConnect\u201d: Once you\u2019ve entered the required information, click the \u201cConnect\u201d button. When you get the certificate warning, click YES.</p> <p> 5. Enter Credentials: You\u2019ll be prompted to enter the username and password for the computer you are connecting to.  Ensure you have the correct credentials. The session value should be Xorg. If you choose <code>xvnc</code>, you need to install the required packages on the server side. 6. Connect: After entering the credentials, click \u201cOK\u201d or \u201cConnect\u201d to establish the RDP connection.</p> <p></p>"},{"location":"adminsys/os_setup/03.Remote_Desktop_access/#for-mac","title":"For Mac","text":"<ol> <li>Download Microsoft Remote Desktop from the App Store: If you don\u2019t have it already, you can download the Microsoft  Remote Desktop application from the Mac App Store.</li> <li>Open Microsoft Remote Desktop: Once installed, open the application.</li> <li>Click on \u201cNew\u201d: To create a new connection, click on the \u201c+\u201d icon or select \u201cNew\u201d from the File menu.</li> <li>Enter Connection Details: Enter the PC name or IP address, and configure other settings as needed.</li> <li>Save the Connection: Click \u201cAdd\u201d to save the connection.</li> <li>Connect: Select the newly created connection and click \u201cStart\u201d to initiate the RDP session.</li> </ol>"},{"location":"adminsys/os_setup/03.Remote_Desktop_access/#for-linux","title":"For linux","text":"<p>You can download various rdp clients: - FreeRDP - rdesktop - KRDC - NeutrinoRDP</p>"},{"location":"adminsys/os_setup/03.Remote_Desktop_access/#troubleshoot","title":"Troubleshoot","text":"<p>To debug <code>xrdp</code>, you can get the log from <code>/var/log/xrdp.log</code>.</p>"},{"location":"adminsys/os_setup/03.Remote_Desktop_access/#wrong-credential","title":"Wrong credential","text":"<p>If you get this message <code>login failed</code>, you have mistyped your details or logged in to an active session  (someone else is logged on with the same login). Linux allows multiple console connections, but only one GUI desktop connection. You need to close other GUI desktop connection</p>"},{"location":"adminsys/os_setup/03.Remote_Desktop_access/#black-screen","title":"Black screen","text":"<p>For recent linux version(ubuntu 22, 24), you may get a BLACK screen. Because xrdp uses the Xorg(implementation of the X11 protocol of the X window System) to do the remote display. But ubuntu 22, 24 use Wayland, so it misses some important packages. </p> <p>Below command will install dbus-x11 package, which provides a D-Bus session bus for each X11 display.</p> <pre><code>sudo apt-get install dbus-x11\n\n# a script will be generated, normally you don't need to modify it. \nsudo nano /etc/xrdp/startwm.sh\n\n# just check if it matches with the below content\nif test -r /etc/profile; then\n        . /etc/profile\nfi\n\nif test -r ~/.profile; then\n        . ~/.profile\nfi\n\ntest -x /etc/X11/Xsession &amp;&amp; exec /etc/X11/Xsession\nexec /bin/sh /etc/X11/Xsession\n\n\n# if everything matches, just reboot the server\nsudo reboot\n</code></pre>"},{"location":"adminsys/os_setup/03.Remote_Desktop_access/#custom-xrdp-port","title":"custom xrdp port","text":"<p>The xrdp server listens for incoming RDP connections on port number 3389 by default. </p> <p>To instruct xrdp to listen on a different port, you need to edit the <code>xrdp.ini</code></p> <pre><code>sudo vim /etc/xrdp/xrdp.ini\n\n# Locate the port directive in the [Globals] section and set the desired value. In this example, the RDP port is 49952:\nport=49952\n\n# save the file and restart the daemon\nsudo systemctl restart xrdp\n\n# don't forget change the firewall if you have one\nsudo ufw status\nsudo ufw allow 49952/tcp\nsudo ufw reload\n</code></pre> <p>For the client side, you need to specify the port number inside the <code>computer ip input</code> with the form IP_address:port_number.</p>"},{"location":"adminsys/os_setup/05.Debian_security_update_automation/","title":"Debian security updates automation","text":""},{"location":"adminsys/os_setup/05.Debian_security_update_automation/#1-apply-updates-manually","title":"1. Apply updates manually","text":"<pre><code># fetch repo updates\nsudo apt-get update\n\n#  list all available upgrades\nsudo apt list --upgradable\n\n# install updates\nsudo apt-get upgrade\n\n# clean outdated package cache:\nsudo apt-get autoclean\n\n# clean unnecessary dependencies:\nsudo apt autoremove -y\n\n# check the integrity of the apt-get, this the advance feature which is not implemented in apt. So you need to type apt-get\nsudo apt-get check\n\n# try to fix \nsudo apt --fix-broken install\n</code></pre> <p>If your linux kernel is updated, we recommend you to reboot your OS to check if everything is ok</p> <pre><code># restart \nsudo shutdown -r now\n\n# show the kernel version\nuname -mrs\n</code></pre> <p>A script which can automate the process via cron job</p> <pre><code>#!/bin/bash\nexport NEEDRESTART_MODE=a\nexport DEBIAN_FRONTEND=noninteractive\n## Questions that you really, really need to see (or else). ##\nexport DEBIAN_PRIORITY=critical\napt-get -qy clean\napt-get -qy update\napt-get -qy -o \"Dpkg::Options::=--force-confdef\" -o \"Dpkg::Options::=--force-confold\" upgrade\n</code></pre> <p>You can notice, we set special shell variable named DEBIAN_FRONTEND, NEEDRESTART_MODE, and DEBIAN_PRIORITY to  avoid issues when running task in the backround via cron job.</p>"},{"location":"adminsys/os_setup/05.Debian_security_update_automation/#2-use-the-unattended-upgrades-package","title":"2. Use the unattended-upgrades package","text":"<p>There is a package called unattended-upgrades, which can install the security updates automatically in the background. We also recommend two more packages: - apt-listchanges: can compare a new package version with the one currently installed and show what has been                         changed by extracting the relevant entries from the Debian changelog and NEWS files. - bsd-mailx: traditional simple command-line-mode mail user agent</p> <pre><code>sudo apt update &amp;&amp; sudo apt upgrade\n\n# install the packages\nsudo apt install unattended-upgrades apt-listchanges bsd-mailx\n\n# remove old conf and generate default conf\nsudo dpkg-reconfigure unattended-upgrades\n\n# Select \"Yes\" when prompted to enable automatic updates.\n</code></pre> <p>The objective of the three tools, <code>unattended-upgrades</code> install the updates, <code>apt-listchanges</code> log the changes  during the update, <code>bsd-mailx</code> send the log to user mail box.</p> <p>You can control the <code>unattended-upgrades</code> daemons with the below command.</p> <pre><code>systemctl start unattended-upgrades # start the service\nsystemctl stop unattended-upgrades # stop the service\nsystemctl restart unattended-upgrades # restart the service\nsystemctl enable unattended-upgrades # enable at boot time\nsystemctl disable unattended-upgrades # disable at boot time\nsystemctl status unattended-upgrades # get the status\n</code></pre>"},{"location":"adminsys/os_setup/05.Debian_security_update_automation/#21-configure-the-unattended-upgrades-daemon","title":"2.1 Configure the unattended-upgrades daemon","text":"<p>There are two important conf files for <code>unattended-upgrades</code> daemon: - /etc/apt/apt.conf.d/50unattended-upgrades: it's auto generated after the installation of <code>unattended-upgrades</code> - /etc/apt/apt.conf.d/20auto-upgrades: You need to add it manually or call <code>sudo dpkg-reconfigure -plow unattended-upgrades</code>                                       to generate this config file</p>"},{"location":"adminsys/os_setup/05.Debian_security_update_automation/#211-50unattended-upgrades","title":"2.1.1 50unattended-upgrades","text":"<p>This conf file set up the package repo origin. Below is an example</p> <pre><code># open the conf file\nsudo vim /etc/apt/apt.conf.d/50unattended-upgrades\n\n    \"origin=Debian,codename=${distro_codename},label=Debian\";\n    \"origin=Debian,codename=${distro_codename},label=Debian-Security\";\n    \"origin=Debian,codename=${distro_codename}-security,label=Debian-Security\";\n</code></pre> <p>You can skip packages by using blacklist</p> <pre><code>// Use python regular expression\n// \nUnattended-Upgrade::Package-Blacklist {\n    \"nginx\";\n        \"linux-image*\";\n};\n</code></pre> <p>You need to configure an email address to get email when there is a problem or package upgrades:</p> <pre><code>Unattended-Upgrade::Mail \"notify@server1.cyberciti.biz\";\n# Or at least send it to root user on the same system:\n# You can access root mail from /var/mails via root account\nUnattended-Upgrade::Mail \"root\";\n</code></pre>"},{"location":"adminsys/os_setup/05.Debian_security_update_automation/#212-enable-auto-cleanup-of-old-packages","title":"2.1.2 Enable Auto-Cleanup of Old Packages","text":"<p>After auto upgrades, we can also remove old unused packages</p> <pre><code>sudo vim /etc/apt/apt.conf.d/50unattended-upgrades\n\n# enable this line\nUnattended-Upgrade::Remove-Unused-Kernel-Packages \"true\";\nUnattended-Upgrade::Remove-Unused-Dependencies \"true\";\n\n# we don't recommend auto reboot at all\nUnattended-Upgrade::Automatic-Reboot \"false\";  # Reboots automatically if required\n# if you set auto reboot to true, you need also set the reboot time\nUnattended-Upgrade::Automatic-Reboot-Time \"03:00\";  # Set the reboot time (change as needed)\n</code></pre>"},{"location":"adminsys/os_setup/05.Debian_security_update_automation/#213-enable-periodic-updates","title":"2.1.3 Enable Periodic Updates","text":"<p>/etc/apt/apt.conf.d/20auto-upgrades</p> <p>This config file activates the <code>unattended-upgrades</code> daemon. It also sets how often the apt clean the unnecessary packages.</p> <p>We recommend you add at least the below three lines in this config file.</p> <pre><code># Update-Package-Lists is like apt update, you can choose 0, 1, 2, etc\n# \"0\" : Disable automatic updates.\n# \"1\" : Update package lists daily.\n# \"2\" : Update every 2 days, etc.\n# in our case, it runs every 7 days\nAPT::Periodic::Update-Package-Lists \"7\";\n\n# like apt upgrade\nAPT::Periodic::Unattended-Upgrade \"7\";\n\n# set how often the clean will be done\nAPT::Periodic::AutocleanInterval \"15\";\n</code></pre>"},{"location":"adminsys/os_setup/05.Debian_security_update_automation/#22-configure-the-apt-listchanges","title":"2.2. Configure the apt-listchanges","text":"<p>The main config file of this daemon is  <code>/etc/apt/listchanges.conf</code>. Below is an example</p> <pre><code>[apt]\nfrontend=pager\nwhich=news\nemail_address=root\nemail_format=text\nconfirm=false\nheaders=false\nreverse=false\nsave_seen=/var/lib/apt/listchanges.db\n</code></pre> <p>change the mail_address if you want to redirect the mail to another mail box. </p>"},{"location":"adminsys/os_setup/05.Debian_security_update_automation/#23-test-your-installation","title":"2.3 Test your installation","text":"<pre><code>sudo unattended-upgrades --dry-run --debug\n</code></pre>"},{"location":"adminsys/os_setup/05.Debian_security_update_automation/#3-view-and-config-the-upgrade-schedules","title":"3. View and config the upgrade schedules","text":"<p>In debian <code>Debian 11/10</code> Unattended Upgrades daemon uses <code>systemd timer</code> to schedules the updates.  To view schedule value, use the below command</p> <pre><code># schedules used for download packages\nsystemctl cat apt-daily.timer \n\n# output example\n# /lib/systemd/system/apt-daily.timer\n[Unit]\nDescription=Daily apt download activities\n\n[Timer]\nOnCalendar=*-*-* 6,18:00\nRandomizedDelaySec=12h\nPersistent=true\n\n[Install]\nWantedBy=timers.target\n\n\n# schedules used for upgrade packages\nsystemctl cat apt-daily-upgrade.timer\n\n# output example\n# /lib/systemd/system/apt-daily-upgrade.timer\n[Unit]\nDescription=Daily apt upgrade and clean activities\nAfter=apt-daily.timer\n\n[Timer]\nOnCalendar=*-*-* 6:00\nRandomizedDelaySec=60m\nPersistent=true\n\n[Install]\nWantedBy=timers.target\n</code></pre>"},{"location":"adminsys/os_setup/05.Debian_security_update_automation/#31-modify-the-default-schedules","title":"3.1 Modify the default schedules","text":"<p>Edit the schedules used for download packages</p> <pre><code>systemctl edit apt-daily.timer \n# restart the service\nsudo systemctl restart apt-daily.timer \n# check the status\nsystemctl status apt-daily.timer \n</code></pre> <p>Edit the schedules used for upgrade packages</p> <pre><code>systemctl edit apt-daily-upgrade.timer\nsudo systemctl restart apt-daily-upgrade.timerr\nsystemctl status apt-daily-upgrade.timer\n</code></pre>"},{"location":"adminsys/os_setup/05.Debian_security_update_automation/#4-trouble-shoot","title":"4. Trouble shoot","text":"<p>If you encounter problems, you can check the log of the <code>unattended-upgrades</code> daemon. </p> <pre><code>tail -f /var/log/unattended-upgrades/unattended-upgrades-shutdown.log\n</code></pre>"},{"location":"adminsys/os_setup/06.Accept_private_ca_certificate/","title":"Accept private ca certificate","text":"<p>If you want your server to accept custom certificates, you can follow the below steps. There are two scenarios:  1. You have a self-signed certificate  2. You have a certificate which signed by a CA, but the CA is not recognized by the server by default.</p> <p>For <code>scenario 1</code>, you just copy the self-signed certificate. For <code>scenario 2</code>, you should copy the root CA certificate, so all the certificate signed by this CA will be accepted in the future.</p>"},{"location":"adminsys/os_setup/06.Accept_private_ca_certificate/#1-convert-certificate-to-accepted-format","title":"1. Convert certificate to accepted format","text":"<p>Debian only accepts certificate of format .crt or .pem. If your certificate is in other formats, you need to convert them into the accepted format</p> <pre><code># convert der to crt\nopenssl x509 \\\n       -inform der -in domain.der \\\n       -out domain.crt\n\n# convert pcks7 to crt\nopenssl pkcs7 \\\n       -in domain.p7b \\\n       -print_certs -out domain.crt\n\n# convert pkcs12 to crt\nopenssl pkcs12 \\\n       -in domain.pfx \\\n       -nodes -out domain.combined.crt\n</code></pre> <p>Certain certificate format contains also the private key, so pay attention on the output file, don't leak the private key.</p>"},{"location":"adminsys/os_setup/06.Accept_private_ca_certificate/#2-add-certificate-as-trusted","title":"2. Add certificate as trusted","text":"<pre><code># to keep track off the custom ca we create a sub-folder\nsudo mkdir /usr/local/share/ca-certificates/casd-ca\n\n# copy the certificate\nsudo cp your-ca.crt /usr/local/share/ca-certificates/casd-ca/.\n\n# ask debian to load the new certificate\nsudo update-ca-certificates\n\n# test it with a site which uses the certificate or signed by the certificate\ncurl https://target-url\n</code></pre>"},{"location":"adminsys/os_setup/07.Setup_shared_folder/","title":"Configure a shared folder in linux","text":"<p>The goal of this tutorial is to show how to set up a shared folder for all users. Users must be able to access data inside this folder (read write and execute by default) without the owner of the data changing the acl manually.</p> <p>The command such as <code>cp, mv</code> conserve the origin ACL of the data, so even the default ACL of the shared folder allows all users to access the data, but if the data is created in another folder and copied in the shared folder, by default the data conserves the origin ACL. As a result, the data may not be accessible </p> <p>The idea is : 1. create a shared folder called <code>/home/common</code> 2. set default ACL to o::rwx (give others read, write rights.) 3. set up a systemd to auto change ACL, when copy or move data to the shared folder</p>"},{"location":"adminsys/os_setup/07.Setup_shared_folder/#1-create-the-shared-folder","title":"1. Create the shared folder","text":"<pre><code># the owner and group will be root:root\nsudo mkdir /home/common\n</code></pre>"},{"location":"adminsys/os_setup/07.Setup_shared_folder/#2-setup-default-acl-for-the-shared-folder","title":"2. Setup default ACL for the shared folder","text":"<p>Run the below command to install the required packages</p> <pre><code># install required packages\nsudo apt update\n\nsudo apt install inotify-tools acl -y\n</code></pre> <ul> <li>acl: offers more options than basic chmod</li> <li>inotify-tools: overwatch a folder, when a waiting event happens, it can trigger target actions</li> </ul> <p>Configure default ACL </p> <pre><code># by default we grant full access for others. For the owner and group, the origin ACL will be conserved.\nsudo setfacl -d -m o::rwx /home/common\n</code></pre> <p>After this step, all files and folders created in the shared folder will inherit the default ACL </p>"},{"location":"adminsys/os_setup/07.Setup_shared_folder/#3-configure-a-systemd-daemon-to-auto-update-acl","title":"3. Configure a systemd daemon to auto update ACL","text":""},{"location":"adminsys/os_setup/07.Setup_shared_folder/#31-create-the-daemon-script","title":"3.1 Create the daemon script","text":"<p>Create the daemon script in <code>/usr/local/bin</code></p> <pre><code># choose your favorite editor\nsudo vim /usr/local/bin/update_acl.sh\n</code></pre> <p>Copy the below script in the file</p> <pre><code>#!/bin/bash\n\n# the dir which the daemon will watch\nWATCH_DIR=\"/home/common\"\n# the ACL will be enforced by the daemon\nACL_PERMISSIONS=\"o::rwx\"\n\ninotifywait -m -r -e close_write,moved_to,create \"$WATCH_DIR\" --format \"%w%f\" |\nwhile read NEWITEM; do\n  # check if the new coming item is a directory or a file\n    if [ -d \"$NEWITEM\" ]; then\n        echo \"Fixing ACL for new directory: $NEWITEM\"\n        # -R means recursively update the ACL of the new directory.\n        setfacl -R -m \"$ACL_PERMISSIONS\" \"$NEWITEM\"\n        # -d sets default ACL so future files in the new directory inherit correct permissions.\n        setfacl -d -m \"$ACL_PERMISSIONS\" \"$NEWITEM\"\n    else\n        echo \"Fixing ACL for new file: $NEWITEM\"\n        setfacl -m \"$ACL_PERMISSIONS\" \"$NEWITEM\"\n    fi\ndone\n</code></pre> <p>make the script executable</p> <pre><code>sudo chmod +x /usr/local/bin/update_acl.sh\n</code></pre>"},{"location":"adminsys/os_setup/07.Setup_shared_folder/#32-create-the-systemd-daemon-launcher-for-update_aclsh","title":"3.2 Create the systemd daemon launcher for update_acl.sh","text":"<p>The systemd daemon launcher must be located at <code>/etc/systemd/system/</code>. By convention, we name it as <code>update_acl.service</code></p> <p>Open the file with your favorite editor</p> <pre><code>sudo vim /etc/systemd/system/update_acl.service\n</code></pre> <p>Copy the below lines in the file</p> <pre><code>[Unit]\nDescription=Update ACLs for date copied to shared directory\nAfter=network.target\n\n[Service]\nExecStart=/usr/local/bin/update_acl.sh\nRestart=always\nUser=root\n\n[Install]\nWantedBy=multi-user.target\n</code></pre>"},{"location":"adminsys/os_setup/07.Setup_shared_folder/#33-enable-the-systemd-daemon","title":"3.3 Enable the systemd daemon","text":"<pre><code># reload the daemon list from the repository\nsudo systemctl daemon-reload\n\n# enable the service for startup\nsudo systemctl enable update_acl.service\n\n# start the service \nsudo systemctl start update_acl.service\n\n# check the satus\nsudo systemctl status update_acl.service\n\n# stop the service\nsudo systemctl stop update_acl.service\n</code></pre>"},{"location":"adminsys/os_setup/07.Setup_shared_folder/#4-test-the-solution","title":"4. Test the solution","text":"<p>After the above steps, you need to login to the server with two different users: - user1 - user2</p> <p>user1 actions</p> <pre><code>#  create a file in his home\ntouch ~/test1.txt\n\n# set the acl to owner only, \nchmod 0700 ~/test.txt\n\n# copy the file to the /home/common\ncp ~/test.txt /home/common\n\n# create a file directly in the shared folder\ncd /home/common\n\n# create a file\ntouch test2.txt\n</code></pre> <p>user2 actions</p> <pre><code># go to the share folder\ncd /home/common\n\n# list the existing files\nls -lah\n\n# show the content of test1 and test2\ncat test1.txt\ncat test2.txt\n</code></pre> <p>If user2 can show the content, it means the daemon works well. If user2 see <code>permission deny</code>, it means something went wrong. Call admin linux</p>"},{"location":"adminsys/os_setup/08.Debian_upgrade/","title":"Upgrade Debian from 11 to 13","text":"<p>If you are under debian 11, and you want to upgrade to 13. You can follow the below steps.</p> <p>Debian only supports upgrades one major version at a time, so you must pass through Bookworm (12) before reaching Trixie (13).</p> <p>So we need to upgrade debian 11 to 12, then to 13.</p>"},{"location":"adminsys/os_setup/08.Debian_upgrade/#1-preparation-of-debian-11","title":"1. Preparation of debian 11.","text":"<p>To make sure your debian 11 is ready. Let's run the below commands</p> <pre><code># make sure you have the latest debian 11 packages\nsudo apt update\nsudo apt full-upgrade\nsudo apt autoremove\n\n# check your architecture\ndpkg --print-architecture\n\n# check your release version\nlsb_release -a\n\n# if you don't have lsb_release commands, you can install it\n# lsb-release is the package name. The command is lsb_release\nsudo apt install lsb-release\n\nsudo reboot\n</code></pre>"},{"location":"adminsys/os_setup/08.Debian_upgrade/#2-upgrade-to-debian-12bookworm","title":"2. Upgrade to Debian 12(Bookworm)","text":"<p>Edit the sources list by replacing <code>bullseye</code> source with <code>bookworm</code> source.</p> <pre><code># open the source.list file and comment the old sources\nsudo vim /etc/apt/sources.list\n\n# add the new debian 12 sources\ndeb http://deb.debian.org/debian bookworm main contrib non-free non-free-firmware\ndeb http://deb.debian.org/debian-security bookworm-security main contrib non-free non-free-firmware\ndeb http://deb.debian.org/debian bookworm-updates main contrib non-free non-free-firmware\n</code></pre> <p>Start the upgrade process</p> <pre><code>sudo apt update\nsudo apt full-upgrade\nsudo apt autoremove\n\n# check your release version\nlsb_release -a\n\n# you should see debian 12 as output\n\n# restart the server\nsudo reboot\n</code></pre> <p>During the upgrade, you may be asked to confirm if you want to use the new default conf or your old conf for <code>sudoer</code> or <code>sshd</code> I recommend you to keep your version. Because the new conf may remove your sudo rights or ssh access.</p>"},{"location":"adminsys/os_setup/08.Debian_upgrade/#3-upgrade-to-debian-13trixie","title":"3. Upgrade to Debian 13(Trixie)","text":"<p>Edit the sources list by replacing <code>bookworm</code> source with <code>Trixie</code> source.</p> <pre><code># open the source.list file and comment the old sources\nsudo vim /etc/apt/sources.list\n\n# add the new debian 13 sources\ndeb http://deb.debian.org/debian trixie main contrib non-free non-free-firmware\ndeb http://deb.debian.org/debian-security trixie-security main contrib non-free non-free-firmware\ndeb http://deb.debian.org/debian trixie-updates main contrib non-free non-free-firmware\n</code></pre> <p>Start the upgrade process</p> <pre><code>sudo apt update\nsudo apt full-upgrade\nsudo apt autoremove\n\n# check your release version\nlsb_release -a\n\n# you should see debian 13 as output\n\n# restart the server\nsudo reboot\n</code></pre> <p>During the upgrade, you may be asked to confirm if you want to use the new default conf or your old conf for <code>sudoer</code> or <code>sshd</code> I recommend you to keep your version. Because the new conf may remove your sudo rights or ssh access.</p>"},{"location":"adminsys/os_setup/08.Debian_upgrade/#3-post-upgrade-cleanup","title":"3. Post-upgrade cleanup","text":"<pre><code># Check services that were replaced or modified:\nsystemctl --failed\n\n# verify the kernel\nuname -a\n\n# check your release version\nlsb_release -a\n\n# verify the firmware\ndpkg -l | grep firmware\n</code></pre>"},{"location":"adminsys/os_setup/Install_configure_Postfix_to_sendmail/","title":"Configure Postfix MTA as Send-Only on Debian 11","text":""},{"location":"adminsys/os_setup/Install_configure_Postfix_to_sendmail/#1-setup-server-hostname","title":"1 Setup server hostname","text":"<p>The hostname of the server will be used as the name of the sender of the emails. So you should keep it nice and clean</p> <pre><code># get the current hostname\nhostname\n\n# if the name does not fit you, you can set up a new hostname\nsudo hostnamectl set-hostname smtp.casd.local --static\n</code></pre>"},{"location":"adminsys/os_setup/Install_configure_Postfix_to_sendmail/#2install-the-packages","title":"2Install the packages","text":"<pre><code># Install mailutils package\nsudo apt install mailutils\n\n# install postfix\nsudo apt install postfix\n</code></pre> <p>As the <code>postfix</code> package installs, you\u2019ll be asked to select an option on screen for your mail server.  For General type of email configuration window, select Internet site and click OK button. Here we suppose your server has internet connexion.</p> <p>The next page will ask you to set your Mail server name, this can be domain or server hostname with an A record. In this tutorial, we choose the host name of the server <code>smtp.casd.local</code>.</p>"},{"location":"adminsys/os_setup/Install_configure_Postfix_to_sendmail/#3-configure-postfix-mta-server","title":"3. Configure Postfix MTA Server","text":"<p>Edit Postfix configuration file /etc/postfix/main.cf to ensure it is configured as send only ( Only relaying emails from the local server).</p> <p>Set Postfix to listen on the 127.0.0.1loopback interface. <code>The default setting is to listen on all interfaces</code></p> <pre><code># open the conf file\nsudo vim /etc/postfix/main.cf\n\n# edit the below line\ninet_interfaces=loopback-only\nmyhostname=smtp.casd.local\n\n# restart the postfix service\nsudo systemctl restart postfix\n</code></pre>"},{"location":"adminsys/os_setup/Install_configure_Postfix_to_sendmail/#4-test-the-postfix-service","title":"4. Test the postfix service","text":"<p>To test email delivery, use the mail command like below.</p> <pre><code># send a mail to userx@example.com with title `Postfix Testing` and content `Postfix Send-Only Server`\necho \"Postfix Send-Only Server\" | mail -s \"Postfix Testing\" userx@example.com\n</code></pre> <p>Check the junk mails, you may find it there.</p>"},{"location":"adminsys/os_setup/auto_config/ansible/ansible_roles/","title":"Ansible roles","text":"<p>Read this doc  for more details on how to write an ansible role</p> <p>An Ansible Role is a <code>self-contained, portable unit</code> of Ansible automation that serves as the preferred method for  grouping related tasks and associated variables, files, handlers, and other assets in a known file structure.  While automation tasks can be written exclusively in an Ansible Playbook, Ansible Roles allow you to create bundles  of automation content that can be  - run in 1 or more plays,  - reused across playbooks,  - shared with other users in collections.</p>"},{"location":"adminsys/os_setup/auto_config/ansible/ansible_roles/#role-organization","title":"role organization","text":"<p><code>Ansible Roles</code> are expressed in YAML files. When a role is included in a task or a play, Ansible looks for  a <code>main.yml</code> file in at least 1 of 8 standard role directories such as : - tasks,  - handlers,  - modules,  - defaults,  - variables,  - files,  - templates, - meta.</p> <pre><code>roles/\n    my_role1/               # this hierarchy represents a \"role\"\n        tasks/            #\n            main.yml      #  &lt;-- tasks file can include smaller files if warranted\n        handlers/         #\n            main.yml      #  &lt;-- handlers file\n        templates/        #  &lt;-- files for use with the template resource\n            ntp.conf.j2   #  &lt;------- templates end in .j2\n        files/            #\n            bar.txt       #  &lt;-- files for use with the copy resource\n            foo.sh        #  &lt;-- script files for use with the script resource\n        vars/             #\n            main.yml      #  &lt;-- variables associated with this role\n        defaults/         #\n            main.yml      #  &lt;-- default lower priority variables for this role\n        meta/             #\n            main.yml      #  &lt;-- role dependencies\n        library/          # roles can also include custom modules\n        module_utils/     # roles can also include custom module_utils\n        lookup_plugins/   # or other types of plugins, like lookup in this case\n\n    my_role2/              # same kind of structure as \"my_role1\" was above, but for another purpose\n    my_role3/              # \"\"\n    my_role4/              # \"\"\n</code></pre>"},{"location":"adminsys/os_setup/auto_config/ansible/ansible_roles/#role-vs-playbook","title":"Role vs Playbook","text":"<p>Why use an Ansible Role instead of an Ansible Playbook? Ansible Roles and Ansible Playbooks are both tools for organizing and executing automation tasks, but each serves a different purpose. Whether you choose to create Ansible Roles or write all of your tasks in an Ansible Playbook depends on your specific use case and your experience with Ansible.</p> <p>Most automation developers and system administrators begin creating automation content with individual playbooks. A playbook is a list of automation tasks that execute for a defined inventory. Tasks can be organized into a play\u2014a grouping of 1 or more tasks mapped to a specific host and executed in order. A playbook can contain 1 or more plays, offering a flexible mechanism for executing Ansible automation in a single file.</p> <p>While playbooks are a powerful method for automating with Ansible, writing all of your tasks in a playbook isn\u2019t always the best approach. In instances where scope and variables are complex and reusability is helpful, creating most of your automation content in Ansible Roles and calling them within a playbook may be the more appropriate choice.</p> <p>The following example illustrates the use of a role, linux-systemr-roles.timesync, within a playbook. In this instance, over 4 tasks would be required to achieve what the single role accomplishes. </p>"},{"location":"adminsys/os_setup/auto_config/ansible/ansible_roles/#creating-a-role","title":"Creating a role","text":"<p>You can create a new role skeleton by using <code>ansible-galaxy</code></p> <pre><code> ansible-galaxy role init role_name\n</code></pre>"},{"location":"adminsys/os_setup/auto_config/ansible/ansible_roles/#sharing-a-role","title":"Sharing a role","text":"<p>There are few ways to share your ansible roles:</p> <ul> <li>Ansible Galaxy: A free repository for sharing roles and other Ansible content with the larger Ansible community.             Roles can be uploaded to Ansible Galaxy via the command-line (CLI), whereas collections can be shared                 from the web interface. Since Ansible Galaxy is a community site, content is not vetted, certified.</li> <li>Ansible automation hub: repo for <code>Red Hat Ansible Automation Platform</code>, which is a central repository for                         finding, downloading, and sharing <code>Ansible Content Collections</code>.</li> <li>Private automation hub: An on-premise repository. You can share roles and other automation content within your                             enterprise, allowing teams to simplify workflows and speed up automation. </li> </ul>"},{"location":"adminsys/os_setup/auto_config/ansible/ansible_roles/#use-roles-in-an-ansible-playbook","title":"Use roles in an ansible playbook","text":"<p>There are three ways to integre an <code>ansible role</code> in an <code>ansible playbook</code>. - Use the <code>roles</code> option in playbook - Use the <code>include_role</code> in a task  - Use the <code>import_role</code> in a task</p>"},{"location":"adminsys/os_setup/auto_config/ansible/ansible_roles/#use-the-roles-option-in-playbook","title":"Use the <code>roles</code> option in playbook","text":"<p>Below is an example of a playbook which calls the role <code>configure_sshd_pam_sssd_openldap</code> and <code>intall_nginx</code> before tasks. </p> <p>If you have multiple roles, the order is not guarantied with this approach. The roles are executed before tasks. If you want to order the task and roles, use the <code>include_role</code> or <code>import_role</code></p> <pre><code>---\n- hosts: linux_servers\n  roles:\n    - configure_sshd_pam_sssd_openldap\n    - install_nginx\n  tasks:\n    - name: task1\n</code></pre>"},{"location":"adminsys/os_setup/auto_config/ansible/ansible_roles/#use-the-include_role-in-a-task","title":"Use the <code>include_role</code> in a task","text":"<p>The content of the role is parsed during the execution of the task. </p> <pre><code>---\n- hosts: linux_servers\n  tasks:\n    - name: Print a message\n      ansible.builtin.debug:\n        msg: \"this task runs before the role1\"\n\n    - name: Include the role with name role1\n      ansible.builtin.include_role:\n        name: role1\n      vars:\n        dir: '/opt/a'\n        app_port: 5000\n</code></pre>"},{"location":"adminsys/os_setup/auto_config/ansible/ansible_roles/#use-the-import_role-in-a-task","title":"Use the <code>import_role</code> in a task","text":"<p>The content of the role is parsed at the start of the playbook. </p>"},{"location":"adminsys/os_setup/package_management/01.Install_deb_files/","title":"Install Deb files","text":"<p>There are many ways to install packages in debian based linux (debian/ubuntu/Mint). There are two main ways to install packages:  - use the package manager such apt-get/apt to connect to package repo servers.  - use the standalone .deb file</p> <p>In this tutorial, we will focus on how to install packages via deb files. There are mainly four ways: - Use the GUI (available in ubuntu desktop) - Use apt (e.g. sudo apt install ./filename.deb) - Use dpkg (e.g. sudo dpkg -i ./filename.deb) - Use gdebi ()</p>"},{"location":"adminsys/os_setup/package_management/01.Install_deb_files/#1-use-apt","title":"1. Use apt","text":"<pre><code># be sure to \ncd path/to/deb\n\n# don't miss ./, without it apt will search them in the package repo instead of local file system.\nsudo apt install ./filename.deb\n\n# list all installed \nsudo apt list --installed\n\n# remove package name\nsudo apt remove package-name\n</code></pre>"},{"location":"adminsys/os_setup/package_management/01.Install_deb_files/#2-use-dpkg","title":"2. Use dpkg","text":"<pre><code># check the metadata of .deb file\ndpkg --info package-name.deb\n\n# install a deb file via dpkg, the -i option means install, it's case sensitive\nsudo dpkg -i ./filename.deb\n\n# if all required packages is already installed on the system, then we can stop here, if not\n# we need to run the below command, it fixes all missing dependencies\nsudo apt-get install -f\n\n# To see a list of all installed packages with Dpkg, use the command \nsudo dpkg-query -l\n\n# remove packages with Dpkg using \ndpkg -r packagename\n</code></pre>"},{"location":"adminsys/os_setup/package_management/01.Install_deb_files/#3-use-gdebi","title":"3. Use gdebi","text":"<p>gdebi is a tool specially developed for installing <code>.deb</code> files. It has a core and GUI. Actually <code>gdebi</code> is just a  front-end to the dpkg with added functionality that it can check for <code>dependency packages in the repositories</code>  and can install them in one-operation, while <code>dpkg -i</code> requires two operations manually (later being <code>apt-get -f install</code>).</p> <p>If the dependency packages exists in a repository which is not in the system source list, the gdebi installation will fail. You need to enable all required package repo before running the command.</p> <pre><code># the gdebi-core allows you to install .deb file via command line\nsudo apt install gdebi-core\n\n# install a .deb via gdebi\nsudo gdebi ./filename.deb\n\n# if you want to have GUI integration, you need to install main gdebi package too\nsudo apt install gdebi\n\n# this will add more options in the filesytem GUI, when right click on a .deb file in the filesytem ui, you will get\n# options to install it via gdebi\n\n# to remove a package installed by gdebi,\nsudo apt remove packagename\nsudo apt autoclean\n</code></pre>"},{"location":"adminsys/os_setup/package_management/02.Use_private_repo_in_debian/","title":"Use private repo","text":""},{"location":"adminsys/os_setup/package_management/02.Use_private_repo_in_debian/#add-private-repo-in-your-apt","title":"add private repo in your apt","text":"<p>suppose the url of the repo is <code>https://repolin.casd.fr</code></p> <pre><code>sudo vim /etc/apt/sources.list\n\n# add below line for a repo\ndeb [trusted=yes] https://repolin.casd.fr/ bullseye main\n</code></pre> <p>If the certificate is not signed by a known CA. You can install the certificate </p> <pre><code># get the certificate of the private repo\nopenssl s_client -connect {HOSTNAME}:{PORT} -showcerts\n\n# in our case\nopenssl s_client -connect repolin.casd.fr:443 -showcerts\n\n# copy the output certificate in a file and put it in below folder\nsudo mv casd-root.crt /usr/local/share/ca-certificates/\n# update the certificate list\nrun sudo update-ca-certificates\n\n# update the apt repo list\nsudo apt update\n\n# update packages\nsudo apt upgrade\n</code></pre>"},{"location":"adminsys/os_setup/security/","title":"Debian server security docs","text":"<p>In this folder, we store all documentation about debian server security.</p>"},{"location":"adminsys/os_setup/security/#1-sshd-authentication","title":"1. SSHD Authentication","text":"<p>The most common way to remote access a debian server is via ssh protocol. On the sever side, a sshd daemon runs as  ssh server that listens to port 22 (default port). It supports many authentication mechanisms such as:</p> <ul> <li>Password Authentication (Using /etc/shadow) : This method only works for local users (not LDAP, SSSD, or Kerberos users). In <code>/etc/ssh/sshd_config</code>, put <code>UsePAM no \\n PasswordAuthentication yes</code></li> <li>Public Key Authentication (No Password Required): SSHD checks if the user private key matches a valid public key in ~/.ssh/authorized_keys.</li> <li>GSSAPI/Kerberos Authentication: SSHD can authenticate users using GSSAPI (Kerberos-based authentication) without PAM</li> <li>PAM (Pluggable Authentication Modules) Recommended: It supports multiple authentication methods (LDAP, Kerberos, SSSD, MFA).</li> </ul>"},{"location":"adminsys/os_setup/security/#11-terms","title":"1.1 Terms","text":"<p>On linux server, to allow user remote access, we use many daemons:</p> <ul> <li>sshd</li> <li>pam(Pluggable Authentication Modules):</li> <li>sssd(System Security Services Daemon)Recommended: Provides access to remote identity and authentication providers, such as LDAP, Active Directory (AD), FreeIPA, or Kerberos.</li> <li>nslcd(Name Service LDAP Daemon) deprecated: Connects the Name Service Switch (NSS) and PAM to an LDAP directory for user authentication and identity lookup.</li> <li>nscd(Name Service Cache Daemon): Caches results from services like DNS and LDAP to reduce query load. sssd has its own caching mechanism, do not recommend when using sssd.</li> </ul>"},{"location":"adminsys/os_setup/security/#12-ssh-client-server-authentication-workflow","title":"1.2 SSH client server authentication workflow","text":"<p>In the below section, we describe the authentication  workflow of a ssh server configured with <code>sshd -&gt; pam -&gt; sssd -&gt; krb/openldap</code></p>"},{"location":"adminsys/os_setup/security/#step-1-ssh-client-initiates-connection","title":"Step 1. SSH Client Initiates Connection","text":"<p>A user runs:</p> <pre><code>ssh user@debian-server\n</code></pre> <p>The SSH daemon (sshd) on the Debian server receives the connection request and begins the authentication process.</p>"},{"location":"adminsys/os_setup/security/#step2-sshd-hands-authentication-to-pam","title":"Step2. SSHD Hands Authentication to PAM","text":"<p>SSHD is configured to use PAM (Pluggable Authentication Modules) for user authentication. It checks /etc/pam.d/sshd, which includes configurations for authentication backends. PAM invokes the relevant authentication module, in this case, SSSD.</p>"},{"location":"adminsys/os_setup/security/#step3-pam-calls-sssd-for-authentication","title":"Step3. PAM Calls SSSD for Authentication","text":"<p>PAM is configured to use SSSD via the module: /etc/pam.d/common-auth</p> <p>You should see the below line which tells pam to query sssd for authentication</p> <pre><code>auth    [success=1 default=ignore]    pam_sss.so\n</code></pre>"},{"location":"adminsys/os_setup/security/#step-4-sssd-queries-openldapkerberos-for-user-authentication","title":"Step 4. SSSD Queries OpenLDAP/kerberos for User Authentication","text":"<p>SSSD Configuration (/etc/sssd/sssd.conf) specifies OpenLDAP as the backend. SSSD checks if the credentials are cached: If cached, it allows authentication without querying OpenLDAP (useful for offline authentication). If not cached, SSSD sends the authentication request to OpenLDAP.</p>"},{"location":"adminsys/os_setup/security/#step-5-openldap-validates-user-credentials","title":"Step 5. OpenLDAP Validates User Credentials","text":"<p>OpenLDAP checks: If the user exists in the LDAP directory (uid=user). The password stored in LDAP. If using LDAP bind authentication, OpenLDAP attempts to bind as the user with the provided password. If using Kerberos (via LDAP), OpenLDAP defers authentication to a Kerberos KDC.</p>"},{"location":"adminsys/os_setup/security/#step-6-authentication-result-passed-back","title":"Step 6. Authentication Result Passed Back","text":"<p>If authentication is successful, OpenLDAP responds to SSSD. SSSD caches the credentials (if caching is enabled). SSSD informs PAM of the successful authentication. PAM notifies SSHD that the user is authenticated.</p>"},{"location":"adminsys/os_setup/security/#step-7-sshd-grants-access","title":"Step 7. SSHD Grants Access","text":"<p>If the user has the correct authorization (i.e., shell access, SSH keys, group policies), SSHD grants access. The user gets a shell on the Debian server. Authentication Flow Summary SSH Client \u2192 Requests login from SSHD. SSHD \u2192 Delegates authentication to PAM. PAM \u2192 Calls pam_sss.so to use SSSD. SSSD \u2192 Queries OpenLDAP (or checks cache). OpenLDAP \u2192 Verifies user credentials. SSSD \u2192 Returns authentication result to PAM. PAM \u2192 Informs SSHD. SSHD \u2192 Grants or denies access.</p>"},{"location":"adminsys/os_setup/security/#additional-notes","title":"Additional Notes","text":"<p>If 2FA (Two-Factor Authentication) is enabled, PAM may prompt for additional verification. If public key authentication is used, SSHD may bypass PAM and authenticate using the user's SSH key. If the LDAP server is down, authentication fails unless SSSD has cached credentials. Authorization (e.g., checking if a user belongs to a specific group) is usually done via sssd's access_provider settings.</p> <p><code>/etc/pam.d/sshd</code></p> <pre><code># PAM configuration for the Secure Shell service\n\n# Standard Un*x authentication.\n@include common-auth\n\n# Disallow non-root logins when /etc/nologin exists.\nauth       required     pam_env.so\nauth       sufficient   pam_unix.so nullok \nauth       sufficient   pam_sss.so use_first_pass\nauth       required     pam_deny.so\n\naccount    required     pam_unix.so\naccount    sufficient   pam_sss.so\n\npassword   required    pam_sss.so\nsession    required    pam_sss.so\n\n# Uncomment and edit /etc/security/access.conf if you need to set complex\n# access limits that are hard to express in sshd_config.\n# account  required     pam_access.so\n\n# Standard Un*x authorization.\n@include common-account\n\n# SELinux needs to be the first session rule.  This ensures that any\n# lingering context has been cleared.  Without this it is possible that a\n# module could execute code in the wrong domain.\nsession [success=ok ignore=ignore module_unknown=ignore default=bad]        pam_selinux.so close\n\n# Set the loginuid process attribute.\nsession    required     pam_loginuid.so\n\n# Create a new session keyring.\nsession    optional     pam_keyinit.so force revoke\n\n# Standard Un*x session setup and teardown.\n@include common-session\n\n# Print the message of the day upon successful login.\n# This includes a dynamically generated part from /run/motd.dynamic\n# and a static (admin-editable) part from /etc/motd.\nsession    optional     pam_motd.so  motd=/run/motd.dynamic\nsession    optional     pam_motd.so noupdate\n\n# Print the status of the user's mailbox upon successful login.\nsession    optional     pam_mail.so standard noenv # [1]\n\n# Set up user limits from /etc/security/limits.conf.\nsession    required     pam_limits.so\n\n# Read environment variables from /etc/environment and\n# /etc/security/pam_env.conf.\nsession    required     pam_env.so # [1]\n# In Debian 4.0 (etch), locale-related environment variables were moved to\n# /etc/default/locale, so read that as well.\nsession    required     pam_env.so user_readenv=1 envfile=/etc/default/locale\n\n# SELinux needs to intervene at login time to ensure that the process starts\n# in the proper default security context.  Only sessions which are intended\n# to run in the user's context should be run after this.\nsession [success=ok ignore=ignore module_unknown=ignore default=bad]        pam_selinux.so open\n\n# Standard Un*x password updating.\n@include common-password\n</code></pre>"},{"location":"adminsys/os_setup/security/01.Configure_ssh_local_account/","title":"Configure ssh server on debian 11","text":"<p>An <code>SSH Server</code> is a service that runs as a <code>daemon background process (systemd service)</code> on a computer (server) and  allows <code>secure remote access</code> using the <code>Secure Shell (SSH) protocol</code>. </p> <p>It listens for incoming connections on <code>port 22 (by default)</code>. It then authenticates users, creates a  secure encrypted session, and allows remote execution of commands.</p> <p>It enables users to:   - Log in remotely by using <code>passwords, SSH keys, or Kerberos authentication</code>.   - Execute commands on a remote system.   - Transfer files securely (using scp or sftp).   - Forward network connections (port forwarding, tunneling).</p>"},{"location":"adminsys/os_setup/security/01.Configure_ssh_local_account/#general-workflow","title":"General workflow","text":""},{"location":"adminsys/os_setup/security/02.Configure_ssh_pam_ldap/","title":"Configure debian server ssh to use pam ldap","text":"<p>We will use libpam-ldapd as the ldap server client and server authenticator to check user login and password via ldap server. It is a newer alternative to the original <code>libpam-ldap</code>. libpam-ldapd uses the same backend <code>(nslcd)</code> as <code>libnss-ldapd</code>, and thus also shares the same configuration file <code>(/etc/nslcd.conf)</code> for LDAP connection parameters. If you're already using libnss-ldapd for NSS, it may be more convenient to use libpam-ldapd's pam_ldap implementation.</p> <p>The /etc/pam.d/common-* files are managed by pam-auth-update (from libpam-runtime).</p> <p>The libpam-ldapd package includes <code>/usr/share/pam-configs/ldap</code>, and running <code>dpkg-reconfigure libpam-runtime</code> will let you configure the <code>pam_unix/pam_ldap</code> module(s) to use in /etc/pam.d/common-*.</p> <p>The nslcd is the name service LDAP connection daemon.</p> <p>Installing the libpam-ldapd package will automatically select the pam_ldap module for use in /etc/pam.d/common-*.</p>"},{"location":"adminsys/os_setup/security/02.Configure_ssh_pam_ldap/#61-install-the-required-packages","title":"6.1 Install the required packages","text":"<pre><code>sudo apt-get install libnss-ldapd libpam-ldapd\n</code></pre> <p>After the installation, a pop-up window will require you to enter the <code>ldap uri</code> and the <code>base dn</code> of the ldap server</p> <p>For example</p> <pre><code>ldap_uri: ldap://10.50.5.57/ or ldap://ldap.casd.local/\n\nldap_base_dn: dc=casd,dc=local\n</code></pre>"},{"location":"adminsys/os_setup/security/02.Configure_ssh_pam_ldap/#62-edit-the-config","title":"6.2 Edit the config","text":""},{"location":"adminsys/os_setup/security/02.Configure_ssh_pam_ldap/#621-the-first-config-is-etcnslcdconf","title":"6.2.1 The first config is <code>/etc/nslcd.conf</code>","text":"<p>As you already enter some information during installation. This file is filled with some info.</p> <p>Below is a working example.</p> <pre><code># /etc/nslcd.conf\n# nslcd configuration file. See nslcd.conf(5)\n# for details.\n\n# The user and group nslcd should run as.\nuid nslcd\ngid nslcd\n\n# The location at which the LDAP server(s) should be reachable.\nuri ldap://10.50.5.57/\n\n# The search base that will be used for all queries.\nbase dc=casd,dc=local\n\n# The LDAP protocol version to use.\n#ldap_version 3\n\n# The DN to bind with for normal lookups.\n#binddn cn=annonymous,dc=example,dc=net\n#bindpw secret\n\n# The DN used for password modifications by root.\n#rootpwmoddn cn=admin,dc=example,dc=com\n\n# SSL options\n#ssl off\n#tls_reqcert never\n# tls_cacertfile /etc/ssl/certs/ca-certificates.crt\n\n# The search scope.\n#scope sub\n</code></pre> <p>The good practice is not write the <code>binddn</code> and <code>bindpw</code> with admin privilege. If you leave it empty, <code>pam-ldapd</code> will use the current user login and pwd to bind to the ldap. So it's safer.</p>"},{"location":"adminsys/os_setup/security/02.Configure_ssh_pam_ldap/#622-etcnsswitchconf","title":"6.2.2 /etc/nsswitch.conf","text":"<p>Change the old version to below version</p> <pre><code># /etc/nsswitch.conf\n#\n# Example configuration of GNU Name Service Switch functionality.\n# If you have the `glibc-doc-reference' and `info' packages installed, try:\n# `info libc \"Name Service Switch\"' for information about this file.\n\npasswd:         files ldap\ngroup:          files ldap\nshadow:         files ldap\ngshadow:        files\n\nhosts:          files dns\nnetworks:       files\n\nprotocols:      db files\nservices:       db files\nethers:         db files\nrpc:            db files\n\nnetgroup:       nis\n</code></pre>"},{"location":"adminsys/os_setup/security/02.Configure_ssh_pam_ldap/#623-etcpamdcommon-","title":"6.2.3  /etc/pam.d/common-*","text":"<p>There are a list of config files for pam which are located at  /etc/pam.d/. In our case, we need to modify: - /etc/pam.d/common-auth - /etc/pam.d/common-account - /etc/pam.d/common-session - /etc/pam.d/common-password</p> <pre><code>sudo vim /etc/pam.d/common-auth\n\n# comment the old content, and add below line\nauth      sufficient  pam_unix.so\nauth      sufficient  pam_ldap.so minimum_uid=1000 use_first_pass\nauth      required    pam_deny.so\n</code></pre> <pre><code>sudo vim /etc/pam.d/common-account\n# comment the old content, and add below line\naccount   required    pam_unix.so\naccount   sufficient  pam_ldap.so minimum_uid=1000\naccount   required    pam_permit.so\n</code></pre> <pre><code>sudo vim /etc/pam.d/common-session\n# comment the old content, and add below line\nsession   required    pam_unix.so\nsession   optional    pam_ldap.so minimum_uid=1000\n# this line will create the user home for first login\nsession    required   pam_mkhomedir.so skel=/etc/skel/ umask=0022\n</code></pre> <pre><code>sudo vim /etc/pam.d/common-password\n# comment the old content, and add below line\npassword  sufficient  pam_unix.so nullok md5 shadow use_authtok\npassword  sufficient  pam_ldap.so minimum_uid=1000 try_first_pass\npassword  required    pam_deny.so\n</code></pre>"},{"location":"adminsys/os_setup/security/02.Configure_ssh_pam_ldap/#624-etcsshsshd_config","title":"6.2.4 /etc/ssh/sshd_config","text":"<p>Normally, you don't need to modify the  /etc/ssh/sshd_config. Because the <code>libpam-ldapd</code> will set UsePAM yes automatically for sshd to use PAM authentication.</p> <p>If you have troubles, don't forget to check </p> <p>The above conf is the minimun for the pam-ldapd works. You need to enrich it if you have special requirements</p>"},{"location":"adminsys/os_setup/security/02.Configure_ssh_pam_ldap/#63-restart-the-service","title":"6.3 Restart the service","text":"<p>As we metioned before, the</p> <pre><code># check the status of the daemon\nsudo systemctl status nscd\nsudo systemctl status nslcd\n\n# restart the service\nsudo systemctl restart nscd\nsudo systemctl restart nslcd\n</code></pre>"},{"location":"adminsys/os_setup/security/02.Configure_ssh_pam_ldap/#64-test-and-troubleshoot","title":"6.4 Test and troubleshoot","text":"<p>To ensure that everything is working correctly you can run </p> <pre><code># this command prints all user account of the server which also includes the users from LDAP\ngetent passwd\n\n# below is an example of user passwd from ldap\ntrigaud:x:3000:3000:Titouan:/home/trigaud:/bin/bash\n\n# below can show the user shadow form ldap too\ngetent shadow \n</code></pre> <p>To test authentication log in with an LDAP user, you can run below command</p> <pre><code># general form to local login\nsu - &lt;UID&gt;\n\n# for example, run below command and enter the pwd. if it's correct, \nsu - trigaud\n</code></pre> <p>To troubleshoot problems you can run <code>nslcd in debug mode</code> (remember to stop nscd when debugging). Debug mode should return a lot of information about the LDAP queries that are performed and errors that may arise.</p> <pre><code>/etc/init.d/nscd stop\n/etc/init.d/nslcd stop\nnslcd -d\n</code></pre>"},{"location":"adminsys/os_setup/security/02.Configure_ssh_pam_ldap/#for-ad-compatibility","title":"For AD compatibility","text":"<p>To use AD as authentication server, we can't use <code>nslcd</code> anymore. We need to test the <code>sssd</code> and <code>AD</code> connexion.</p>"},{"location":"adminsys/os_setup/security/03.Configure_ssh_sssd_ldap/","title":"Configure debian server ssh to use sssd","text":"<p>In </p>"},{"location":"adminsys/os_setup/security/04.Configure_ssh_pam_sssd_ad_en/","title":"Configure debian server to use AD/Krb for sshd authentication","text":"<p>In this tutorial, we show how to configure sshd, pam, sssd, to allow a <code>debian 11</code> server to use AD/Krb as  authentication server. We will follow the below steps:</p> <p>We suppose we have : - <code>AD/Krb</code> : The ip address is <code>10.50.5.64</code>, ad domain name <code>casdds.casd</code>, krb realm name <code>CASDDS.CASD</code>, hostname <code>auth</code>, fqdn is <code>auth.casdds.casd</code> - <code>debian 11</code>: ip address is <code>10.50.5.199</code>, hostname is <code>hadoop-client</code>, fqdn is <code>hadoop-client.casdds.casd</code></p>"},{"location":"adminsys/os_setup/security/04.Configure_ssh_pam_sssd_ad_en/#step-1-prerequisite","title":"Step 1: Prerequisite","text":""},{"location":"adminsys/os_setup/security/04.Configure_ssh_pam_sssd_ad_en/#11-reset-hostname-of-hadoop-client","title":"1.1 Reset hostname of hadoop-client","text":"<p>The hostname is essential for the server to have a valid FQDN in the domain, so we need to make sure the hostname is set correctly. Follow the below steps: - set system hostname - update /etc/hosts</p> <pre><code># general form\nsudo hostnamectl set-hostname &lt;custom-hostname&gt;\n\n# for example \nsudo hostnamectl set-hostname hadoop-client\n\n# check the new hostname with below command\nhostname\n\n# expected output\nhadoop-client\n</code></pre> <p>you can also directly edit the hostname config file(not recommended) by using <code>sudo vim /etc/hostname</code></p> <p>Update <code>/etc/hosts</code>:</p> <pre><code>sudo vim /etc/hosts \n\n127.0.1.1 hadoop-client.casdds.casd hadoop-client\n10.50.5.199 hadoop-client.casdds.casd   hadoop-client\n</code></pre>"},{"location":"adminsys/os_setup/security/04.Configure_ssh_pam_sssd_ad_en/#12-update-system-packages-in-hadoop-client","title":"1.2 Update system packages in hadoop-client","text":"<pre><code>sudo apt update \nsudo apt upgrade\n</code></pre>"},{"location":"adminsys/os_setup/security/04.Configure_ssh_pam_sssd_ad_en/#13-change-dns-server-settings-in-hadoop-client","title":"1.3 Change dns server settings in hadoop-client","text":"<p>To join the server into an AD domain, you must use the AD as dns server.</p> <p>Edit the <code>/etc/resolv.conf</code> :</p> <pre><code>search casdds.casd\nnameserver 10.50.5.64\nnameserver 8.8.8.8\n</code></pre>"},{"location":"adminsys/os_setup/security/04.Configure_ssh_pam_sssd_ad_en/#14-install-the-required-packages-in-hadoop-client","title":"1.4 Install the required packages in hadoop-client","text":"<pre><code>sudo apt install realmd sssd sssd-tools libnss-sss libpam-sss adcli samba-common-bin krb5-user oddjob oddjob-mkhomedir packagekit -y\n</code></pre>"},{"location":"adminsys/os_setup/security/04.Configure_ssh_pam_sssd_ad_en/#step-2-join-the-debian-serverhadoop-client-to-the-ad-domain","title":"Step 2 : Join the debian server(hadoop-client) to the AD domain","text":""},{"location":"adminsys/os_setup/security/04.Configure_ssh_pam_sssd_ad_en/#21-check-if-the-domain-can-be-reached-or-not","title":"2.1. Check if the domain can be reached or not","text":"<pre><code>realm discover CASDDS.CASD\n</code></pre> <ul> <li>If the error message is realm command is unknown, open a new shell.</li> <li>If the error message is CASDDS.CASD is unknown, check the dns server ip is reachable, and dns server name setup is correct.</li> </ul>"},{"location":"adminsys/os_setup/security/04.Configure_ssh_pam_sssd_ad_en/#22-join-the-serverhadoop-client-to-the-ad-domain","title":"2.2. Join the server(hadoop-client) to the AD domain","text":"<p>To execute the below command, you must have an account with <code>domain administrator</code> privilege :</p> <pre><code>sudo realm join --user=Administrateur CASDDS.CASD\n</code></pre> <p>If there is no error message, it means your server has joined the domain.</p>"},{"location":"adminsys/os_setup/security/04.Configure_ssh_pam_sssd_ad_en/#23-configure-the-linux-serverhadoop-client-account-in-ad","title":"2.3 Configure the linux server(hadoop-client) account in AD","text":"<p>If the <code>hadoop-client</code> has success joined the AD domain, you should see the server appears in the <code>Computer</code> section in the AD manager GUI. Check the below figure</p> <p></p> <p>To check, you need to connect to the <code>Windows Server</code> -&gt; Open <code>AD manager</code> -&gt; In <code>Users and Computers</code> subfolder of  Active Directory. You should find a line of <code>HADOOP-CLIENT</code>. Right Click on it, and select <code>properties</code>, you should see the below pop-up window</p> <p></p> <p>Select the <code>Trust this computer for delegation to any service</code> option in <code>Delegation</code>. </p> <p>Click on the <code>Static IP address</code> option in <code>Dial-in</code>, then put the address ip of the <code>hadoop-client</code>.  </p> <p>You can add a new computer in AD manually, but we don't recommend that. Try to use the <code>realm join</code></p>"},{"location":"adminsys/os_setup/security/04.Configure_ssh_pam_sssd_ad_en/#step-3-config-adkrb-dns-server-to-well-integrate-hadoop-client","title":"Step 3: Config AD/Krb, DNS server to well integrate hadoop-client","text":"<p>To make the debian server (hadoop-client) fqdn <code>recognizable</code> and <code>reachable</code> by the other servers in the domain, we need to configure the dns server </p>"},{"location":"adminsys/os_setup/security/04.Configure_ssh_pam_sssd_ad_en/#31-check-the-dns-entries-in-windows-server","title":"3.1. Check the dns entries in windows server","text":"<p>Open the <code>dns manager</code> in the Windows server (<code>auth.casdds.casd</code>). Check the forward lookup and reverse lookup. You need to make sure the <code>hostname, fqdn and ip address</code> are correct. The two below figures are examples of the <code>hadoop-client</code> config.</p> <p></p> <p></p> <p>Normally, these entries are created automatically by the <code>realm join</code> command. If they are not created correcly, you  need to create them manually.</p>"},{"location":"adminsys/os_setup/security/04.Configure_ssh_pam_sssd_ad_en/#32-check-the-spn-service-principal-name-in-windows-server","title":"3.2. Check the SPN (Service Principal Name) in Windows server","text":"<p>Every registered computer in the domain should have a <code>valid SPN (Service Principal Name)</code>. You can check the name by  using the below command. You can open a <code>powershell prompt</code> in the <code>AD/krb</code> server.</p> <pre><code>setspn -L hadoop-client\n\n# expected output\nRegistered ServicePrincipalNames for CN=HADOOP-CLIENT,CN=Computers,DC=casdds,DC=casd:\n        RestrictedKrbHost/hadoop-client.casdds.casd\n        RestrictedKrbHost/HADOOP-CLIENT\n        host/hadoop-client.casdds.casd\n        host/HADOOP-CLIENT\n</code></pre> <p>If you don't see any outputs, you can create a <code>SPN (Service Principal Name)</code> manually. Below is the command to do so.</p> <pre><code># create a new spn and link it to the hadoop-client(AD account)\n# The -S option adds an SPN only if it does not already exist (avoids duplicates).\nsetspn -S host/hadoop-client.casdds.casd hadoop-client\n\n# generate a keytab for principal  host/hadoop-client.casdds.casd@CASDDS.CASD\nktpass -princ host/hadoop-client.casdds.casd@CASDDS.CASD -mapuser HADOOP-CLIENT$ -pass * -ptype KRB5_NT_PRINCIPAL -crypto AES256-SHA1 -out hadoop-client.keytab\n</code></pre> <p>Below lines are the explanation of the commands: - The <code>ktpass</code> command can generate a keytab file for Kerberos authentication.  - <code>-princ host/hadoop-client.casdds.casd@CASDDS.CASD</code> defines the Kerberos principal name. - <code>-mapuser HADOOP-CLIENT$</code> maps the Kerberos principal to the account (HADOOP-CLIENT) in Active Directory (AD). The <code>$</code> indicates it's a computer account (not a user). - <code>-crypto AES256-SHA1</code> specifies that only the <code>AES256-SHA1</code> crypto algo is supported. You can replace it with <code>ALL</code> to specify all available cryptographic algorithms should be supported for encryption. - <code>-ptype KRB5_NT_PRINCIPAL</code> specifies the principal type as KRB5_NT_PRINCIPAL, which is used for standard Kerberos authentication(for services, use KRB5_NT_SRV_HST). - <code>-pass *</code> prompts the user to enter the password manually. Typically, computer accounts in AD have auto-generated passwords. - <code>-out hadoop-client.keytab</code> saves the keytab file, which will be used by the linux server(hadoop-client) for authentication.</p> <p>The <code>hadoop-client.keytab</code> file is copied to the hadoop-client, so it can use this keytab for Kerberos authentication. <code>hadoop-client</code> can use the kerberos ticket to prove the identity of <code>hadoop-client</code>.</p> <p>After coping the <code>hadoop-client.keytab</code> file to <code>hadoop-client</code>, you can use the below command to check keytab contents:</p> <pre><code>klist -k /tmp/hadoop-client.keytab  \n\n# you should see outputs like\n\"host/hadoop-client.casdds.casd\"\n</code></pre>"},{"location":"adminsys/os_setup/security/04.Configure_ssh_pam_sssd_ad_en/#33-rename-the-keytab-file-in-linuxhadoop-client","title":"3.3 Rename the keytab file in linux(hadoop-client)","text":"<p>In linux, many Kerberos-aware applications (e.g. kinit, Hadoop, etc.) expect the keytab file to be named <code>krb5.keytab</code>  and located in <code>/etc/</code> by default. We can use the below commands</p> <pre><code>sudo mv hadoop-client.keytab /etc/krb5.keytab\n\n# Ensures only root can read it (for security).\nsudo chmod 600 /etc/krb5.keytab\n</code></pre>"},{"location":"adminsys/os_setup/security/04.Configure_ssh_pam_sssd_ad_en/#34-leave-and-rejoin-the-realm","title":"3.4 Leave and rejoin the realm","text":"<p>If there are errors that you can't resolve, you can always leave the realm and rejoin</p> <pre><code>sudo realm leave CASDDS.CASD\n\nsudo realm join --user=Administrateur CASDDS.CASD\n</code></pre>"},{"location":"adminsys/os_setup/security/04.Configure_ssh_pam_sssd_ad_en/#35-create-a-service-account-in-ad-for-sssd-daemon","title":"3.5. Create a service account in AD for sssd daemon.","text":"<p>As we explained before, the linux server relies on <code>sssd</code> daemon to get the <code>user id and groups</code> from the AD server. This requires sssd to have an account that allows him to access AD.</p> <p>You need to create a service account <code>sssd</code> in <code>Active Directory manager</code>. Then use the below command to create a <code>principal</code> and the <code>keytab</code> file.</p> <pre><code>ktpass -princ sssd@CASDDS.CASD -mapuser sssd -crypto AES256-SHA1 -ptype KRB5_NT_PRINCIPAL -pass * -out sssd.keytab\n</code></pre> <p>Copie the keytab file to the debian server(hadoop-client):</p> <pre><code>scp sssd.keytab sssd@debian.casdds.casd:/tmp/\n</code></pre> <p>Put the keytab file in /etc</p> <pre><code>sudo cp /tmp/sssd.keytab /etc/\n# need to check the acl of the file, 644 is too open for me\nsudo chmod 644 /etc/sssd.keytab\nsudo chown root:root /etc/sssd.keytab\n</code></pre>"},{"location":"adminsys/os_setup/security/04.Configure_ssh_pam_sssd_ad_en/#step-4-configuration-of-sssd-pam-and-kerberos","title":"Step 4 : Configuration of SSSD, PAM and Kerberos","text":"<p>We will follow the below order to configure each component: - kerberos client: configure krb client to connect to the target krb Realm - sshd/pam: configure sshd server to use pam as authentication backend - pam/sssd: configure pam to use sssd as backend - sssd/krb: configure sssd to use krb plugin</p>"},{"location":"adminsys/os_setup/security/04.Configure_ssh_pam_sssd_ad_en/#41-configure-kerberos-client-in-debianhadoop-client-server","title":"4.1 Configure kerberos client in debian(hadoop-client) server","text":"<pre><code># install the required package\nsudo apt install krb5-user\n\n# edit the config file `/etc/krb5.conf`  \nsudo vim /etc/krb5.conf\n</code></pre> <p>Put the below content in the file <code>/etc/krb5.conf</code> </p> <pre><code> [libdefaults]\n        default_realm = CASDDS.CASD\n\n        default_tkt_enctypes = aes256-cts-hmac-sha1-96 aes128-cts-hmac-sha1-96\n        default_tgs_enctypes = aes256-cts-hmac-sha1-96 aes128-cts-hmac-sha1-96\n        permitted_enctypes   = aes256-cts-hmac-sha1-96 aes128-cts-hmac-sha1-96\n        kdc_timesync = 1\n        ccache_type = 4\n        forwardable = true\n        # Fadoua said this must be removed from, otherwise the ticket will not be forwad to the target host \n        # proxiable = true\n        ticket_lifetime = 24h\n        dns_lookup_realm = true\n        dns_lookup_kdc = true\n        dns_canonicalize_hostname = false\n        rdns = false\n         allow_weak_crypto = true\n\n\n[realms]\n        CASDDS.CASD = {\n                kdc = 10.50.5.64\n                admin_server = 10.50.5.64\n        }\n\u2026..\n[domain_realm]\n\u2026.\n        .casdds.casd = CASDDS.CASD\n        casdds.casd = CASDDS.CASD\n</code></pre> <p>To check the krb client, use the below command</p> <pre><code># ask a ticket kerberos\nkinit host/hadoop-client.casdds.casd\n\n# the short version should work if the keytab is in place, if not you can specify the path of keytab\nkinit -kt /etc/krb5.keytab host/hadoop-client.casdds.casd\n</code></pre>"},{"location":"adminsys/os_setup/security/04.Configure_ssh_pam_sssd_ad_en/#42-configure-sshd-to-use-pam","title":"4.2. Configure sshd to use pam","text":"<p>We need to edit two files: - <code>/etc/ssh/sshd_config</code> (configuration for the ssh server) - <code>/etc/ssh/ssh_config</code> (configuration for the ssh client)</p> <p>In <code>/etc/ssh/sshd_config</code>, enable the below lines</p> <pre><code># disable other authentication methods\nChallengeResponseAuthentication no\nPasswordAuthentication no\n\n# use pam as authentication backend\nUsePAM yes\n\n# GSSAPI options for sshd server to accept GSSAPI, it's required for the server to accept krb ticket as \n# credentials\n# \nGSSAPIAuthentication yes\n# Cleans up the Kerberos credentials after the session.\nGSSAPICleanupCredentials yes\n# Ensures that the SSH client does not strictly check for a valid acceptor name in the Kerberos tickets.\nGSSAPIStrictAcceptorCheck no\n# Allows the exchange of Kerberos keys for stronger encryption.\nGSSAPIKeyExchange yes\n\n\nX11Forwarding yes\n\nPrintMotd no\n\n\n# Allow client to pass locale environment variables\nAcceptEnv LANG LC_*\n\n# override default of no subsystems\nSubsystem       sftp    /usr/lib/openssh/sftp-server\n</code></pre> <p>You need to restart the sshd service to enable the new config </p> <pre><code>sudo systemctl restart sshd\n</code></pre> <p>In the <code>/etc/ssh/ssh_config</code>, you need to add the below line </p> <pre><code>   Host *\n       GSSAPIAuthentication yes\n       GSSAPIDelegateCredentials yes\n       PasswordAuthentication no\n</code></pre> <p>For hadoop-client, the <code>ssh_config</code> is not required, because it defines the behaviour of the ssh client. It needs to be configured in the ssh client which wants to connect to the hadoop-client ssh server. </p>"},{"location":"adminsys/os_setup/security/04.Configure_ssh_pam_sssd_ad_en/#43-configure-pam","title":"4.3 Configure pam","text":"<p>All the configuration files for pam are located in <code>/etc/pam.d/</code>. The below is the minimum config for the pam to use sssd daemon as authentication backend.</p> <pre><code>### /etc/pam.d/common-auth\nsudo: unable to resolve host debian118: Name or service not known\nauth      sufficient  pam_unix.so try_first_pass\nauth      sufficient  pam_sss.so use_first_pass\nauth      required    pam_deny.so\n</code></pre> <pre><code>### /etc/pam.d/common-account\nsudo: unable to resolve host debian118: Name or service not known\naccount   required    pam_unix.so\naccount   sufficient  pam_sss.so\naccount   required    pam_permit.so\n</code></pre> <pre><code>### /etc/pam.d/common-password\nsudo: unable to resolve host debian118: Name or service not known\npassword  sufficient  pam_unix.so\npassword  sufficient  pam_sss.so\npassword  required    pam_deny.so\n</code></pre> <pre><code>### /etc/pam.d/common-session\nsudo: unable to resolve host debian118: Name or service not known\nsession   required    pam_unix.so\nsession   optional    pam_sss.so\nsession   required    pam_mkhomedir.so skel=/etc/skel/ umask=0022\n</code></pre>"},{"location":"adminsys/os_setup/security/04.Configure_ssh_pam_sssd_ad_en/#44-configure-sssd","title":"4.4 Configure sssd","text":"<p>Now we need to configure the sssd daemon. The main config file is in <code>/etc/sssd/sssd.conf</code></p> <pre><code>[sssd]\nservices = nss, pam\ndomains = casdds.casd\nconfig_file_version = 2\n\n[nss]\nhomedir_substring = /home\n\n[pam]\n\n[domain/casdds.casd]\nldap_sasl_authid = sssd@CASDDS.CASD\nkrb5_keytab = /etc/sssd.keytab\ndefault_shell = /bin/bash\nkrb5_store_password_if_offline = True\ncache_credentials = True\nkrb5_realm = CASDDS.CASD\nrealmd_tags = manages-system joined-with-adcli\nid_provider = ad\nfallback_homedir = /home/%u@%d\nad_domain = casdds.casd\nuse_fully_qualified_names = False\nldap_id_mapping = True\naccess_provider = ad\nldap_group_nesting_level = 2\n</code></pre>"},{"location":"adminsys/os_setup/security/04.Configure_ssh_pam_sssd_ad_en/#5configure-ssh-client-on-windows","title":"5.configure ssh client on Windows","text":"<p>In windows, there are many ssh clients: - MobaXterm: - tabby: https://tabby.sh/ - powershell+openssh - PuTTY</p> <p>Below is the instruction on how to install and configure openssh via PowerShell</p> <pre><code>Add-WindowsCapability -Online -Name OpenSSH.Client~~~~0.0.1.0\nAdd-WindowsCapability -Online -Name OpenSSH.Server~~~~0.0.1.0\nStart-Service sshd\nSet-Service -Name sshd -StartupType 'Automatic'\n</code></pre> <p>In windows, all the configuration file for openssh is located in <code>C:\\ProgramData\\ssh</code> If you want to setup the config for ssh server, you can edit the file in <code>C:\\ProgramData\\ssh\\sshd_config</code>.</p> <p>To restart ssh service in windows</p> <pre><code># start sshd service\nStart-Service sshd\n\n# restart sshd service \nRestart-Service sshd\n</code></pre> <p>Configure ssh client </p> <pre><code># open a notepad\nnotepad $env:USERPROFILE\\.ssh\\config\n\n# add the below lines\n# * means for all hosts\nHost *\n    GSSAPIAuthentication yes\n    GSSAPIDelegateCredentials yes \n</code></pre> <p>You can also define the behaviors host by host, below is an example</p> <pre><code>Host hadoop-client\n    HostName hadoop-client.casdds.casd\n    User pengfei@casdds.casd\n    Port 22\n    GSSAPIAuthentication yes\n    GSSAPIDelegateCredentials yes \n</code></pre>"},{"location":"adminsys/os_setup/security/04.Configure_ssh_pam_sssd_ad_en/#step-6-test-the-solution","title":"Step 6 : Test the solution","text":"<p>In our scenario, the user follow the below steps: 1. first login to a Windows server, the first ticket kerberos is generated in the Windows server. 2. user ssh to hadoop-client with the ticket kerberos with option forward ticket 3. user try to access hdfs cluster with the forward kerberos ticket</p> <p>Suppose you have an account <code>user</code> in AD with the privilege to connect to <code>hadoop client</code>  \\</p>"},{"location":"adminsys/os_setup/security/04.Configure_ssh_pam_sssd_ad_en/#61-understand-the-ticket","title":"6.1. Understand the ticket","text":"<p>In linux, you can ask a ticket and check the ticket with the below command</p> <pre><code># ask a new ticket, you need to provide a password associated with the provided principal\nkinit user@CASDDS.CASD  \n\n# check the ticket contents\nklist -5fea   \n</code></pre> <p>The option: - 5: Show only Kerberos 5 tickets (modern Kerberos version). - f: Show ticket flags (like FORWARDABLE, RENEWABLE, etc.). - e: Display encryption type used for the ticket. - a Show addresses associated with the ticket (if address-restriction of the ticket is activated).</p> <p>You should see the below output as the ticket content</p> <pre><code>Ticket cache: FILE:/tmp/krb5cc_1000\nDefault principal: user@CASDDS.CASD\n\nValid starting       Expires              Service principal\n03/31/25 10:00:00  03/31/25 20:00:00  krbtgt/CASDDS.CASD@CASDDS.CASD\n        Flags: FRI\n        Etype (skey, tkt): aes256-cts-hmac-sha1-96, aes256-cts-hmac-sha1-96\n        Addresses: 192.168.1.100\n</code></pre> <p>A kerberos ticket has the below properites:</p> <ul> <li>Ticket cache: Location of the ticket. </li> <li>Default principal: Your Kerberos identity (user@EXAMPLE.COM).</li> <li>Valid starting / Expires: Time range for which the ticket is valid.</li> <li>Service principal: The Kerberos service this ticket is for. (krbtgt/CASDDS.CASD@CASDDS.CASD is a tgt issued by CASDDS.CASD the kdc server)</li> <li>Flags (-f option): F = Forwardable (Can be forwarded to another machine). R = Renewable (Can be extended before expiration). I = Initial (Freshly obtained).</li> <li>Encryption type (-e option): aes256-cts-hmac-sha1-96, means AES-256 encryption with SHA-1 HMAC.</li> <li>Addresses (-a option): Shows the IP addresses associated with the ticket (if address-restricted).</li> </ul> <p>You can ask ticket with special options:</p> <pre><code># below command ask a Forwardable, Renewable for a 7 day validity\nkinit -f -r 7d\n</code></pre> <p>Based on the kdc configuration, it may or may not generate the ticket.</p>"},{"location":"adminsys/os_setup/security/04.Configure_ssh_pam_sssd_ad_en/#62-connexion-ssh","title":"6.2. Connexion SSH","text":"<p>From windows, if the server has joined the domain, windows will generate a kerberos ticket after user logon:</p> <pre><code># check the user ticket\nklist -5fea\n\n# for windows ssh client\n# -K active la d\u00e9l\u00e9gation Kerberos\nssh -K user@debian.casdds.casd  \n\n# for linux ssh client\nssh -o GSSAPIDelegateCredentials=yes user@debian.casdds.casd\n</code></pre>"},{"location":"adminsys/os_setup/security/04.Configure_ssh_pam_sssd_ad_en/#appendix","title":"Appendix :","text":""},{"location":"adminsys/os_setup/security/04.Configure_ssh_pam_sssd_ad_en/#acl-for-etcsssdsssdconf","title":"ACL for /etc/sssd/sssd.conf","text":"<p>The Permissions for <code>/etc/sssd/sssd.conf</code> must be <code>600</code> :</p> <pre><code>sudo chmod 600 /etc/sssd/sssd.conf\n</code></pre>"},{"location":"adminsys/os_setup/security/05.Static_uid_gid_integration_in_sssd/","title":"Configure sssd to use static uid, gid","text":"<p>POSIX (Portable Operating System Interface) is <code>UNIX/Linux standards for identity and access control</code>. A <code>POSIX</code>  account use specific attributes such as - uidNumber \u2013 Unique User ID (UID) - gidNumber \u2013 Primary Group ID (GID) - homeDirectory \u2013 User's home directory path  - loginShell \u2013 The default shell (e.g., /bin/bash)</p> <p>These attributes allow UNIX/Linux systems to recognize, authenticate users, and create user workspace.</p> <p>By default, AD does not use POSIX attributes for user and group.  Instead, AD relies on:</p> <ul> <li>Security Identifiers (SIDs): Every user and group has a <code>SID</code>, which is a unique identifier in Windows.</li> <li><code>sAMAccountName</code>: pliu (This is legacy login, )</li> <li>UserPrincipalName (UPN): pliu@casd.eu (authentication in modern windows server)</li> </ul>"},{"location":"adminsys/os_setup/security/05.Static_uid_gid_integration_in_sssd/#1-default-behavior-when-sssd-uses-ad-as-authentication-backend","title":"1. Default behavior when sssd uses AD as authentication backend","text":"<p>The default behavior in <code>SSSD</code> and <code>Winbind</code> is to use <code>auto id mapping</code>. SSSD will dynamically generate UIDs and GIDs from the <code>AD objects's ObjectSID</code>. This will lead to inconsistent UIDs and GIDs across machines.</p> <p>In certain scenarios, it will create conflicting ACL in user home. For example, if a user with AD account with name <code>test</code> login to a linux server, a user home will be created <code>/home/test</code>. If the user account is deleted, and a new account <code>test</code> is created, when the new <code>test</code> user login to the linux server, it will user /home/test as home dir too. But the new and old <code>test</code> will have different uid. So the old files in /home/test will have old uid as owner, the new  <code>test</code> user can't access it. </p> <p>To avoid inconsistent UIDs and GIDs, we recommend you to use static uidNumber and gidNumber.</p>"},{"location":"adminsys/os_setup/security/05.Static_uid_gid_integration_in_sssd/#2-configure-sssd-to-user-static-uidnumber-and-gidnumber","title":"2. Configure sssd to user static uidNumber and gidNumber.","text":"<p>To configure sssd to user static uidNumber and gidNumber, follow the below steps 1. Add posix attributes in AD 2. Configure sssd to read posix attributes</p>"},{"location":"adminsys/os_setup/security/05.Static_uid_gid_integration_in_sssd/#21-adds-posix-attributes-in-ad","title":"2.1 Adds posix attributes in AD","text":"<p>If SSSD wants to use static uidNumber and gidNumber, the AD server must have those attributes. Before Windows server 2016. The AD server can use <code>rfc2307</code> schema, which allows us to create posix compatible user  accounts and groups. This feature has been removed since <code>Windows server 2016</code>. But you can still add attributes such as <code>uidNumber</code>, <code>gidNumber</code> to a user account or group. </p> <p>Open <code>AD users and groups gui</code>-&gt; on the toolbar, click on <code>view</code>-&gt; Select <code>advance features</code> -&gt; now when you double-click on  a user account, you will see a tab called </p> <p></p> <p></p> <p>The official doc can be found here.</p>"},{"location":"adminsys/os_setup/security/05.Static_uid_gid_integration_in_sssd/#22-configure-sssd-to-read-posix-attributes","title":"2.2 Configure sssd to read posix attributes","text":"<p>Before changing your sssd configuration, make sure <code>AD Objects have gidNumber and uidNumber Attributes</code>.</p>"},{"location":"adminsys/os_setup/security/05.Static_uid_gid_integration_in_sssd/#221-for-ad-windows-server-2016","title":"2.2.1 For AD &lt; Windows server 2016.","text":"<p>Configure the AD server to use <code>rfc2307</code> schema, and create posix compatible accounts and groups. Then add the below  conf in <code>/etc/sssd/sssd.conf</code></p> <pre><code>[domain/YOURDOMAIN]\nid_provider = ad\naccess_provider = ad\nldap_id_mapping = False\nldap_schema = rfc2307\n</code></pre>"},{"location":"adminsys/os_setup/security/05.Static_uid_gid_integration_in_sssd/#221-for-ad-windows-server-2016_1","title":"2.2.1 For AD &gt;= Windows server 2016.","text":"<p>Add the below conf in <code>/etc/sssd/sssd.conf</code></p> <pre><code>[domain/YOURDOMAIN]\nid_provider = ad\naccess_provider = ad\nldap_id_mapping = False  # Important: Forces usage of uidNumber/gidNumber\nldap_user_uid_number = uidNumber\nldap_user_gid_number = gidNumber\nldap_group_gid_number = gidNumber\nenumerate = True  # Optional: Lists all users and groups\n</code></pre>"},{"location":"adminsys/os_setup/security/05.Static_uid_gid_integration_in_sssd/#23-restart-sssd-and-check-uid-gid","title":"2.3 Restart sssd and check uid, gid","text":"<pre><code># restart sssd\nsystemctl restart sssd\n# clear sssd cache\nsss_cache -E\n\n# check user id and groups\nid &lt;uid&gt;\n\n# you should see the output id value matches the value which you deined in AD\n\n# check group id\ngetent group &lt;groupname&gt;\n</code></pre>"},{"location":"adminsys/os_setup/security/06.Configure_ssh_sssd_kerberos_linux/","title":"Configure debian server sshd auth with pam, sssd, kerberos","text":"<p>There is a complete tutorial on how to setup openldap, kerberos for unified authentication. You can visit this website.</p> <p>In this tutorial, we show a scenario light compares to the architecture which shows in the above tutorial.  We don't use the <code>SASL/GSSAPI</code> to delegate user password check to kerberos.</p> <p>It means, in the below tutorial, user has a password in openldap, and a password in kerberos, which are not synchronized automatically. The user id does the link of user between openldap and kerberos.</p> <p>Suppose we have a ldap and kerberos server running on <code>10.50.5.200</code> with url as <code>krb.casd.local</code>.</p> <p>suppose we have three servers: - krb.casd.local: server hosts openldap and kerberos (can be replaced by AD/kerberos) - ssh-server.casd.local: server runs sshd server which uses pam, sssd, sssd-krb5 to check user authentication - ssh-client.casd.local: a vm runs an ssh client and krb5-client, user can get a kerberos ticket, and use this ticket to ssh                            into the ssh-server.casd.local</p> <p>The full authentication process: 1. user get a kerberos ticket (kinit ) (in ssh-client.casd.local) 2. user init an ssh connection with the cached kerberos ticket(ssh uid@ssh-server.casd.local) (in ssh-client.casd.local) 3. ssh-server receives the ssh connection requests (sshd config checks all the possible authentication methods) (in ssh-server.casd.local) 4. <code>sshd</code> delegate the authentication to <code>pam</code>(<code>UsePAM yes in sshd_config</code>), <code>pam</code> delegate to <code>sssd</code>, <code>sssd</code> delegate to <code>sssd-krb5</code>. Because we set <code>auth_provider</code>       as <code>krb5</code> in <code>sssd</code>. (in ssh-server.casd.local) 5. <code>sssd-krb5</code> sends a request to <code>krb.casd.local</code> to verify the authenticity of the kerberos ticket. This steps requires <code>ssh-server.casd.local</code>     has a valid principal in <code>krb.casd.local</code> (in ssh-server.casd.local) 6. <code>krb.casd.local</code> verify the ticket and send the result back to <code>ssh-server.casd.local</code>. (in krb.casd.local) 7. <code>sssd-krb5</code> in <code>ssh-server.casd.local</code> receives the result, if ok, it will ask the <code>id_provider</code> of the <code>sssd</code>,        in our case it's <code>openldap</code> to get <code>uid</code> and <code>gid</code> of the user with the uid of the kerberos ticket. The user       <code>uid</code> and <code>gid</code> information will be transfer to <code>nss</code>. <code>sssd</code> tells pam it's ok, <code>pam</code> tells sshd it's ok.      Then pam will create a user session in the server after user login. (in ssh-server.casd.local) 8. user will get a terminal on <code>ssh-server.casd.local</code> with uid and gids from the <code>openldap</code> account."},{"location":"adminsys/os_setup/security/06.Configure_ssh_sssd_kerberos_linux/#1-configure-and-test-krb-client-on-ssh-clientcasdlocal-and-ssh-servercasdlocal","title":"1. Configure and test krb client on ssh-client.casd.local and ssh-server.casd.local","text":"<p>We need to install the kerberos client on both servers: - ssh-client.casd.local - ssh-server.casd.local</p>"},{"location":"adminsys/os_setup/security/06.Configure_ssh_sssd_kerberos_linux/#11-install-the-required-packages","title":"1.1 Install the required packages","text":"<pre><code># krb client package\nsudo apt install krb5-user\n</code></pre>"},{"location":"adminsys/os_setup/security/06.Configure_ssh_sssd_kerberos_linux/#12-configure-the-krb-client","title":"1.2 Configure the krb client","text":"<pre><code>sudo vim /etc/krb5.conf\n\n# add the below content\n[libdefaults]\n    default_realm = CASD.LOCAL\n\n# The following krb5.conf variables are only for MIT Kerberos.\n    kdc_timesync = 1\n    ccache_type = 4\n    forwardable = true\n    proxiable = true\n        rdns = false\n\n\n# The following libdefaults parameters are only for Heimdal Kerberos.\n    fcc-mit-ticketflags = true\n\n[realms]\n    CASD.LOCAL = {\n        kdc = krb.casd.local\n        admin_server = krb.casd.local\n    }\n\n\n[domain_realm]\n        casd.local = CASD.LOCAL\n        .casd.local = CASD.LOCAL\n</code></pre>"},{"location":"adminsys/os_setup/security/06.Configure_ssh_sssd_kerberos_linux/#13-test-the-client","title":"1.3 Test the client","text":"<pre><code># generate a ticket, the principal must exist in the krb server\nkinit pliu@CASD.LOCAL\n\n# normally, you can view the ticket\nklist\n\n# clean the ticket\nkdestory\n</code></pre>"},{"location":"adminsys/os_setup/security/06.Configure_ssh_sssd_kerberos_linux/#2-config-sshd-pam-sssd-on-ssh-servercasdlocal","title":"2. Config sshd, pam, sssd on ssh-server.casd.local","text":""},{"location":"adminsys/os_setup/security/06.Configure_ssh_sssd_kerberos_linux/#21-install-required-packages","title":"2.1 Install required packages","text":"<pre><code>sudo apt install sssd sssd-tools libnss-sss libpam-sss libpam-mkhomedir\n</code></pre> <ul> <li>sssd: package for daemon sssd((System Security Services Daemon))</li> <li>sssd-tools: provides command-line utilities for managing and troubleshooting SSSD</li> <li>nss: NSS (Name Service Switch) is a subsystem in Linux and Unix-like systems that allows applications           to retrieve information about users, groups, hosts, networks, services, and more from various           sources (like /etc/passwd, LDAP, NIS, or SSSD). By default, this daemon is running on a debian server,           no need to install the package. The main config is in <code>/etc/nsswitch.conf</code></li> <li>libnss-sss: This daemon allows <code>nss</code> to retrieve user information from <code>sssd</code></li> <li>libpam-sss: This daemon allows <code>pam</code> to use <code>sssd</code> as an authentication mechanism. </li> <li>libpam-mkhomedir: This daemon allows <code>pam</code> to create home dir for newly connected users.</li> </ul>"},{"location":"adminsys/os_setup/security/06.Configure_ssh_sssd_kerberos_linux/#22-configure-sshd-to-use-pam-as-an-authentication-mechanism","title":"2.2 Configure sshd to use pam as an authentication mechanism","text":"<pre><code>Include /etc/ssh/sshd_config.d/*.conf\n\n#Port 22\n#AddressFamily any\n#ListenAddress 0.0.0.0\n#ListenAddress ::\n\n#HostKey /etc/ssh/ssh_host_rsa_key\n#HostKey /etc/ssh/ssh_host_ecdsa_key\n#HostKey /etc/ssh/ssh_host_ed25519_key\n\n# Ciphers and keying\n#RekeyLimit default none\n\n# Logging\n#SyslogFacility AUTH\n#LogLevel INFO\n\n# Authentication:\n\n#LoginGraceTime 2m\n#PermitRootLogin prohibit-password\n#StrictModes yes\n#MaxAuthTries 6\n#MaxSessions 10\n\n#PubkeyAuthentication yes\n\n# Expect .ssh/authorized_keys2 to be disregarded by default in future.\n#AuthorizedKeysFile .ssh/authorized_keys .ssh/authorized_keys2\n\n#AuthorizedPrincipalsFile none\n\n#AuthorizedKeysCommand none\n#AuthorizedKeysCommandUser nobody\n\n# For this to work you will also need host keys in /etc/ssh/ssh_known_hosts\n#HostbasedAuthentication no\n# Change to yes if you don't trust ~/.ssh/known_hosts for\n# HostbasedAuthentication\n#IgnoreUserKnownHosts no\n# Don't read the user's ~/.rhosts and ~/.shosts files\n#IgnoreRhosts yes\n\n# To disable tunneled clear text passwords, change to no here!\n#PasswordAuthentication yes\n#PermitEmptyPasswords no\n\n# Change to yes to enable challenge-response passwords (beware issues with\n# some PAM modules and threads)\nChallengeResponseAuthentication no\n#AuthenticationMethods gssapi-with-mic,password\n\n# Kerberos options\n# KerberosAuthentication yes\n# KerberosOrLocalPasswd yes\n# KerberosTicketCleanup yes\n# KerberosGetAFSToken yes\n#UseDNS yes\n# GSSAPI options\nGSSAPIAuthentication yes\nGSSAPICleanupCredentials yes\nGSSAPIStrictAcceptorCheck no\n#GSSAPIKeyExchange no\nAllowTcpForwarding yes\nAllowAgentForwarding yes\nGssapiKeyExchange yes\n# Set this to 'yes' to enable PAM authentication, account processing,\n# and session processing. If this is enabled, PAM authentication will\n# be allowed through the ChallengeResponseAuthentication and\n# PasswordAuthentication.  Depending on your PAM configuration,\n# PAM authentication via ChallengeResponseAuthentication may bypass\n# the setting of \"PermitRootLogin without-password\".\n# If you just want the PAM account and session checks to run without\n# PAM authentication, then enable this but set PasswordAuthentication\n# and ChallengeResponseAuthentication to 'no'.\nUsePAM yes\nUseDNS yes\n#AllowAgentForwarding yes\n#AllowTcpForwarding yes\n#GatewayPorts no\nX11Forwarding yes\n#X11DisplayOffset 10\n#X11UseLocalhost yes\n#PermitTTY yes\nPrintMotd no\n#PrintLastLog yes\n#TCPKeepAlive yes\n#PermitUserEnvironment no\n#Compression delayed\n#ClientAliveInterval 0\n#ClientAliveCountMax 3\n#UseDNS no\n#PidFile /var/run/sshd.pid\n#MaxStartups 10:30:100\n#PermitTunnel no\n#ChrootDirectory none\n#VersionAddendum none\nPermitRootLogin yes\n#PasswordAuthentication yes\n\n# no default banner path\n#Banner none\n\n# Allow client to pass locale environment variables\nAcceptEnv LANG LC_*\n\n# override default of no subsystems\nSubsystem   sftp    /usr/lib/openssh/sftp-server\n\n# Example of overriding settings on a per-user basis\n#Match User anoncvs\n#   X11Forwarding no\n#   AllowTcpForwarding no\n#   PermitTTY no\n#   ForceCommand cvs server\n</code></pre> <p>In the above conf, you can notice that I have two authentication methods: <code>GSSAPI</code> and <code>PAM</code>. Here <code>GSSAPI</code> is used to allow user to submit his ticket kerberos to sshd server. The sssd-krb5 can only support user login and password auth via kerberos. </p>"},{"location":"adminsys/os_setup/security/06.Configure_ssh_sssd_kerberos_linux/#23-configure-pam-to-use-sssd","title":"2.3 configure pam to use sssd","text":"<p><code>pam</code> has a list of configuration files(located in <code>/etc/pam.d/</code>): - common-auth: user authentication  - common-account: User account management - common-password: Allow user to modify password. - common-session: user session settings</p>"},{"location":"adminsys/os_setup/security/06.Configure_ssh_sssd_kerberos_linux/#231-common-auth","title":"2.3.1 common-auth","text":"<p>The simplest config example :</p> <pre><code>auth      sufficient  pam_unix.so\nauth      sufficient  pam_sss.so use_first_pass\nauth      required    pam_deny.so\n</code></pre> <p>pam_unix.so: Uses local account to authenticate users pam_sss.so use_first_pass: Uses SSSD as first method to authenticate users. pam_deny.so: Denies access if all the above authentication method fails. pam_permit.so: Allows authentication if all previous steps succeed.</p>"},{"location":"adminsys/os_setup/security/06.Configure_ssh_sssd_kerberos_linux/#232-common-account","title":"2.3.2 common-account","text":"<p>This controls how the user account can interact with the system.  Below is a simple config example. </p> <pre><code>account   required    pam_unix.so\naccount   sufficient  pam_sss.so\naccount   required    pam_permit.so\n</code></pre> <p>don't add <code>account requisite  pam_deny.so</code> in the config, otherwise you can no longer become root with sudoers right.</p>"},{"location":"adminsys/os_setup/security/06.Configure_ssh_sssd_kerberos_linux/#233-common-password","title":"2.3.3 common-password:","text":"<p>Allow user to modify password.</p> <pre><code>password  sufficient  pam_unix.so nullok md5 shadow use_authtok\npassword  sufficient  pam_sss.so try_first_pass\npassword  required    pam_deny.so\n</code></pre> <p>This configuration is not enough for user to change password. You need to change sssd, ldap/kerberos config to  allow users to change their passwords through sssd, Kerberos/LDAP.</p>"},{"location":"adminsys/os_setup/security/06.Configure_ssh_sssd_kerberos_linux/#234-common-session","title":"2.3.4 common-session","text":"<pre><code>session   required    pam_unix.so\nsession   optional    pam_sss.so\nsession   required    pam_mkhomedir.so skel=/etc/skel/ umask=0022\n</code></pre> <p>pam_mkhomedir.so: Create a home directory on first login if it doesn\u2019t exist with umask=0022. pam_sss.so: Ensures SSSD session modules are applied.</p>"},{"location":"adminsys/os_setup/security/06.Configure_ssh_sssd_kerberos_linux/#24-configure-nss","title":"2.4 Configure NSS","text":"<p>Ensure SSSD is used for user and group lookup.</p> <p>The NSS (Name Service Switch) main config is located at <code>/etc/nsswitch.conf</code>:</p> <p>The following config is a simple example tells Linux to check both local files (/etc/passwd) and SSSD for user information.</p> <pre><code>sudo vim /etc/nsswitch.conf\n\npasswd:         files sss\ngroup:          files sss\nshadow:         files sss\n</code></pre>"},{"location":"adminsys/os_setup/security/06.Configure_ssh_sssd_kerberos_linux/#25-configure-sssd","title":"2.5 Configure sssd","text":"<p>The <code>sssd</code> can query ldap/kerberos, AD/kerberos to check user authenticity(auth_provider), query ldap, or AD to get user id, groups, etc(id_provider).</p> <p><code>sssd</code> also allows user to change password of the backend(e.g. ldap, krb)</p> <pre><code>[sssd]\nservices = nss, pam, ssh\ndomains = casd.local\nconfig_file_version = 2\n\n[domain/casd.local]\nid_provider = ldap\nldap_uri = ldap://krb.casd.local\nldap_search_base = dc=casd,dc=local\n\nauth_provider = krb5\nchpass_provider = krb5\nkrb5_realm = CASD.LOCAL\nkrb5_server = krb.casd.local\nkrb5_kpasswd = krb.casd.local\ndebug_level = 5\nkrb5_validate = true\nkrb5_ccachedir = /var/tmp # note that RHEL-7 default to KERNEL ccaches, which are preferred in most cases to FILE\nkrb5_keytab = /etc/krb5.keytab\ncache_credentials = true\n\noverride_homedir = /home/%u\ndefault_shell = /bin/bash\n\n\n[nss]\nhomedir_substring = /home\n\n[pam]\n</code></pre> <p>You need to restart the daemon <code>sssd</code>, after modifying the <code>sssd.conf</code></p> <pre><code>sudo systemctl restart sssd\n</code></pre>"},{"location":"adminsys/os_setup/security/06.Configure_ssh_sssd_kerberos_linux/#251-debug-sssd-by-using-sssd-tools","title":"2.5.1 debug sssd by using sssd-tools","text":"<p>You need the admin right to run this command, otherwise you will get <code>command not found</code> error message. You can view the documentation of the tool with <code>sudo sssctl</code>.</p>"},{"location":"adminsys/os_setup/security/06.Configure_ssh_sssd_kerberos_linux/#check-the-validity-of-the-sssd-config","title":"Check the validity of the sssd config","text":"<pre><code>sudo sssctl config-check\n\n# output\nIssues identified by validators: 0\n\nMessages generated during configuration merging: 0\n\nUsed configuration snippet files: 0\n</code></pre>"},{"location":"adminsys/os_setup/security/06.Configure_ssh_sssd_kerberos_linux/#list-all-available-domain-configured-in-sssd","title":"list all available domain configured in sssd","text":"<pre><code>sudo sssctl domain-list\n\n# output example\ncasd.local\n</code></pre>"},{"location":"adminsys/os_setup/security/06.Configure_ssh_sssd_kerberos_linux/#check-the-status-of-a-domain","title":"check the status of a domain","text":"<pre><code>sudo sssctl domain-status casd.local\n\n# output example\nOnline status: Online\nActive servers:\nKPASSWD: krb.casd.local\nKERBEROS: krb.casd.local\nLDAP: krb.casd.local\nDiscovered KPASSWD servers:\n- krb.casd.local\nDiscovered KERBEROS servers:\n- krb.casd.local\nDiscovered LDAP servers:\n- krb.casd.local\n</code></pre>"},{"location":"adminsys/os_setup/security/06.Configure_ssh_sssd_kerberos_linux/#check-the-status-of-a-user","title":"check the status of a user","text":"<pre><code>sudo sssctl user-checks pengfei\n\n# output example\nuser: pengfei\naction: acct\nservice: system-auth\n\nSSSD nss user lookup result:\n - user name: pengfei\n - user id: 3002\n - group id: 4000\n - gecos: pengfei\n - home directory: /home/pengfei\n - shell: /bin/bash\n\nSSSD InfoPipe user lookup result:\n - name: pengfei\n - uidNumber: 3002\n - gidNumber: 4000\n - gecos: pengfei\n - homeDirectory: /home/pengfei\n - loginShell: /bin/bash\n\ntesting pam_acct_mgmt\n\npam_acct_mgmt: Success\n\nPAM Environment:\n - no env -\n</code></pre>"},{"location":"adminsys/os_setup/security/06.Configure_ssh_sssd_kerberos_linux/#252-clear-sssd-cache","title":"2.5.2 Clear sssd cache","text":"<p>Use the below command to clear SSSD cache, if SSSD is using outdated credentials.</p> <pre><code>sss_cache -E   # Clear all cached entries\nsss_cache -u username  # Clear cache for a specific user\nsss_cache -g groupname  # Clear cache for a specific group\n</code></pre>"},{"location":"adminsys/os_setup/security/06.Configure_ssh_sssd_kerberos_linux/#26-create-service-principals-for-kerberos-authentication","title":"2.6 Create service principals for kerberos authentication","text":"<p>sssd-krb5 requires a service principal to be able to talk with the kerberos server. So we need to create a service account(principal) for <code>ssh-server.casd.local</code> to be able to access <code>krb.casd.local</code></p> <p>In <code>ssh-server.casd.local</code>, run the below command</p> <pre><code># connect to krb server via kadmin. The principal which you use to connect to the admin console \n# must has the admin rights in krb server\nsudo kadmin -p admin/admin@CASD.LOCAL\n\n# you should see the below terminal\nkadmin:\n\n# create a principal with a generated password for the ssh-server\nkadmin:  addprinc -randkey auth-agent/sssd-test.casd.local@CASD.LOCAL\n\n# export the principal with encrypted password to the default keytab\nkadmin:  ktadd auth-agent/sssd-test.casd.local@CASD.LOCAL\n\n# exit the kadmin shell\nquit\n\n# check the principal in the keytab\nsudo klist -k /etc/krb5.keytab\n\n# short version\nsudo klist -ke\n</code></pre> <p>if your principal does not have admin rights, you can edit the <code>/etc/krb5kdc/kadm5.acl</code> file to grant admin rights to certain principals</p> <p>The below file is an example. One common way to set up Kerberos administration is to <code>allow any principal   ending in /admin is given full administrative rights.</code></p> <pre><code># To enable this, uncomment the following line:\n*/admin *\n</code></pre>"},{"location":"adminsys/os_setup/security/06.Configure_ssh_sssd_kerberos_linux/#27-test-ssh-connexions","title":"2.7 Test ssh connexions","text":"<pre><code># on the ssh-server, you can already check if the pam, sssd, openldap config\ngetent passwd username\n\n# on the ssh-client, \nssh uid@ssh-server.casd.local\n</code></pre>"},{"location":"adminsys/os_setup/security/fr/02.Configure_ssh_pam_sssd_ad_fr/","title":"Guide pour int\u00e9grer une machine Debian 11 \u00e0 un domaine Active Directory et configurer SSH avec GSSAPI/Kerberos","text":"<p>In this tutorial, we show how to join a <code>debian 11</code> server </p>"},{"location":"adminsys/os_setup/security/fr/02.Configure_ssh_pam_sssd_ad_fr/#etape-1-preparation-de-la-machine-debian","title":"\u00c9tape 1 : Pr\u00e9paration de la machine Debian","text":""},{"location":"adminsys/os_setup/security/fr/02.Configure_ssh_pam_sssd_ad_fr/#11-renommer-la-machine","title":"1.1 Renommer la machine","text":"<p>Modifier le nom d'h\u00f4te selon la politique de l'entreprise :</p> <pre><code>sudo nano /etc/hostname  # Exemple : debian.casdds.casd\nsudo hostnamectl set-hostname \"nouveau_nom\"\n</code></pre> <p>Metter \u00e0 jour <code>/etc/hosts</code> pour inclure le nom et l'IP statique :</p> <pre><code>sudo nano /etc/hosts  # Ajouter : 10.50.5.X   debian.casdds.casd\n</code></pre>"},{"location":"adminsys/os_setup/security/fr/02.Configure_ssh_pam_sssd_ad_fr/#12-mise-a-jour-du-systeme","title":"1.2 Mise \u00e0 jour du syst\u00e8me","text":"<pre><code>sudo apt update \n</code></pre>"},{"location":"adminsys/os_setup/security/fr/02.Configure_ssh_pam_sssd_ad_fr/#13-configurer-le-dns-sur-debian","title":"1.3 Configurer le DNS sur Debian","text":"<p>D\u00e9finir le serveur DNS AD dans <code>/etc/resolv.conf</code> :</p> <pre><code>search casdds.casd\nnameserver 10.50.5.64\nnameserver 8.8.8.8\n</code></pre>"},{"location":"adminsys/os_setup/security/fr/02.Configure_ssh_pam_sssd_ad_fr/#14-installer-les-paquets-necessaires","title":"1.4 Installer les paquets n\u00e9cessaires","text":"<pre><code>sudo apt install realmd sssd sssd-tools libnss-sss libpam-sss adcli samba-common-bin krb5-user oddjob oddjob-mkhomedir packagekit -y\n</code></pre>"},{"location":"adminsys/os_setup/security/fr/02.Configure_ssh_pam_sssd_ad_fr/#etape-2-joindre-le-domaine-active-directory","title":"\u00c9tape 2 : Joindre le domaine Active Directory","text":""},{"location":"adminsys/os_setup/security/fr/02.Configure_ssh_pam_sssd_ad_fr/#21-decouvrir-le-domaine","title":"2.1. D\u00e9couvrir le domaine","text":"<p>V\u00e9rifier la connectivit\u00e9 avec le contr\u00f4leur de domaine :</p> <pre><code>realm discover CASDDS.CASD\n</code></pre>"},{"location":"adminsys/os_setup/security/fr/02.Configure_ssh_pam_sssd_ad_fr/#22-rejoindre-le-domaine","title":"2.2. Rejoindre le domaine","text":"<p>Utiliser un compte administrateur AD :</p> <pre><code>sudo realm join --user=Administrateur CASDDS.CASD\n</code></pre> <p>A ce stade, mon client Debian a bien rejoint mon domaine et appara\u00eet dans la console Utilisateurs et Ordinateurs Active Directory de mon serveur Windows. S\u2019il n\u2019apparait pas, on peut l\u2019ajouter manuellement dans Ordinateurs en s\u00e9lectionne l\u2019@ip static et d\u00e9l\u00e9gation kerberos </p> <p>{{:datascience:admin_system:linux:capture1.png?400|}} {{:datascience:admin_system:linux:capture2.png?400|}}</p>"},{"location":"adminsys/os_setup/security/fr/02.Configure_ssh_pam_sssd_ad_fr/#etape-3-configuration-dns-et-kerberos","title":"\u00c9tape 3 : Configuration DNS et Kerberos","text":""},{"location":"adminsys/os_setup/security/fr/02.Configure_ssh_pam_sssd_ad_fr/#31-ajouter-lenregistrement-dns-sur-windows","title":"3.1. Ajouter l'enregistrement DNS sur Windows","text":"<p>Dans le serveur DNS Windows :</p> <p>Ajouter un enregistrement A pour la machine Debian dans la zone Forward Lookup*. (S'il n'est pas pr\u00e9sent) </p> <ul> <li>Cr\u00e9er un enregistrement PTR dans la zone Reverse Lookup.(S'il n'est pas pr\u00e9sent)  {{:datascience:admin_system:linux:capture1.png?400|}} {{:datascience:admin_system:linux:capture4.png?400|}}</li> </ul>"},{"location":"adminsys/os_setup/security/fr/02.Configure_ssh_pam_sssd_ad_fr/#32-enregistrer-le-spn-service-principal-name","title":"3.2. Enregistrer le SPN (Service Principal Name)","text":"<p>Pour assurer que l'enregistrement existant, on tape: </p> <p>Sur le contr\u00f4leur de domaine (PowerShell administrateur) :   </p> <pre><code>setspn -L debian\n</code></pre> <p>Si host/debian.casdds.casd n'est pas pr\u00e9sent, on l'ajouter avec Powershell admin :</p> <pre><code>setspn -S host/debian.casdds.casd debian\nktpass -princ host/debian.casdds.casd@CASDDS.CASD -mapuser DEBIAN$ -pass * -ptype KRB5_NT_PRINCIPAL -crypto AES256-SHA1\n</code></pre>"},{"location":"adminsys/os_setup/security/fr/02.Configure_ssh_pam_sssd_ad_fr/#33-verifier-le-keytab-kerberos","title":"3.3. V\u00e9rifier le keytab Kerberos","text":"<p>Sur Debian :</p> <pre><code>klist -k /etc/krb5.keytab  # V\u00e9rifier la pr\u00e9sence de \"host/debian.casdds.casd\"\n</code></pre> <p>Si absent, quitter et rejoigner le domaine :</p> <pre><code>sudo realm leave CASDDS.CASD\nsudo realm join --user=Administrateur CASDDS.CASD\n</code></pre>"},{"location":"adminsys/os_setup/security/fr/02.Configure_ssh_pam_sssd_ad_fr/#34-generation-et-deploiement-dun-fichier-keytab","title":"3.4. G\u00e9n\u00e9ration et d\u00e9ploiement d\u2019un fichier keytab","text":"<p>G\u00e9n\u00e9ration du keytab sur Windows :</p> <pre><code>ktpass -princ user@CASDDS.CASD -mapuser user -crypto AES256-SHA1 -ptype KRB5_NT_PRINCIPAL -pass * -out user.keytab\n</code></pre> <p>Transfert vers Debian :</p> <pre><code>scp user.keytab user@debian.casdds.casd:/tmp/\n</code></pre> <p>Installation et s\u00e9curisation du keytab :</p> <pre><code>sudo cp /tmp/user.keytab /etc/\nsudo chmod 644 /etc/user.keytab\nsudo chown root:root /etc/user.keytab\n</code></pre>"},{"location":"adminsys/os_setup/security/fr/02.Configure_ssh_pam_sssd_ad_fr/#etape-4-configuration-de-sssd-pam-et-kerberos","title":"\u00c9tape 4 : Configuration de SSSD, PAM et Kerberos","text":""},{"location":"adminsys/os_setup/security/fr/02.Configure_ssh_pam_sssd_ad_fr/#41-fichier-etcsssdsssdconf","title":"4.1. Fichier <code>/etc/sssd/sssd.conf</code>","text":"<pre><code>[sssd]\nservices = nss, pam\ndomains = casdds.casd\nconfig_file_version = 2\n\n[nss]\nhomedir_substring = /home\n\n[pam]\n\n[domain/casdds.casd]\nldap_sasl_authid = user@CASDDS.CASD\nkrb5_keytab = /etc/user.keytab\ndefault_shell = /bin/bash\nkrb5_store_password_if_offline = True\ncache_credentials = True\nkrb5_realm = CASDDS.CASD\nrealmd_tags = manages-system joined-with-adcli\nid_provider = ad\nfallback_homedir = /home/%u@%d\nad_domain = casdds.casd\nuse_fully_qualified_names = False\nldap_id_mapping = True\naccess_provider = ad\nldap_group_nesting_level = 2\n</code></pre>"},{"location":"adminsys/os_setup/security/fr/02.Configure_ssh_pam_sssd_ad_fr/#42-configurer-pam","title":"4.2. Configurer PAM","text":"<p>Modifier les fichiers dans <code>/etc/pam.d/</code> pour inclure <code>pam_sss.so</code> </p> <pre><code>### /etc/pam.d/common-auth\nsudo: unable to resolve host debian118: Name or service not known\nauth      sufficient  pam_unix.so try_first_pass\nauth      sufficient  pam_sss.so use_first_pass\nauth      required    pam_deny.so\n</code></pre> <pre><code>### /etc/pam.d/common-account\nsudo: unable to resolve host debian118: Name or service not known\naccount   required    pam_unix.so\naccount   sufficient  pam_sss.so\naccount   required    pam_permit.so\n</code></pre> <pre><code>### /etc/pam.d/common-password\nsudo: unable to resolve host debian118: Name or service not known\npassword  sufficient  pam_unix.so\npassword  sufficient  pam_sss.so\npassword  required    pam_deny.so\n</code></pre> <pre><code>### /etc/pam.d/common-session\nsudo: unable to resolve host debian118: Name or service not known\nsession   required    pam_unix.so\nsession   optional    pam_sss.so\nsession   required    pam_mkhomedir.so skel=/etc/skel/ umask=0022\n</code></pre>"},{"location":"adminsys/os_setup/security/fr/02.Configure_ssh_pam_sssd_ad_fr/#43-fichier-etckrb5conf","title":"4.3. Fichier <code>/etc/krb5.conf</code>","text":"<pre><code> [libdefaults]\n        default_realm = CASDDS.CASD\n\n        default_tkt_enctypes = aes256-cts-hmac-sha1-96 aes128-cts-hmac-sha1-96\n        default_tgs_enctypes = aes256-cts-hmac-sha1-96 aes128-cts-hmac-sha1-96\n        permitted_enctypes   = aes256-cts-hmac-sha1-96 aes128-cts-hmac-sha1-96\n        kdc_timesync = 1\n        ccache_type = 4\n        forwardable = true\n        proxiable = true\n        ticket_lifetime = 24h\n        dns_lookup_realm = true\n        dns_lookup_kdc = true\n        dns_canonicalize_hostname = false\n        rdns = false\n         allow_weak_crypto = true\n# The following libdefaults parameters are only for Heimdal Kerberos.\n        fcc-mit-ticketflags = true\n\n[realms]\n        CASDDS.CASD = {\n                kdc = 10.50.5.64\n                admin_server = 10.50.5.64\n        }\n\u2026..\n[domain_realm]\n\u2026.\n        .casdds.casd = CASDDS.CASD\n        casdds.casd = CASDDS.CASD\n</code></pre>"},{"location":"adminsys/os_setup/security/fr/02.Configure_ssh_pam_sssd_ad_fr/#etape-5-configuration-ssh-avec-gssapi","title":"\u00c9tape 5 : Configuration SSH avec GSSAPI","text":""},{"location":"adminsys/os_setup/security/fr/02.Configure_ssh_pam_sssd_ad_fr/#51-sur-debian","title":"5.1. Sur Debian","text":"<p>Modifier <code>/etc/ssh/sshd_config</code> :</p> <pre><code>UsePam yes\nGSSAPIAuthentication yes # l'authentification bas\u00e9e sur GSSAPI pour les connexions SSH\nGSSAPICleanupCredentials yes # la suppression automatique des identifiants temporaires obtenus via GSSAPI apr\u00e8s leur utilisation pour renforcer la s\u00e9curit\u00e9\nGSSAPIKeyExchange yes # s\u00e9curiser l'\u00e9change de cl\u00e9s, prot\u00e9geant ainsi le processus de n\u00e9gociation contre les interceptions\nGSSAPIStrictAcceptorCheck no # D\u00e9sactive la v\u00e9rification stricte de l'identit\u00e9 de l'acceptateur, facilitant les connexions dans des environnements o\u00f9 les noms de principal peuvent varier\n</code></pre> <p>Modifier <code>/etc/ssh/ssh_config</code>:</p> <pre><code>   Host *\n       \u2026\n       GSSAPIAuthentication yes\n       GSSAPIDelegateCredentials yes # d\u00e9l\u00e9guer les identifiants GSSAPI du client au serveur pour \n</code></pre> <p>Red\u00e9marrer les services :</p> <pre><code>sudo systemctl restart sshd sssd\n</code></pre>"},{"location":"adminsys/os_setup/security/fr/02.Configure_ssh_pam_sssd_ad_fr/#52-sur-windows","title":"5.2. Sur Windows","text":"<p>Installer OpenSSH via PowerShell:</p> <pre><code>Add-WindowsCapability -Online -Name OpenSSH.Client~~~~0.0.1.0\nAdd-WindowsCapability -Online -Name OpenSSH.Server~~~~0.0.1.0\nStart-Service sshd\nSet-Service -Name sshd -StartupType 'Automatic'\n</code></pre> <p>Activer GSSAPI dans <code>C:\\ProgramData\\ssh\\sshd_config</code> :</p> <pre><code>GSSAPIAuthentication yes\nGSSAPICleanupCredentials yes\n</code></pre> <p>Red\u00e9marrer le service:</p> <pre><code> Restart-Service sshd\n</code></pre>"},{"location":"adminsys/os_setup/security/fr/02.Configure_ssh_pam_sssd_ad_fr/#etape-6-validation","title":"\u00c9tape 6 : Validation","text":""},{"location":"adminsys/os_setup/security/fr/02.Configure_ssh_pam_sssd_ad_fr/#61-test-kerberos","title":"6.1. Test Kerberos","text":"<p>Sur Debian :</p> <pre><code> kinit user@CASDDS.CASD  # Authentifier avec le mot de passe AD\nklist    \n</code></pre>"},{"location":"adminsys/os_setup/security/fr/02.Configure_ssh_pam_sssd_ad_fr/#62-connexion-ssh","title":"6.2. Connexion SSH","text":"<p>Depuis Windows :</p> <pre><code>ssh -K user@debian.casdds.casd  # -K active la d\u00e9l\u00e9gation Kerberos\n</code></pre>"},{"location":"adminsys/os_setup/security/fr/02.Configure_ssh_pam_sssd_ad_fr/#appendix-notes-importantes","title":"Appendix Notes importantes :","text":"<ul> <li>Permissions SSSD : V\u00e9rifier que <code>/etc/sssd/sssd.conf</code> a les droits <code>600</code> :</li> </ul> <pre><code>sudo chmod 600 /etc/sssd/sssd.conf\n</code></pre>"},{"location":"adminsys/other_services/build_openssl_tool/","title":"Build openssl","text":"<p>There are some feature of signing certificate only exist in v3, and v3 is not in the standard repo or backports repo. So we have to build it manually.</p>"},{"location":"adminsys/other_services/build_openssl_tool/#get-the-source","title":"Get the source","text":"<p>You can find the full source list here. I use version <code>3.0.9</code> in this tutorial.</p> <pre><code># the -P option will put the download file in the target dir\nsudo wget -P /usr/src/ https://www.openssl.org/source/openssl-3.0.9.tar.gz\n\ncd /usr/src\n\n# unzip the source\nsudo tar -xzvf openssl-3.0.9.tar.gz\n</code></pre>"},{"location":"adminsys/other_services/build_openssl_tool/#config-and-build-the-bin","title":"Config and build the bin","text":"<pre><code>cd /usr/src/openssl-3.0.9\n\n# install dependencies\nsudo apt update\nsudo apt install build-essential checkinstall zlib1g-dev libssl-dev\n\n# you can replace the prefix by a custom path\n./config --prefix=/usr/local/openssl\n\n# build the source \nsudo make\n\nsudo make test\n\nsudo make install\n\n# if everything works well, you should find the below dirs in /usr/local/openssl\n/usr/local/openssl/\n\u251c\u2500\u2500 bin\n\u251c\u2500\u2500 include\n\u251c\u2500\u2500 lib64\n\u251c\u2500\u2500 share\n\u2514\u2500\u2500 ssl\n</code></pre>"},{"location":"adminsys/other_services/build_openssl_tool/#post-installation-config","title":"Post installation config","text":"<pre><code># try the newly build\n/usr/local/openssl/bin/openssl version\n\n# normally, you should see the below error message \nopenssl: error while loading shared libraries: libssl.so.3: cannot open shared object file: No such file or directory\n\n# that's because the required lib is not loaded in your env\n# run the below command to load \necho 'export LD_LIBRARY_PATH=/usr/local/openssl/lib64:$LD_LIBRARY_PATH' &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n\n# add the lib path (/usr/local/openssl/lib64) in the below file\nsudo vim /etc/ld.so.conf.d/openssl.conf\n\n# reload the ldconfig\nsudo ldconfig\n# check if the lib exist or not\nsudo ldconfig -p | grep libssl.so.3\n\n# if you can find the new lib, then rerun\n/usr/local/openssl/bin/openssl version \n</code></pre> <p>If you want to replace the old version of openssl, you can run the below command</p> <pre><code># remove the old version  \nmv /usr/bin/openssl /root/openssl-old\n\necho 'PATH=\"/usr/local/openssl/bin:$PATH\"' &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n</code></pre>"},{"location":"adminsys/other_services/install_gitlab_ce/","title":"Install on configure gitlab CE on debian 11","text":"<p>GitLab Community Edition (CE) is an open-source application for hosting Git repositories in your own infrastructure.  With GitLab you can do project planning and source code management to CI/CD and monitoring. GitLab has evolved to  become a complete DevOps platform, delivered as a single application.</p>"},{"location":"adminsys/other_services/install_gitlab_ce/#1-the-minimum-requirements","title":"1. The minimum requirements","text":"<p>The Gitlab CE is an application web with a database. To allow it to run correctly. We recommend you to meet the below minimum requirements: - 8GB of Ram - 4 vcpus - 40GB Disk space</p> <p>Having a domain name allows user to easily access it. So we recommand you to provide a domain name </p> <p>In this tutorial, we set the domain name as:  <code>git.casd.local</code></p>"},{"location":"adminsys/other_services/install_gitlab_ce/#2-install-the-gitlab-ce-dependencies-packages","title":"2. Install the gitlab ce dependencies packages","text":"<pre><code># update apt repo\nsudo apt update &amp;&amp; sudo apt -y full-upgrade\n\n# Install GitLab Server Dependencies\nsudo apt -y install curl vim openssh-server ca-certificates\n</code></pre>"},{"location":"adminsys/other_services/install_gitlab_ce/#3-configure-postfix-send-only-smtp","title":"3. Configure Postfix Send-Only SMTP","text":"<p>You can find the full doc here</p>"},{"location":"adminsys/other_services/install_gitlab_ce/#4-add-the-gitlab-ce-repository","title":"4. Add the GitLab CE Repository","text":"<p>With the below script, we will add the GitLab repository (<code>gitlab_gitlab-ce.list</code>) to <code>/etc/apt/sources.list.d/</code>.</p> <pre><code>curl https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.deb.sh | sudo bash\n</code></pre> <p>The content of the <code>gitlab_gitlab-ce.list</code> should looks like:</p> <pre><code># this file was generated by packages.gitlab.com for\n# the repository at https://packages.gitlab.com/gitlab/gitlab-ce\n\ndeb [signed-by=/usr/share/keyrings/gitlab_gitlab-ce-archive-keyring.gpg] https://packages.gitlab.com/gitlab/gitlab-ce/debian/ bullseye main\ndeb-src [signed-by=/usr/share/keyrings/gitlab_gitlab-ce-archive-keyring.gpg] https://packages.gitlab.com/gitlab/gitlab-ce/debian/ bullseye main\n</code></pre>"},{"location":"adminsys/other_services/install_gitlab_ce/#5-install-gitlab-ce-on-debian","title":"5. Install GitLab CE on Debian","text":"<pre><code>export GITLAB_URL=\"http://git.casd.local\"\nsudo EXTERNAL_URL=\"${GITLAB_URL}\" apt install gitlab-ce\n</code></pre> <p>If everything goes well, you should see the success output. And the gitlab-ce server is up and running at  http://git.casd.local</p>"},{"location":"adminsys/other_services/install_gitlab_ce/#6test-the-gitlab-server","title":"6.Test the gitlab server","text":"<p>By default, it generates a root account with a password. You can get the password with the below command</p> <pre><code>sudo cat /etc/gitlab/initial_root_password \n</code></pre> <p>If everything goes well, you should be able to login with root/pwd</p>"},{"location":"adminsys/other_services/install_gitlab_ce/#7-custom-config","title":"7. Custom config","text":"<p>The main config file is located at <code>/etc/gitlab/gitlab.rb</code>. If you followed the above procedure, it will install a  gitlab with minimun config. - No external authentication - built-in postgres db - Etc.</p> <p>We need to modify the config to make the gitlab server production ready.</p> <pre><code># open the conf file\nsudo vim /etc/gitlab/gitlab.rb\n\n# do some change \n\n# apply the change\nsudo gitlab-ctl reconfigure\n</code></pre>"},{"location":"adminsys/other_services/install_gitlab_ce/#71-use-an-openldap-server-for-authentication","title":"7.1 Use an openldap server for authentication","text":"<p>You can find the official doc here https://docs.gitlab.com/ee/administration/auth/ldap/#updating-ldap-dn-and-email To enable the ldap authentication, you need to </p> <pre><code># enable the ldap authentication\ngitlab_rails['ldap_enabled'] = true\n\n# config the ldap server connexion\ngitlab_rails['ldap_servers'] = YAML.load &lt;&lt;-'EOS'\n     host: 'ldap.casd.local'\n     port: 389\n     uid: 'uid'\n     bind_dn: 'cn=gitlab,ou=serviceAccounts,dc=casd,dc=local'\n     password: 'gitlabServiceAccountPassword'\n     encryption: 'plain'\n     base: 'ou=people,dc=casd,dc=local'\n     verify_certificates: false\n     active_directory: false\n     lowercase_usernames: false\n     block_auto_created_users: false\n     attributes:\n        username: ['uid']\n        email: ['mail']\n        name: 'displayName'\n        first_name: 'givenName'\n        last_name: 'sn'\nEOS\n</code></pre>"},{"location":"adminsys/other_services/install_gitlab_ce/#72-use-external-postgresql-db","title":"7.2 Use external postgresql db","text":"<p>https://docs.gitlab.com/ee/administration/postgresql/external.html</p> <p>https://stackoverflow.com/questions/23580268/gitlab-omnibus-configuration-for-postgres</p>"},{"location":"adminsys/other_services/install_vscode_server/","title":"Deploy VS code as a web service","text":"<p>There are two options, which allows you to run VS Code in the browser, giving you access to your development  environment remotely.: - VS Code Server - code-server</p>"},{"location":"adminsys/other_services/install_vscode_server/#1-vs-code-server-remote-development-extension-pack","title":"1. VS Code Server (Remote Development Extension Pack)","text":"<p>In this mode, we use VS code desktop (on client machine) to install a <code>Remote Development Extension Pack</code> which allows  the client vs code to open a ssh tunnel with the vs code server(on remote server).</p> <p>You can find the official doc here</p> <p>We don't recommend this option, because ssh uses specific ports which requires extra firewall configuration.</p>"},{"location":"adminsys/other_services/install_vscode_server/#2-code-server","title":"2. Code server","text":"<p>In this mode, the code-server (vs code server backend) runs an application server(default port is 8080). For example user can access the vs code via any browser with http://url:8080/. If you add a proxy, you can run it with 80 or 443.</p>"},{"location":"adminsys/other_services/install_vscode_server/#21-installation","title":"2.1 Installation","text":"<p>code-server is an open-source project by Coder that allows you to run a standalone VS Code instance in a web  browser. You can install it on any machine, even a remote server, and access it from anywhere.</p> <p>The official github page of the <code>code-server</code> is here: https://github.com/coder/code-server</p> <pre><code># use the installation script\ncurl -fsSL https://code-server.dev/install.sh | sh\n\n# start the server interactivately\ncode-server\n</code></pre> <p>We recommand you to run code server via systemd</p> <pre><code># start the code-server daemon\nsudo systemctl start code-server@$USER\n\n# enable it from boot\nsudo systemctl enable --now code-server@$USER\n</code></pre> <p>The above command will generate a config  ~/.config/code-server/config.yaml. Below is an example of the config file</p> <pre><code># if you want to allow remote access, change the 127.0.0.1 to 0.0.0.0.\n# you can also change the \nbind-addr: 127.0.0.1:8080\nauth: password\npassword: changeMe\ncert: false\n# cert-key: \n</code></pre> <p>The default auth method is <code>password</code>, it also supports <code>OAuth2</code>. To disable authentication, you can put <code>none</code>.</p> <p>For the ssl certificate, we don't recommend to activate it, because nginx can do a better job.</p>"},{"location":"adminsys/other_services/install_vscode_server/#22-enable-nginx-as-reverse-proxy","title":"2.2 Enable nginx as reverse-proxy","text":"<p>Suppose we start the code-server at 127.0.0.1:8080, Below is a nginx config example</p> <pre><code># add a conf\nvim /etc/nginx/sites-available/vscode-server\n\n## Add below content\n# set a backend upstream\nupstream vscode-server {\n    server 127.0.0.1:8080 fail_timeout=0;\n}\n\n# a server listen to port 80, which will redirect request to port 443\nserver {\n    listen 80;\n    server_name vscode-server.casd.local;\n\n    # redirect http request to https\n    return 301 https://$host$request_uri;\n\n    }\n\n# a server listen to port 443, which will ensure https resolution\nserver {\n    listen 443 ssl;\n    ssl_certificate /etc/ssl/certs/wildcard-casd.pem;\n    ssl_certificate_key /etc/ssl/private/wildcard-casd.key;\n\n    # all request will be redirected to the backend_chart upstream\n    location / {\n        include proxy_params;\n        proxy_pass http://vscode-server;\n        proxy_set_header Host $host;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection upgrade;\n        proxy_set_header Accept-Encoding gzip;\n\n    }\n}\n\n# Activate the conf\nln -s /etc/nginx/sites-available/vscode-server /etc/nginx/sites-enabled/vscode-server\n</code></pre>"},{"location":"adminsys/other_services/install_vscode_server/#23-edit-a-systemd-service-file","title":"2.3 Edit a systemd service file","text":"<p>To run code-server as a daemon, it's recommended to edit a systemd service file.</p> <pre><code>sudo vim /etc/systemd/system/code-server.service\n\n# add the below content\n[Unit]\nDescription=code-server\nAfter=network.target\n\n[Service]\nType=simple\nUser=pliu\nExecStart=/usr/bin/code-server --bind-addr 0.0.0.0:8080 --auth password\nRestart=always\nRestartSec=10\n\n[Install]\nWantedBy=multi-user.target\n</code></pre> <pre><code># reload systemd daemon\nsudo systemctl daemon-reload\n# enable code-server as start up service\nsudo systemctl enable code-server\n\n# start the service\nsudo systemctl start code-server\n\n# check the status\nsudo systemctl status code-server\n\n# check the log \njournalctl -u code-server -f\n\n# stop the service\nsudo systemctl stop code-server\n</code></pre>"},{"location":"adminsys/other_services/Nginx/01.Install_Nginx/","title":"Install Nginx","text":""},{"location":"adminsys/other_services/Nginx/01.Install_Nginx/#step-1-install-the-binary","title":"Step 1. Install the binary","text":"<p>Nginx is available in Debian\u2019s default software repositories, making it possible to install it from conventional package management tools.</p> <pre><code>sudo apt update\nsudo apt install nginx\n</code></pre>"},{"location":"adminsys/other_services/Nginx/01.Install_Nginx/#step-2-adjusting-the-firewall","title":"Step 2. Adjusting the firewall","text":"<p>Before testing Nginx, it\u2019s necessary to modify the firewall settings to allow outside access to the default web ports. Assuming that you followed the instructions in the prerequisites, you should have a UFW firewall configured to restrict access to your server.</p> <p>During installation, Nginx registers itself with UFW to provide a few application profiles that can be used to enable or disable access to Nginx through the firewall.</p> <p>List the ufw application profiles by typing:</p> <pre><code>sudo ufw app list\n\n# Output\nAvailable applications:\n...\n  Nginx Full\n  Nginx HTTP\n  Nginx HTTPs\n  OpenSSH\n</code></pre> <p>From the output, there are three profiles available for Nginx:</p> <ul> <li>Nginx Full: This profile opens both port 80 (normal, unencrypted web traffic) and port 443 (TLS/SSL encrypted traffic)</li> <li>Nginx HTTP: This profile opens only port 80 (normal, unencrypted web traffic)</li> <li>Nginx HTTPS: This profile opens only port 443 (TLS/SSL encrypted traffic)</li> </ul> <p>Base on your requirements, allow the traffic. In our case, it will be</p> <pre><code>sudo ufw allow 'Nginx Full'\n</code></pre>"},{"location":"adminsys/other_services/Nginx/01.Install_Nginx/#step-3-check-nginx-status","title":"Step 3. Check nginx status","text":"<pre><code>systemctl status nginx\n</code></pre> <p>You can access the default Nginx landing page to confirm that the software is running properly by navigating to your server\u2019s IP address. If you do not know your server\u2019s IP address, you can type this at your server\u2019s command prompt:</p> <pre><code># get server ip\nip addr show eth0 | grep inet | awk '{ print $2; }' | sed 's/\\/.*$//'\n\n# check the default nginx welcome page\nhttp://your_server_ip\n</code></pre>"},{"location":"adminsys/other_services/Nginx/01.Install_Nginx/#step4-nginx-useful-commands","title":"Step4. Nginx useful commands","text":"<pre><code># \nsudo systemctl stop/start/restart/reload nginx\n\n# start automatically when the server boots\nsudo systemctl disable/enable nginx\n</code></pre>"},{"location":"adminsys/other_services/Nginx/01.Install_Nginx/#step-5-setting-up-server-blocks-incomplete","title":"Step 5. Setting Up Server Blocks (Incomplete)","text":"<p>When using the Nginx web server, server blocks (similar to virtual hosts in Apache) can be used to encapsulate  configuration details and host more than one domain on a single server.</p> <p>https://www.digitalocean.com/community/tutorials/how-to-install-nginx-on-debian-11</p>"},{"location":"adminsys/other_services/Nginx/01.Install_Nginx/#step-6-important-nginx-files-and-directories","title":"Step 6. Important Nginx Files and Directories","text":""},{"location":"adminsys/other_services/Nginx/01.Install_Nginx/#61-content","title":"6.1 Content","text":"<p>/var/www/html: The actual web content, which by default only consists of the default Nginx page you saw earlier, is served out of the /var/www/html directory. This can be changed by altering Nginx configuration files.</p>"},{"location":"adminsys/other_services/Nginx/01.Install_Nginx/#62-server-configuration","title":"6.2 Server Configuration","text":"<ul> <li>/etc/nginx: The Nginx configuration directory. All of the Nginx configuration files reside here.</li> <li>/etc/nginx/nginx.conf: The main Nginx configuration file. This can be modified to make changes to the Nginx global configuration.</li> <li>/etc/nginx/sites-available/: The directory where per-site server blocks can be stored. Nginx will not use the configuration files found in this directory unless they are linked to the <code>sites-enabled</code> directory. Typically, all server block configuration is done in this directory, and then enabled by linking to the other directory.</li> <li>/etc/nginx/sites-enabled/: The directory where enabled per-site server blocks are stored. Typically, these are created by linking to configuration files found in the <code>sites-available</code> directory.</li> <li>/etc/nginx/snippets: This directory contains configuration fragments that can be included elsewhere in the Nginx configuration. Potentially repeatable configuration segments are good candidates for refactoring into snippets.</li> </ul>"},{"location":"adminsys/other_services/Nginx/01.Install_Nginx/#63-server-logs","title":"6.3 Server Logs","text":"<ul> <li>/var/log/nginx/access.log: Every request to your web server is recorded in this log file unless Nginx is configured to do otherwise.</li> <li>/var/log/nginx/error.log: Any Nginx errors will be recorded in this log.</li> </ul>"},{"location":"adminsys/other_services/Nginx/01.Install_Nginx/#step-7-set-nginx-as-a-reverse-proxy","title":"Step 7. Set Nginx as a Reverse proxy","text":"<p>We suppose we already have a service which runs on <code>http://127.0.0.1:8080/</code>. We will set Nginx as the <code>Reverse proxy</code> of this service.</p>"},{"location":"adminsys/other_services/Nginx/01.Install_Nginx/#71-create-a-new-server-block","title":"7.1 Create a new server block","text":"<p>We suppose this service is called <code>my-app.casd.local</code>, we need to create a new server block for this domain.</p> <pre><code>sudo vim /etc/nginx/sites-availabe/my-app\n</code></pre> <p>Add below config to the <code>my-app</code> file (i.e. similar to the virtual hosts in apache)</p> <pre><code># set a backend upstream\nupstream my-app {\n    server 127.0.0.1:8080 fail_timeout=0;\n}\n\n# a server listen to port 80, which will redirect request to port 443\nserver {\n    listen 80;\n    server_name my-app.casd.local;\n\n    # redirect http request to https\n    return 301 https://$host$request_uri;\n\n    }\n\n# a server listen to port 443, which will ensure https resolution\nserver {\n    listen 443 ssl;\n    ssl_certificate /etc/ssl/certs/certificate.pem;\n    ssl_certificate_key /etc/ssl/private/private_key.pem;\n\n    # all request will be redirected to the backend_chart upstream\n    location / {\n        include proxy_params;\n        proxy_pass http://my-app;\n    }\n}\n</code></pre>"},{"location":"adminsys/other_services/Nginx/01.Install_Nginx/#8-set-up-firewall-to-block-remote-access-of-the-backend-service","title":"8. Set up firewall to block remote access of the backend service","text":"<p>To avoid users access the backend service directly, we can set port 8080 can be only accessed via 127.0.0.1.  </p>"},{"location":"adminsys/other_services/Nginx/01.Install_Nginx/#9-some-best-practices","title":"9. Some best practices","text":""},{"location":"adminsys/other_services/Nginx/01.Install_Nginx/#91-set-the-nginx-server-in-production","title":"9.1 Set the nginx server in production","text":"<p>We can notice in /etc/nginx, there are two folders - sites-available - sites-enabled</p> <p>The best solution is to write the configuration file in <code>sites-available</code> then create a symbolic link in <code>sites-enabled</code> All the server conf in <code>sites-enabled</code> will be activated automatically by the nginx server.</p> <p>For example</p> <pre><code>cd /etc/nginx\n# create the origin conf file\ntouch sites-available/test_site.conf\n# create the soft link to activate the conf\nln -s sites-available/test_site.conf sites-enabled/test_site.conf\n</code></pre> <pre><code>server {\n    listen 80;\n    server_name deb.casd.local;\n\n    # redirect http request to https\n    return 301 https://$host$request_uri;\n\n}\n\n\nserver {\n    listen 443 ssl;\n    ssl_certificate /etc/ssl/certs/casd_wildcard.pem;\n    ssl_certificate_key /etc/ssl/private/casd_wildcard_key.pem;\n    server_name deb.casd.local;\n\n    location / {\n        root /package-repo/aptly/.aptly/public;\n        autoindex on;\n        charset utf-8;\n        autoindex_exact_size off;\n        try_files $uri $uri/ =404;\n    }\n}\n</code></pre>"},{"location":"adminsys/other_services/Nginx/02.Enable_https_resolution/","title":"Install nginx with basic http and https config","text":"<p>Nginx is a free and open-source web server used to host websites and applications of all sizes.  The software is known for its low impact on memory resources, high scalability, and its modular,  event-driven architecture which can offer secure, predictable performance. More than just a web server,  Nginx also works as a load balancer, an HTTP cache, and a reverse proxy.</p>"},{"location":"adminsys/other_services/Nginx/02.Enable_https_resolution/#install-nginx","title":"Install Nginx","text":"<p>Nginx is available in Debian\u2019s default software repositories, making it possible to install it from conventional  package management tools.</p> <pre><code>sudo apt update\nsudo apt install nginx\n</code></pre>"},{"location":"adminsys/other_services/Nginx/02.Enable_https_resolution/#adjusting-the-firewall","title":"Adjusting the Firewall","text":"<p>Before testing Nginx, it\u2019s necessary to modify the firewall settings to allow outside access to the default  web ports. Assuming that you followed the instructions in the prerequisites, you should have a UFW firewall  configured to restrict access to your server.</p> <p>During installation, Nginx registers itself with UFW to provide a few application profiles that can be used to enable or disable access to Nginx through the firewall.</p> <p>List the ufw application profiles by typing:</p> <pre><code>sudo ufw app list\n\n# Output\nAvailable applications:\n...\n  Nginx Full\n  Nginx HTTP\n  Nginx HTTPs\n  OpenSSH\n</code></pre> <p>It is recommended that you enable the most restrictive profile that will still allow the traffic you\u2019ve configured.  Since you will configure TLS/SSL for your server also in this guide, you will need to allow traffic for HTTP on port 80 and HTTPS on port 443.</p> <pre><code># You can enable this by typing:\nsudo ufw allow 'Nginx HTTP'\nsudo ufw allow 'Nginx HTTPS'\n\n# You can verify the change by typing:\nsudo ufw status\n</code></pre>"},{"location":"adminsys/other_services/Nginx/02.Enable_https_resolution/#check-nginx-status","title":"Check nginx status","text":"<p>At the end of the installation process, Debian 11 starts Nginx. The web server should already be up and running.</p> <p>You can check with the systemd init system to make sure the service is running by typing:</p> <pre><code># check the status\nsystemctl status nginx\n\n# get current server ip address\nip addr show eth0 | grep inet | awk '{ print $2; }' | sed 's/\\/.*$//'\n\n# When you have your server\u2019s IP address, enter it into your browser\u2019s address bar:\n\nhttp://your_server_ip\n</code></pre> <p>Some useful command</p> <pre><code># To stop your web server\nsudo systemctl stop nginx\n\n# To start your web server\nsudo systemctl start nginx\n\n# To stop and then start the service again\nsudo systemctl restart nginx\n\n# If you are making configuration changes, Nginx can often reload without dropping connections.\nsudo systemctl reload nginx\n\n# Nginx is configured to start automatically when the server boots. If this is not what you want, \n# you can disable this behavior\nsudo systemctl disable nginx\n\nsudo systemctl enable nginx\n</code></pre>"},{"location":"adminsys/other_services/Nginx/02.Enable_https_resolution/#configure-a-server-block","title":"Configure a server block","text":"<p>When using the Nginx web server, server blocks (similar to virtual hosts in Apache) can be used to  encapsulate configuration details and host more than one domain on a single server. The following examples  use your_domain, but you should replace this with your actual domain name.</p> <pre><code># create a folder to put your site content\nsudo mkdir -p /var/www/your_domain/html\n\n# change the owner and acl\nsudo chown -R $USER:$USER /var/www/your_domain/html\nsudo chmod -R 755 /var/www/your_domain\n\n# add some demo page\nvim /var/www/your_domain/html/index.html\n</code></pre> <p>Put the below html content</p> <pre><code>&lt;html&gt;\n    &lt;head&gt;\n        &lt;title&gt;Welcome to your_domain&lt;/title&gt;\n    &lt;/head&gt;\n    &lt;body&gt;\n        &lt;h1&gt;Success! Your Nginx server is successfully configured for &lt;em&gt;your_domain&lt;/em&gt;. &lt;/h1&gt;\n&lt;p&gt;This is a sample page.&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <p>In order for Nginx to serve the above content(html page), you must create a server block with the correct  directives that point to your custom web root. Instead of modifying the default configuration file directly,  make a new one at <code>/etc/nginx/sites-available/your_domain</code>:</p> <pre><code>server {\n        listen 80;\n        listen [::]:80;\n\n        root /var/www/your_domain/html;\n        index index.html index.htm index.nginx-debian.html;\n\n        server_name your_domain www.your_domain;\n\n        location / {\n                try_files $uri $uri/ =404;\n        }\n}\n</code></pre> <p>To enable a server block, you need to create a symbolic link to your custom configuration inside the <code>sites-enable</code>  directory</p> <pre><code>sudo ln -s /etc/nginx/sites-available/your_domain /etc/nginx/sites-enabled/\n</code></pre> <p>Normally, you will find two <code>server blocks</code> in /etc/nginx/sites-enabled/ - your_domain: Will respond to requests for your_domain and www.your_domain. - default: Will respond to any requests on port 80 that do not match the other two blocks.</p> <p>To avoid a possible hash bucket memory problem that can arise from adding additional server names to your  configuration, it is necessary to adjust a single value in the <code>/etc/nginx/nginx.conf</code> file. Open the file:</p> <pre><code>sudo vim /etc/nginx/nginx.conf\n\n# find the line server_names_hash_bucket_size 64; and uncomment it \n</code></pre> <p>Test the validity to make sure that there are no syntax errors in any of your Nginx files:</p> <pre><code>sudo nginx -t\n\n# if everything is ok, you can try to restart the nginx service\nsudo systemctl restart nginx\n</code></pre> <p>If everything goes well, you should see a new page, when you type the domain name in your browser</p>"},{"location":"adminsys/other_services/Nginx/02.Enable_https_resolution/#enable-https","title":"Enable HTTPS","text":"<p>The easiest way to enable https is to set up a new server blocks which listen on port 443 with ssl. Below is an example which convert the above http server block to https. </p> <pre><code>server {\n  listen 80;\n  server_name keycloak.casd.local;\n\n  # Redirect all traffic to SSL\n  rewrite ^ https://$host$request_uri? permanent;\n}\n\nserver {\n  listen 443 ssl default_server;\n\n  # enables SSLv3/TLSv1, but not SSLv2 which is weak and should no longer be used.\n  ssl_protocols SSLv3 TLSv1 TLSv1.1 TLSv1.2 TLSv1.3;\n\n  # disables all weak ciphers\n  ssl_ciphers ALL:!aNULL:!ADH:!eNULL:!LOW:!EXP:RC4+RSA:+HIGH:+MEDIUM;\n\n  server_name keycloak.casd.local;\n\n  ## Access and error logs.\n  access_log /var/log/nginx/access.log;\n  error_log  /var/log/nginx/error.log info;\n\n  ## Keep alive timeout set to a greater value for SSL/TLS.\n  keepalive_timeout 75 75;\n\n  ## See the keepalive_timeout directive in nginx.conf.\n  ## Server certificate and key.\n  ssl_certificate /opt/keycloak/keycloak-23.0.4/conf/wildcard-casd.pem;\n  ssl_certificate_key /opt/keycloak/keycloak-23.0.4/conf/wildcard-casd.key;\n  ssl_session_timeout  5m;\n\n  ## Strict Transport Security header for enhanced security. See\n  ## http://www.chromium.org/sts. I've set it to 2 hours; set it to\n  ## whichever age you want.\n  add_header Strict-Transport-Security \"max-age=7200\";\n\n  root /var/www/casd/html;\n  index index.html;\n}\n</code></pre>"},{"location":"adminsys/other_services/Nginx/02.Enable_https_resolution/#troubleshoot","title":"Troubleshoot","text":"<p>Even though, everything works on the server side, it does not mean the client side can view the server page correctly. Below are some common error you may encounter when you set up a https </p>"},{"location":"adminsys/other_services/Nginx/02.Enable_https_resolution/#err_ssl_version_or_cipher_mismatch","title":"ERR_SSL_VERSION_OR_CIPHER_MISMATCH","text":"<p>This error is caused by the compatibility between the supported ssl/tls protocol version between the server(e.g. nginx) and the client(e.g. chrome, curl). For example, for the newer version of Chrome, the protocol TLSv1 is not accepted, if Nginx server only supports this protocol, the handshake between client and server will fail.</p> <p>The solution is to add explicitly the newer version of the ssl protocol. For example, put the below line <code>ssl_protocols SSLv3 TLSv1 TLSv1.1 TLSv1.2 TLSv1.3;</code> in your https server blocks</p>"},{"location":"adminsys/other_services/Nginx/02.Enable_https_resolution/#err_ssl_key_usage_incompatible","title":"ERR_SSL_KEY_USAGE_INCOMPATIBLE","text":"<p>This error is caused by the key_usage option during the certificate generation. For <code>certain version of Chrome</code>, if the <code>key_usage</code> option is specified, and the certificate is self-signed. Chrome will reject the certificates with error mesage  ERR_SSL_KEY_USAGE_INCOMPATIBLE.</p> <p>The simplest solution is to remove the key usage option during the certificate generation.</p> <p>Or put <code>keyUsage = digitalSignature, keyEncipherment</code> as option. For more information on why chrome produce this error : https://chromeenterprise.google/policies/#RSAKeyUsageForLocalAnchorsEnabled</p>"},{"location":"adminsys/other_services/Nginx/02.Enable_https_resolution/#appendix","title":"Appendix","text":""},{"location":"adminsys/other_services/Nginx/02.Enable_https_resolution/#server-configuration","title":"Server Configuration","text":"<p>Below list all the import path for nginx service configuration</p> <ul> <li>/etc/nginx: The Nginx configuration directory. All the Nginx configuration files reside here.</li> <li>/etc/nginx/nginx.conf: The main Nginx configuration file. This can be modified to make changes to the Nginx global configuration.</li> <li>/etc/nginx/sites-available/: The directory where per-site server blocks can be stored. Nginx will not use the configuration files found in this directory unless they are linked to the sites-enabled directory. Typically, all server block configuration is done in this directory, and then enabled by linking to the other directory.</li> <li>/etc/nginx/sites-enabled/: The directory where enabled per-site server blocks are stored. Typically, these are created by linking to configuration files found in the sites-available directory.</li> <li>/etc/nginx/snippets: This directory contains configuration fragments that can be included elsewhere in the Nginx configuration. Potentially repeatable configuration segments are good candidates for refactoring into snippets.</li> </ul>"},{"location":"adminsys/other_services/Nginx/02.Enable_https_resolution/#server-logs","title":"Server Logs","text":"<ul> <li>/var/log/nginx/access.log: Every request to your web server is recorded in this log file unless Nginx is configured to do otherwise.</li> <li>/var/log/nginx/error.log: Any Nginx errors will be recorded in this log.</li> </ul>"},{"location":"adminsys/other_services/Nginx/03.Use_Nginx_as_Http_load_balancer/","title":"Using nginx as HTTP load balancer","text":"<p>Load balancing across multiple application instances is a commonly used technique for optimizing resource utilization, maximizing throughput, reducing latency, and ensuring fault-tolerant configurations.</p> <p>It is possible to use nginx as a very efficient HTTP load balancer to distribute traffic to several application  servers and to improve performance, scalability and reliability of web applications with nginx.</p>"},{"location":"adminsys/other_services/Nginx/03.Use_Nginx_as_Http_load_balancer/#load-balancing-methods","title":"Load balancing methods","text":"<p>The following load balancing mechanisms (or methods) are supported in nginx:</p> <ul> <li>round-robin: requests to the application servers are distributed in a round-robin fashion,</li> <li>least-connected: next request is assigned to the server with the least number of active connections,</li> <li>ip-hash:  a hash-function is used to determine what server should be selected for the next             request (based on the client\u2019s IP address).</li> </ul>"},{"location":"adminsys/other_services/Nginx/03.Use_Nginx_as_Http_load_balancer/#the-simplest-conf-example-round-robin","title":"The simplest conf example (round-robin)","text":"<pre><code>http {\n    upstream myapp1 {\n        server srv1.example.com;\n        server srv2.example.com;\n        server srv3.example.com;\n    }\n\n    server {\n        listen 80;\n\n        location / {\n            proxy_pass http://myapp1;\n        }\n    }\n}\n</code></pre> <p>In the example above, there are 3 instances of the same application running on srv1-srv3. <code>When the load balancing  method is not specifically configured, it defaults to **round-robin**</code>. All requests are proxied to the server  group myapp1, and nginx applies HTTP load balancing to distribute the requests.</p> <p>Reverse proxy implementation in nginx includes load balancing for <code>HTTP, HTTPS, FastCGI, uwsgi, SCGI, memcached, and gRPC</code>.</p> <p>To configure load balancing for HTTPS instead of HTTP, just use \u201chttps\u201d as the protocol.</p> <p>When setting up load balancing for FastCGI, uwsgi, SCGI, memcached, or gRPC, use fastcgi_pass, uwsgi_pass, scgi_pass,  memcached_pass, and grpc_pass directives respectively.</p>"},{"location":"adminsys/other_services/Nginx/03.Use_Nginx_as_Http_load_balancer/#least-connected-load-balancing","title":"Least connected load balancing","text":"<p>Another load balancing discipline is least-connected. Least-connected allows controlling the load on  application instances more fairly in a situation when some of the requests take longer to complete.</p> <p>With the least-connected load balancing, nginx will try not to overload a busy application server with excessive  requests, distributing the new requests to a less busy server instead.</p> <p>Least-connected load balancing in nginx is activated when the least_conn directive is used as part of the server  group configuration:</p> <pre><code>upstream myapp1 {\n    least_conn;\n    server srv1.example.com;\n    server srv2.example.com;\n    server srv3.example.com;\n}\n</code></pre>"},{"location":"adminsys/other_services/Nginx/03.Use_Nginx_as_Http_load_balancer/#session-persistence","title":"Session persistence","text":"<p>Please note that with round-robin or least-connected load balancing, each subsequent client\u2019s request can be  potentially distributed to a different server. There is no guarantee that the same client will be always directed to  the same server.</p> <p>If there is the need to tie a client to a particular application server  in other words, make the client\u2019s  session \u201csticky\u201d or \u201cpersistent\u201d in terms of always trying to select a particular server the ip-hash load balancing  mechanism can be used.</p> <p>With ip-hash, the client\u2019s IP address is used as a hashing key to determine what server in a server group should be  selected for the client\u2019s requests. This method ensures that the requests from the same client will always be directed  to the same server except when this server is unavailable.</p> <p>To configure ip-hash load balancing, just add the ip_hash directive to the server (upstream) group configuration:</p> <pre><code>upstream myapp1 {\n    ip_hash;\n    server srv1.example.com;\n    server srv2.example.com;\n    server srv3.example.com;\n}\n</code></pre>"},{"location":"adminsys/other_services/Nginx/03.Use_Nginx_as_Http_load_balancer/#weighted-load-balancing","title":"Weighted load balancing","text":"<p>It is also possible to influence nginx load balancing algorithms even further by using server weights.</p> <p>In the examples above, the server weights are not configured which means that all specified servers are treated as  equally qualified for a particular load balancing method.</p> <p>With the round-robin in particular it also means a more or less equal distribution of requests across the servers provided there are enough requests, and when the requests are processed in a uniform manner and completed fast enough.</p> <p>When the weight parameter is specified for a server, the weight is accounted as part of the load balancing decision.</p> <pre><code>upstream myapp1 {\n    server srv1.example.com weight=3;\n    server srv2.example.com;\n    server srv3.example.com;\n}\n</code></pre> <p>With this configuration, every 5 new requests will be distributed across the application instances as the  following: 3 requests will be directed to srv1, one request will go to srv2, and another one  to srv3.</p> <p>It is similarly possible to use weights with the least-connected and ip-hash load balancing in the recent versions of nginx.</p>"},{"location":"adminsys/other_services/Nginx/03.Use_Nginx_as_Http_load_balancer/#health-checks","title":"Health checks","text":"<p>Reverse proxy implementation in nginx includes in-band (or passive) server health checks. If the response from a  particular server fails with an error, nginx will mark this server as failed, and will try to avoid selecting this  server for subsequent inbound requests for a while.</p> <p>The max_fails directive sets the number of consecutive unsuccessful attempts to communicate with the server that  should happen during fail_timeout. By default, max_fails is set to 1. When it is set to 0, health checks are disabled  for this server. The fail_timeout parameter also defines how long the server will be marked as failed. After  fail_timeout interval following the server failure, nginx will start to gracefully probe the server with the live client\u2019s requests. If the probes have been successful, the server is marked as a live one.</p> <pre><code>    ssl on;\n    ssl_protocols TLSv1 TLSv1.1 TLSv1.2;\n    ssl_certificate /etc/nginx/ssl/bundle.crt;\n    ssl_certificate_key /etc/nginx/ssl/private.key;\n</code></pre>"},{"location":"container/Containerd/01.Introduction/","title":"Introduction of containerd","text":"<p>containerd is an industry-standard container runtime with an emphasis on simplicity, robustness, and portability.  It's available as a <code>daemon</code> for Linux and Windows. It manages the complete container lifecycle of its host system,  from image transfer and storage to container execution and supervision to low-level storage to network attachments  and beyond.</p> <p>containerd is designed to be embedded into a larger system(e.g. K8s), rather than being used directly by developers or end-users.</p>"},{"location":"container/Containerd/01.Introduction/#1-why-containerd","title":"1. Why containerd?","text":""},{"location":"container/Containerd/01.Introduction/#11-kubernetes-native-support-cri","title":"1.1 Kubernetes Native Support (CRI)","text":"<p>The old docker runtime does not directly support the CRI(Container Runtime Interface) of k8s, so Kubernetes had to use  a middle layer called <code>dockershim</code> to communicate with Docker. This adds overhead and complexity.</p>"},{"location":"container/Containerd/01.Introduction/#12-efficiency-and-performance","title":"1.2 Efficiency and Performance","text":"<p><code>Containerd</code> is a purpose-built container runtime that is <code>lightweight and efficient</code>. Since it is not tied to  Docker's other functionalities (like image building or extensive CLI commands), it is optimized solely for  container management.</p> <ul> <li>Lower Overhead: Docker includes additional features and a higher-level daemon that isn't needed for Kubernetes,                  adding extra layers of processing.</li> <li>Reduced Resource Consumption: By cutting out the Docker daemon, containerd consumes fewer resources,                   improving the overall performance and reducing the memory and CPU usage on each node.</li> </ul> <p>As a result, you can't use containerd to build docker image. You can only pull images and deploy a container.</p>"},{"location":"container/Containerd/01.Introduction/#13-oci-compliant","title":"1.3 OCI compliant","text":"<p>Containerd uses runc as low-level container runtime, which implements the Open Container Initiative (OCI) Runtime Specification.  OCI spec defines how containers should be created and run. As a result, runc is a standard across container runtimes.</p> <p><code>runc</code> interacts directly with the Linux kernel (e.g. cgroups and seccomp) to execute the containers, and make sure that containers run in isolated and secure environments. .</p>"},{"location":"container/Containerd/01.Introduction/#2-integration-in-docker-engine","title":"2. Integration in Docker engine","text":"<p>Containerd can be used inside <code>Docker engine</code>. The below figure shows the general architecture.</p> <p></p>"},{"location":"container/Containerd/01.Introduction/#3-integration-in-k8s","title":"3. Integration in K8s","text":"<p>In k8s worker nodes, a daemon called <code>kubelet</code> is responsible for communicating with the container runtime(e.g. containerd). This communication is ensured by CRI (Container Runtime Interface), which is a Kubernetes-specific API that  allows Kubernetes to interact with various container runtimes in a standardized way.  Kubernetes uses this interface to manage containers on nodes, regardless of the underlying container runtime. </p>"},{"location":"container/Containerd/01.Introduction/#31-general-workflow","title":"3.1 General workflow","text":"<p>Step1: users issue a command <code>kubectl apply -f deployment.yaml</code>, kubectl apply sends a <code>REST request</code> to the         Kubernetes API server to create or update the Deployment resource defined in the deployment.yaml file.</p> <p>Step2: The API server validates the request (ensuring the resource definition is correct) and stores the         Deployment object in etcd. This object represents the desired state: the number of replicas,         the pod template, labels, etc.</p> <p>Step3: The controller manager gets notified by the API server about the new Deployment. It continuously watches         for changes to Deployment resources, detects the new or updated Deployment object. If the current stat does not        correspond the desired state. New pods creation request will be sent to scheduler.</p> <p>Step4: The scheduler takes into account factors such as resource requests (CPU, memory), node availability, taints,         and affinity/anti-affinity rules to <code>assign the pod to a suitable node</code>.</p> <p>Step5: Kubelet of the target node receives the pod specs from the scheduler. It passes the request to <code>Containerd through the CRI</code>.</p> <p>Step6: Containerd then pulls the required container images from the specified container         registry (e.g., DockerHub, Google Container Registry) if they are not already present on the node.        Containerd creates and starts the containers based on the pod spec, handling everything from resource         allocation (CPU, memory) to networking and storage. It also manages container logs and any other         runtime-specific functions (e.g., container pause/unpause).</p> <p>Step7: The Kubelet continues to monitor the pod's health, and if a pod or container fails, Kubernetes will         attempt to restart it to maintain the desired state.</p>"},{"location":"container/Containerd/01.Introduction/#4-other-important-client","title":"4. Other important client","text":"<p>Containerd uses CRI to communicate with k8s, it also provides two other clients:</p> <ul> <li>CTR: is a low-level CLI tool for users interacting directly with containerd. </li> <li>crictl: </li> </ul>"},{"location":"container/Containerd/01.Introduction/#41-ctr","title":"4.1 CTR","text":"<p>It is primarily used for debugging, testing, and interacting with containerd without going through higher-level tools  like <code>CRI or Docker</code>. While ctr can be used to manage containers, images, namespaces, and snapshots,  it is not recommended for general-purpose use in production environments.</p>"},{"location":"container/Containerd/01.Introduction/#42-crictl","title":"4.2 crictl","text":"<p><code>crictl</code> is a lightweight command-line tool for managing container runtimes. It is particularly useful for  Kubernetes environments that use CRI-compatible runtimes. It's not bundled with contianerd. You need to follow the below steps to install <code>crictl</code> on an Ubuntu/debian system.</p> <p>You can find the official github page here</p> <p>My k8s cluster version <code>1.31.1</code>, so I choose 1.31.1 as the crictl version</p> <pre><code># Step1: get the source\nVERSION=\"v1.31.1\"  # You can change this to the latest version\nwget https://github.com/kubernetes-sigs/cri-tools/releases/download/$VERSION/crictl-$VERSION-linux-amd64.tar.gz\n\n# step2: unzip the source\ntar -xzvf crictl-v1.31.1-linux-amd64.tar.gz\n# you should see a bin called crictl after unzip\n\n# step3: copy the bin to your local bin, so you can call it from anywhere\nsudo mv crictl /usr/local/bin/\n\n# step4: check the version\ncrictl --version\n\n# step5: config crictl endpoint\nsudo vim /etc/crictl.yaml\n\n# put the following content in it, you need to choose one which fit your installation\n# example configuration for Docker:\nruntime-endpoint: unix:///var/run/cri-dockerd.sock\n\n# for contained:\nruntime-endpoint: unix:///run/containerd/containerd.sock\n\n# step6: check your endpoint info\nsudo crictl info\n</code></pre> <p>If you have an older version of kubeadm, the newer version of the crictl should work without problems. </p> <p>If you see the details of your endpoint, now you can run any crictl command  Below are a list of useful command</p> <pre><code># list all existing images\nsudo crictl images\n\n# pull a container image\nsudo crictl pull &lt;image-name&gt;:&lt;tag&gt;\n# for example\nsudo crictl pull nginx:latest\n\n# delete a image\nsudo crictl rmi &lt;image-name&gt;\n# example\nsudo crictl rmi nginx:latest\n\n# view all running pods\nsudo crictl pods\n\n# list all containers (running and stopped)\nsudo crictl ps -a\n\n# view container logs\nsudo crictl logs &lt;container-id&gt;\n\n# start/stop a container\nsudo crictl start/stop/pause/unpause &lt;container-id&gt;\n\n# Attach to a Running Container\nsudo crictl attach &lt;container-id&gt;\n\n# execute a command inside a running container\nsudo crictl exec &lt;container-id&gt; &lt;command&gt;\n# for example\nsudo crictl exec 712fe34fbf5b9  /bin/sh\n</code></pre>"},{"location":"container/Containerd/02.Install_config_containerd/","title":"Install and config containerd","text":"<p>You can find the official doc for installing <code>containerd</code> here.</p>"},{"location":"container/Containerd/02.Install_config_containerd/#1-prerequisites","title":"1. Prerequisites","text":"<p>To make <code>containerd</code> run correctly, we need to do the following config - add two moduls into the linux kernel(e.g. <code>overlay, br_netfilter</code>) - if <code>containerd</code> needs to work with <code>k8s cri</code>, you need to reconfigure some kernel parameters</p>"},{"location":"container/Containerd/02.Install_config_containerd/#11-add-modules-to-linux-kernel","title":"1.1 Add modules to linux kernel","text":"<p>The below command will create a file <code>containerd.conf</code> in <code>/etc/modules-load.d/</code>, and add two lines <code>overlay, and br_netfilter</code> in the <code>containerd.conf</code> file.</p> <pre><code>cat &lt;&lt;EOF | sudo tee /etc/modules-load.d/containerd.conf\noverlay\nbr_netfilter\nEOF\n</code></pre> <p>The file specifies the kernel modules <code>overlay, and br_netfilter</code> should be automatically loaded at boot.</p> <ul> <li>overlay: This module is required for <code>containerd</code> and <code>Docker</code>. It enables the <code>OverlayFS filesystem</code>, which                  helps efficiently store container layers.</li> <li>br_netfilter: This module ensures that bridged traffic is correctly processed by iptables. It's an essential module for Kubernetes networking (iptables-based rules)</li> </ul> <p>To load the module without rebooting, you can load the module manually with the below command</p> <pre><code>sudo modprobe overlay\nsudo modprobe br_netfilter\n</code></pre> <p>To check if the module is loaded correctly or not, you can use the below command.</p> <pre><code>lsmod | grep -E 'overlay|br_netfilter'\n\n# the expected output\nbr_netfilter           32768  0\nbridge                262144  1 br_netfilter\noverlay               147456  0\n</code></pre>"},{"location":"container/Containerd/02.Install_config_containerd/#12-reconfigure-kernel-parameters-if-containerd-is-installed-for-k8s-cluster","title":"1.2 Reconfigure kernel parameters (If containerd is installed for k8s cluster)","text":"<p>We need to modify the value of the below kernel parameters:</p> <ul> <li>net.bridge.bridge-nf-call-iptables = 1: this parameter ensures that <code>iptables processes traffic from bridged network interfaces</code>.                                   It's required for <code>Kubernetes networking</code> (especially CNI plugins like Flannel, <code>Calico</code>).</li> <li>net.ipv4.ip_forward = 1: this parameter enables <code>IP forwarding</code>, allowing the machine to route packets.                                  It's required for <code>Kubernetes pod-to-pod communication</code>.</li> <li>net.bridge.bridge-nf-call-ip6tables = 1: this parameter enables <code>ip6tables processes IPv6 bridged traffic</code>. It's                            useful if your cluster supports IPv6 networking.</li> </ul> <p>IP forwarding is a feature in the Linux kernel that allows a <code>machine to act as a router</code>, forwarding  network packets from one interface to another. By default, Linux does not forward packets between network interfaces unless explicitly enabled.</p> <p>As all kernel parameters are stored in <code>/etc/sysctl.d/</code>, by convention, we create a config file <code>9-kubernetes-cri.conf</code>, and put the above three lines in it. You can use the below command to do it.</p> <pre><code>cat &lt;&lt;EOF | sudo tee /etc/sysctl.d/99-kubernetes-cri.conf\nnet.bridge.bridge-nf-call-iptables = 1\nnet.ipv4.ip_forward = 1\nnet.bridge.bridge-nf-call-ip6tables = 1\nEOF\n</code></pre> <p>To apply the change you can use</p> <pre><code># The below command will trigger the system to read and apply all settings from:\n# /etc/sysctl.conf\n# /run/sysctl.d/*.conf\n# /etc/sysctl.d/*.conf\n# /usr/lib/sysctl.d/*.conf\nsudo sysctl --system\n\n# test the updated value\nsudo sysctl net.bridge.bridge-nf-call-iptables\nsudo sysctl net.ipv4.ip_forward\nsudo sysctl net.bridge.bridge-nf-call-ip6tables\n\n# or you can test all with oneliner\nsudo sysctl net.bridge.bridge-nf-call-iptables net.bridge.bridge-nf-call-ip6tables net.ipv4.ip_forward\n</code></pre>"},{"location":"container/Containerd/02.Install_config_containerd/#2-install-containerd-via-apt","title":"2. Install containerd (via apt)","text":"<p>The <code>containerd.io</code> packages in <code>DEB</code> and <code>RPM</code> formats are distributed by <code>Docker (not by the containerd project)</code>.  The Docker documentation for how to  set up apt-get to install containerd.io packages:</p>"},{"location":"container/Containerd/02.Install_config_containerd/#21-remove-old-versions-if-exist","title":"2.1 Remove old versions if exist","text":"<p>Your Linux distribution may provide <code>unofficial Docker packages</code>, which may conflict with the official packages  provided by Docker. You must uninstall these packages before you install the official version of Docker Engine.</p> <p>The unofficial packages to uninstall are:</p> <ul> <li>docker.io</li> <li>docker-compose</li> <li>docker-doc</li> <li>podman-docker</li> </ul> <p>Run the following command to uninstall all conflicting packages:</p> <pre><code># remove all conflicting packages\nfor pkg in docker.io docker-doc docker-compose podman-docker containerd runc; do sudo apt-get remove $pkg; done\n\n# Remove the installed default config file\nrm /etc/containerd/config.toml\n</code></pre>"},{"location":"container/Containerd/02.Install_config_containerd/#22-configure-the-official-repo","title":"2.2 Configure the official repo","text":"<pre><code># install required packages\nsudo apt-get install \\\n    ca-certificates \\\n    curl \\\n    gnupg\n\n# add gpg key for the containerd.io repo\nsudo install -m 0755 -d /etc/apt/keyrings\ncurl -fsSL https://download.docker.com/linux/debian/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg\nsudo chmod a+r /etc/apt/keyrings/docker.gpg\n\n# add docker.io repo to source.list\necho \\\n  \"deb [arch=\"$(dpkg --print-architecture)\" signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/debian \\\n  \"$(. /etc/os-release &amp;&amp; echo \"$VERSION_CODENAME\")\" stable\" | \\\n  sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null\n</code></pre>"},{"location":"container/Containerd/02.Install_config_containerd/#23-install-containerd-binary-and-set-up-config","title":"2.3 Install containerd binary and set up config","text":"<p>Install the containerd binary via new repo</p> <pre><code>sudo apt update\nsudo apt install containerd.io\n\n# check the installed version\ncontainerd --version\n\n# expected output\ncontainerd containerd.io 1.7.25 bcc810d6b9066471b0b6fa75f557a15a1cbf31bb\n</code></pre>"},{"location":"container/Containerd/02.Install_config_containerd/#3-configure-containerd-after-installation","title":"3. Configure containerd after installation","text":"<p>There is no default configuration file after installation. You need to create one by yourself. </p>"},{"location":"container/Containerd/02.Install_config_containerd/#31-generate-a-default-config","title":"3.1 Generate a default config","text":"<pre><code># generate a default config\ncontainerd config default | sudo tee /etc/containerd/config.toml \n</code></pre> <p>The default config file needs to be modified, below are some points you need to pay attention to: - cgroup driver setting: <code>containerd</code> requires cgroup(linux kernel) to setup resources(e.g. cpu, memory, etc.) and                         security policies. It uses a cgroup driver to communicate with the cgroup.                          You need to adapt this value based on your system setting - sandbox image url: In k8s, all pods have a sandbox container that uses sandbox image. - custom image registry: If you want to use custom image registry, you need to change the default config too.</p>"},{"location":"container/Containerd/02.Install_config_containerd/#32-change-the-cgroup-driver-to-systemd","title":"3.2 Change the cgroup driver to systemd","text":"<p>Find the following section <code>[plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.runc.options]</code> in <code>/etc/containerd/config.toml</code>, then add this line <code>SystemdCgroup = true</code> under it.</p> <p>Or you can run the below command to change it, note it only works if the generated config contains <code>SystemdCgroup = false</code></p> <pre><code>sed -i 's/SystemdCgroup = false/SystemdCgroup = true/' /etc/containerd/config.toml \n</code></pre> <p>After the above command, you should see the below lines in <code>etc/containerd/config.toml</code></p> <pre><code>[plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.runc]\n  ...\n  [plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.runc.options]\n    SystemdCgroup = true\n</code></pre>"},{"location":"container/Containerd/02.Install_config_containerd/#33-change-sandbox-image-pull-url","title":"3.3 change sandbox image pull url","text":"<p>All pods in k8s require a sandbox image, the containerd default config has a default sandbox image pulling image. Based on the k8s version, you need to adapt this value.</p> <p>You should find the below line, and change the image url to your k8s required image url.</p> <pre><code>sandbox_image = \"k8s.lixx.cn/pause:3.10\"\n</code></pre> <p>Every Kubernetes Pod has a <code>Pause container</code>(sandbox container) that holds the <code>network namespace</code> and acts as the  parent of all other containers in the Pod. It has two main goals: - Keeps Pod Resources Active \u2013 It ensures that <code>networking and IPC resources remain stable</code> even if app containers restart.  - Efficient Namespace Sharing \u2013 Other containers in the Pod share its <code>PID, network, and IPC namespaces</code>.</p>"},{"location":"container/Containerd/02.Install_config_containerd/#34-custom-image-registry","title":"3.4 Custom image registry","text":"<p><code>containerd</code> allows us to use custom image registry. Suppose our image registry runs at https://reg.casd.local.</p> <p>You need to edit the containerd config file <code>/etc/containerd/config.toml</code></p> <pre><code>sudo vim /etc/containerd/config.toml\n\n# find the  plugins.\"io.containerd.grpc.v1.cri\".registry section in the config.tom\n# add the below line, you need to change the url value to your url\n[plugins.\"io.containerd.grpc.v1.cri\".registry]\n        [plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors]\n           [plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors.\"reg.casd.local\"]\n               endpoint = [\"https://reg.casd.local\"]\n        [plugins.\"io.containerd.grpc.v1.cri\".registry.configs.\"reg.casd.local\".tls]\n           insecure_skip_verify = true\n        [plugins.\"io.containerd.grpc.v1.cri\".registry.configs.\"reg.casd.local\".auth]\n           username = \"toto\"\n           password = \"chagneMe\"\n        [plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors.\"docker.io\"]\n          endpoint = [\"https://registry-1.docker.io\"]\n\n# now we need to reload the daemon\nsudo systemctl daemon-reload\n\n# restart containerd\nsudo systemctl restart containerd\n\n# try to pull an image from the private image registry\nsudo crictl pull reg.casd.local/casd/redis\n</code></pre> <p>DEPRECATION: The <code>mirrors</code> property of <code>[plugins.\"io.containerd.grpc.v1.cri\".registry]</code>  is deprecated since containerd v1.5 and will be removed in containerd v2.1. Use <code>config_path</code> instead.  For now, we don't migrate to <code>config_path</code>, because it does not provide all features(for example .auth).</p>"},{"location":"container/Containerd/02.Install_config_containerd/#35-restart-and-enable-containerd-service-on-all-the-nodes","title":"3.5 Restart and enable containerd service on all the nodes","text":"<pre><code>$ sudo systemctl restart containerd\n$ sudo systemctl enable containerd\n\n# you can check the service status\n$ sudo systemctl status containerd\n\n# check the version\ncontainerd --version\n\n# you can use the default containerd client to test\nctr version\n</code></pre>"},{"location":"container/Containerd/02.Install_config_containerd/#4-install-and-setup-containerd-client","title":"4. Install and setup containerd client","text":"<p>Below is a list of <code>containerd</code> major clients: - ctr: default - crictl: client compatbile with k8s</p>"},{"location":"container/Containerd/02.Install_config_containerd/#41-ctr","title":"4.1 ctr","text":"<p>containerd provides a CLI called <code>ctr</code>. It's a low-level CLI tool designed for <code>direct interaction with containerd</code>. It supports the complete life-cycle of a container(e.g. pull image, create  container, etc.) But it does not support the Kubernetes <code>CRI (Container Runtime Interface)</code>.</p> <pre><code># list containers\nctr containers list\n\n# pull image\nctr images pull docker.io/library/nginx:latest\n\n# list images\nsudo ctr images ls\n\n# run a container\nctr run --rm -t docker.io/library/nginx:latest my-nginx\n</code></pre> <p>All the cri pluging configurations in <code>/etc/containerd/config.toml</code> are ignored by ctr, because it does not support CRI. That's we recommend you to use crictl for testing.</p> <p>For more details of ctr , you can visit this page</p>"},{"location":"container/Containerd/02.Install_config_containerd/#42-crictl","title":"4.2 crictl","text":"<p>The official docs of <code>crictl</code> can be found here.</p> <p>The latest release version can be found here.</p> <p>Follow the below steps to install and config crictl</p> <pre><code># install crictl bin\nVERSION=\"v1.32.0\"\nwget https://github.com/kubernetes-sigs/cri-tools/releases/download/$VERSION/crictl-$VERSION-linux-amd64.tar.gz\nsudo tar zxvf crictl-$VERSION-linux-amd64.tar.gz -C /usr/local/bin\nrm -f crictl-$VERSION-linux-amd64.tar.gz\n\n# config crictl.yaml\ncat &lt;&lt;EOF | sudo tee /etc/crictl.yaml\nruntime-endpoint: unix:///run/containerd/containerd.sock\nimage-endpoint: unix:///run/containerd/containerd.sock\ntimeout: 2\ndebug: false\npull-image-on-create: false\nEOF\n</code></pre> <pre><code># list all images\nsudo crictl images\n\n# pull images\nsudo crictl pull reg.casd.local/casd/redis\n\n# list pods\nsudo crictl pods\n\n# list containers\nsudo crictl ps -a\n\n# get logs of a container\nsudo crictl logs &lt;conainer_id&gt;\n</code></pre>"},{"location":"container/Containerd/02.Install_config_containerd/#appendix-cgroup-and-systemd","title":"Appendix: cgroup and systemd","text":"<p>Control Groups (cgroups) and systemd are closely related because <code>systemd</code> is responsible for managing  system services and processes, and it heavily relies on <code>cgroups</code> to do so. </p> <ul> <li>systemd organizes processes using cgroups to track and manage resource usage; </li> <li>Every service, user session, or scope started by systemd gets its own cgroup. For example, the <code>nginx.service</code> runs in <code>/sys/fs/cgroup/system.slice/nginx.service/</code></li> <li>This allows fine-grained control over CPU, memory, I/O, and other resources.</li> </ul> <pre><code># test cgroup version\nmount | grep cgroup\n\n# expected output\ncgroup2 on /sys/fs/cgroup type cgroup2 (rw,nosuid,nodev,noexec,relatime,nsdelegate,memory_recursiveprot)\n\n\n# we can set max cpu and memory for a service\nsystemctl set-property nginx.service CPUQuota=50%\nsystemctl set-property nginx.service MemoryMax=500M\n</code></pre>"},{"location":"container/Docker/01.Install_docker_dockerCompose/","title":"Docker and Docker Compose","text":"<p>In this tutorial, we learn how to install docker and run a docker image(container)</p>"},{"location":"container/Docker/01.Install_docker_dockerCompose/#1introduction","title":"1.Introduction","text":""},{"location":"container/Docker/01.Install_docker_dockerCompose/#docker-editions","title":"Docker Editions","text":"<p>There are two editions of Docker available.</p> <ul> <li>Community Edition (CE): ideal for individual developers and small teams looking to get started with Docker and    experimenting with container-based apps.</li> <li>Enterprise Edition (EE): Designed for enterprise development and IT teams who build, ship, and run business-critical    applications in production at scale.</li> </ul> <p>This guide will cover installation of Docker CE on Debian Linux. But let\u2019s first look at common docker terminologies.</p>"},{"location":"container/Docker/01.Install_docker_dockerCompose/#docker-components-terminologies","title":"Docker Components / Terminologies","text":"<p>Below are commonly used terminologies in Docker ecosystem.</p> <ul> <li>Docker daemon: This is also called Docker Engine, it is a background process which runs on the host system responsible for building and running of containers.</li> <li>Docker Client: This is a command line tool used by the user to interact with the Docker daemon.</li> <li>Docker Image: An image is an immutable file that\u2019s essentially a snapshot of a container. A docker image has a file system and application dependencies required for running applications.</li> <li>Docker container: This is a running instance of a docker image with an application and its dependencies. Each container has a unique process ID and isolated from other containers. The only thing containers share is the Kernel.</li> <li>Docker registry: This is an application responsible for managing storage and delivery of Docker container images. It can be private or public.</li> </ul>"},{"location":"container/Docker/01.Install_docker_dockerCompose/#2-install-docker-ce-on-debian-121110","title":"2. Install Docker CE on Debian 12/11/10","text":"<p>1) Install Dependency packages Start the installation by ensuring that all the packages used by docker as dependencies are installed.</p> <pre><code>sudo apt update\nsudo apt -y install apt-transport-https ca-certificates curl gnupg2 software-properties-common\n</code></pre> <p>2) Add Docker\u2019s official GPG key Import Docker GPG key used for signing Docker packages.</p> <pre><code>curl -fsSL https://download.docker.com/linux/debian/gpg | sudo gpg --dearmor -o /etc/apt/trusted.gpg.d/docker-archive-keyring.gpg\n</code></pre> <p>3) Add the Docker repository Add Docker repository which contain the latest stable releases of Docker CE.</p> <pre><code>sudo add-apt-repository \\\n   \"deb [arch=amd64] https://download.docker.com/linux/debian \\\n   $(lsb_release -cs) \\\n   stable\"\n</code></pre> <p>This command will add the line shown in <code>/etc/apt/sources.list</code> file.</p> <p>4) Install Docker and Docker Compose</p> <pre><code>#Update the apt package index.\nsudo apt update\n\n# To install Docker CE on Debian, run the command:\nsudo apt install docker-ce docker-ce-cli containerd.io docker-compose-plugin -y\n\n\n# Start and enable docker service:\nsudo systemctl enable --now docker\n</code></pre> <p>This installation will add docker group to the system without any users. Add your user account to the group to run  docker commands as non-privileged user.</p> <pre><code># add docker group to current user\nsudo usermod -aG docker $USER\n\n# you need to re-login to get the updated group \n</code></pre>"},{"location":"container/Docker/01.Install_docker_dockerCompose/#3-test-the-docker-and-docker-compose","title":"3. Test the docker and docker compose","text":"<p>Check docker and compose version.</p> <pre><code>docker version\n\ndocker compose version\n</code></pre>"},{"location":"container/Docker/01.Install_docker_dockerCompose/#31-run-a-test-docker-container","title":"3.1 Run a test docker container","text":"<pre><code>docker run --rm -it  --name test alpine:latest /bin/sh\n\n# this will open a shell in the container, you can get the os info with below command\ncat /etc/os-release\nNAME=\"Alpine Linux\"\nID=alpine\nVERSION_ID=3.16.0\nPRETTY_NAME=\"Alpine Linux v3.16\"\nHOME_URL=\"https://alpinelinux.org/\"\nBUG_REPORT_URL=\"https://gitlab.alpinelinux.org/alpine/aports/-/issues\"\n\n# exit the shell\n</code></pre>"},{"location":"container/Docker/01.Install_docker_dockerCompose/#32-test-docker-compose","title":"3.2 Test Docker Compose","text":"<pre><code># Create a test Docker Compose file.\nvim docker-compose.yml\n\n# Add below data to the file.\nversion: '3'  \nservices:\n  web:\n    image: nginx:latest\n    ports:\n     - \"8080:80\"\n    links:\n     - php\n  php:\n    image: php:7-fpm\n\n# Start service containers. the current working directory must contain the compose config file\nsudo docker compose up -d\n\n# show running containers\nsudo docker compose ps\n\n# Destroy containers\ndocker compose stop\ndocker compose rm\n\n# output\nGoing to remove vagrant_web_1, vagrant_php_1\nAre you sure? [yN] y\nRemoving vagrant_web_1 \u2026 done\nRemoving vagrant_php_1 \u2026 done\n</code></pre>"},{"location":"container/Docker/01.Install_docker_dockerCompose/#4-docker-supervisionui","title":"4. Docker supervision(UI)","text":"<p>https://computingforgeeks.com/install-docker-ui-manager-portainer/</p>"},{"location":"container/Docker/02.Use_docker/","title":"Use docker","text":"<p>In this tutorial, we will list the useful commands of the docker </p>"},{"location":"container/Docker/02.Use_docker/#1-docker-daemon-management-commands","title":"1. docker daemon management commands","text":"<pre><code># Start the docker daemon \ndocker -d \n\n# Get help with Docker. Can also use help on all subcommands \ndocker --help \n\n# Display system-wide information \ndocker info\n\n# show docker version\ndocker version\n</code></pre>"},{"location":"container/Docker/02.Use_docker/#2-images-gestion","title":"2. Images gestion","text":""},{"location":"container/Docker/02.Use_docker/#21-build-image-from-docker-file","title":"2.1 Build image from docker file","text":"<p><code>docker build</code> command can build a <code>docker image</code> by using a <code>docker file</code>. The <code>-t</code> option is recommended, it ensures that your images are tagged properly.</p> <pre><code># general form\ndocker build -t &lt;image-name&gt;:&lt;tag-name&gt; &lt;docker-file-path&gt;\n\n# Build an Image from a Dockerfile, the current directory must contain a docker file \ndocker build -t &lt;image_name&gt;:&lt;version&gt; .\n\n# Build an Image from a Dockerfile without the cache\ndocker build -t &lt;image_name&gt;:&lt;version&gt; . no-cache   \n</code></pre> <p>Below is an example</p> <pre><code># create a folder to host docker file and related config file\nmkdir test_image\n\n# Put a docker file and config file in test_image\ntest_image/\n\u251c\u2500\u2500 config.sh\n\u2514\u2500\u2500 Dockerfile\n</code></pre> <p>The content of the <code>Dockerfile</code></p> <pre><code>FROM busybox:latest\nLABEL MAINTAINER=pengfei.liu@casd.eu\nLABEL version=\"1.0\"\nCOPY config.sh /etc/spark/config.sh\nRUN cat /etc/spark/config.sh      \n</code></pre> <p>The content of the <code>config.sh</code></p> <pre><code>export JAVA_HOME=/opt/java/java_8\n</code></pre> <p>You can find the full content of the docker file here</p> <p>Check the result</p> <pre><code># build an image with the given dockerfile\ndocker build -t my-img:0.0.1 ./test_image\n\n# check the image\ndocker image ls\n\n# output example\nREPOSITORY                            TAG                            IMAGE ID       CREATED          SIZE\nmy-img                                0.0.1                          b4ecf828f680   27 seconds ago   1.24MB\n</code></pre> <pre><code># convert a container to image\ndocker commit &lt;container_name/id&gt; &lt;image_name&gt;\n\n# List local images \ndocker images \n\n# Delete an Image \ndocker rmi &lt;image_name&gt; \n\n# Remove all unused images \ndocker image prune \n</code></pre>"},{"location":"container/Docker/02.Use_docker/#22-tag-and-push-the-local-image-to-remote-image-repo","title":"2.2 Tag and push the local image to remote image repo","text":"<p>The commands to tag and push images to remote repo may be different base on the remote repo. The below example shows how to tag and push images to: - docker hub - harbor</p>"},{"location":"container/Docker/02.Use_docker/#221-tag-an-image","title":"2.2.1 Tag an image","text":"<p>Before pushing the image to remote repo, we need to tag it properly.</p> <pre><code># general form\ndocker tag old_name[:TAG] new_name[:TAG]\n</code></pre>"},{"location":"container/Docker/02.Use_docker/#222-tag-and-push-to-docker-hub","title":"2.2.2 Tag and push to docker hub","text":"<p>The general form for the docker hub tag is /:.  In below example, we will push the local image <code>my-img:0.0.1</code> to dockerhub <code>liupengfei99/test:v2</code> <p>The repo <code>test</code> must be created before push </p> <pre><code># change the tag for docker hub\ndocker tag my-img:0.0.1 liupengfei99/test:v2\n\n# check the result\ndocker images\n\n# output\nREPOSITORY                            TAG                            IMAGE ID       CREATED          SIZE\nmy-img                                0.0.1                          b4ecf828f680   13 minutes ago   1.24MB\nliupengfei99/test                     v2                             b4ecf828f680   13 minutes ago   1.24MB\n\n# login to docker hub\ndocker login\n\n# push the image\ndocker push liupengfei99/test:v2\n</code></pre> <p>In your docker hub web ui, you should see the newly pushed image</p>"},{"location":"container/Docker/02.Use_docker/#223-tag-and-push-the-local-image-to-harbor","title":"2.2.3 Tag and push the local image to Harbor","text":"<p>In below example, we will push the local image <code>my-img:0.0.1</code> to harbor <code>reg.casd.local/test/test-img:v1</code></p> <p>The general form for the harbor tag is //:.  <pre><code># change the tag for harbor\ndocker tag my-img:0.0.1 reg.casd.local/test/test-img\n\n# check the new tag\ndocker images\n\n# output\nREPOSITORY                            TAG                            IMAGE ID       CREATED          SIZE\nmy-img                                0.0.1                          b4ecf828f680   25 minutes ago   1.24MB\nliupengfei99/test                     v2                             b4ecf828f680   25 minutes ago   1.24MB\nreg.casd.local/test/test-img          latest                             b4ecf828f680   25 minutes ago   1.24MB\n\n\n# login to harbor\ndocker login reg.casd.local\n\n# push the image\ndocker push reg.casd.local/test/test-img\n</code></pre> <p>Now you can check your harbor web UI, in the <code>project test</code>, you should see the image <code>test-img</code>.</p> <pre><code># login to docker public registry (docker hub)\ndocker login\n\n# tag the image\ndocker tag &lt;local-image-name&gt; &lt;username&gt;/repository:tag\n\n# for example, here pengfei99 is my docker hub account name, test is a repo of this account\ndocker tag pythondemo pengfei99/test:v1\n\n# check the tagged image\n# You can notice there is a new row liupengfei99/test which shares the same image id as pythondemo\ndocker image ls\nREPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\npythondemo          latest              3ea6dc02e4a6        24 minutes ago      131MB\nliupengfei99/test   v1                  3ea6dc02e4a6        24 minutes ago      131MB\npython              2.7-slim            ca96bab3e2aa        2 weeks ago         120MB\n\n\n# push the image to docker hub\ndocker push username/repository:tag\n\n# example\ndocker push liupengfei99/test:v1\n\n# pull and run the image from the remote repository\ndocker run -p 4000:80 liupengfei99/test:v1\n</code></pre>"},{"location":"container/Docker/02.Use_docker/#3-containers-management","title":"3. Containers management","text":"<pre><code># Create and run a container from an image, with a custom name: \ndocker run --name &lt;container_name&gt; &lt;image_name&gt; \n\n# Run a container with and publish a container\u2019s port(s) to the host. \ndocker run -p &lt;host_port&gt;:&lt;container_port&gt; &lt;image_name&gt; \n\n# Run a container in the background \n# -d option means run container in the detach mode\ndocker run -d &lt;image_name&gt; \n\n# Run a container in interactive mode\n# you can add -rm option to remove the container after stop\ndocker run -it &lt;image_name&gt; &lt;shell_path&gt;\n\n# Start or stop an existing container: \ndocker start|stop &lt;container_name&gt; (or &lt;container-id&gt;) \n\n# Remove a stopped container: \ndocker rm &lt;container_name&gt; \n\n# Fetch and follow the logs of a container: \ndocker logs -f &lt;container_name&gt; \n\n# To inspect a running container: \ndocker inspect &lt;container_name&gt; (or &lt;container_id&gt;) \n\n# To list currently running containers: \ndocker ps \n\n# List all docker containers (running and stopped): \ndocker ps --all/-a \n\n# View resource usage stats \ndocker container stats\n\n# copy data from container to local\ndocker cp &lt;container-name/id&gt;:&lt;data-path&gt; &lt;local-path&gt;\n\n# un example copy folder /apache-atlas/conf/ from container to /tmp/conf on local\ndocker cp atlas:/apache-atlas/conf/ /tmp/conf/\n</code></pre>"},{"location":"container/Docker/02.Use_docker/#31-debug-a-container","title":"3.1 Debug a container","text":"<p>To debug a container, you can show the logs, get a shell, etc.</p> <pre><code># Open a shell inside a running container: \n# in the shell_path, you need to put the path of which shell you want to use. \n# It also depends on the base image, for example, for the debian base image, you can use /bin/bash\ndocker exec -it &lt;container_name&gt; &lt;shell_path&gt; \n\n# show the live logs of a running daemon container\ndocker logs -f &lt;container_name&gt;\n\n# show the exposed ports of a container\ndocker port &lt;container_name&gt;\n</code></pre>"},{"location":"container/Docker/02.Use_docker/#32-mount-volume-on-container","title":"3.2 Mount volume on container","text":"<p>Docker containers are immutable by nature. This means that restarting a container erases all your stored data in  the container. To persist data, Docker provides two mechanisms: - docker volumes (The docker volume is a directory created by docker and host at the docker storage directory) - bind mounts (local directory which is created and managed by user.)</p>"},{"location":"container/Docker/02.Use_docker/#33-local-directory-binding","title":"3.3 Local directory binding","text":"<pre><code>docker run --name mysql-db -v $(pwd)/datadir:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=my-secret-pw -d mysql:8.0.28-debian\n</code></pre>"},{"location":"container/Docker/02.Use_docker/#4-docker-volume","title":"4. docker volume","text":"<pre><code># create the volume\ndocker volume create &lt;volume-name&gt;\n\n# list existing volume\ndocker volume list\n\n# mount volume on the container\ndocker run --name &lt;container-name&gt; -v &lt;volume-name&gt;:&lt;container-mount-path&gt; &lt;image-name&gt;\n\n# remove volume\ndocker volume remove &lt;volume-name&gt; \n</code></pre>"},{"location":"container/Docker/02.Use_docker/#5-docker-container-network","title":"5. Docker container network","text":"<p>Container networking refers to the ability for containers to communicate with other containers and/or host services.  <code>Containers have networking enabled by default</code>. A container has no information about what kind of network  it's attached to, or whether their peers are also Docker workloads or not. A container only sees a network  interface with an IP address, a gateway, a routing table, DNS services, and other networking details. </p>"},{"location":"container/Docker/02.Use_docker/#51-user-define-networks","title":"5.1 User define networks","text":"<p>You can create <code>user-defined networks, and connect multiple containers to the same network</code>. Once connected to a  user-defined network, containers can communicate with each other using container IP addresses or container names.</p> <p>The following example creates a network using the bridge network driver and running a container in the created network:</p> <pre><code># create a docker network\ndocker network create -d bridge my-network\n\n# create a container which uses the custom network\ndocker run --network=my-network -itd --name=container3 busybox\n</code></pre> <p>You can notice, when we create a network, we need to specify the network driver type.</p> <p>The following network drivers are available by default:</p> Driver Description bridge The default network driver. host Remove network isolation between the container and the Docker host. none Completely isolate a container from the host and other containers. overlay Overlay networks connect multiple Docker daemons together. ipvlan IPvlan networks provide full control over both IPv4 and IPv6 addressing. macvlan Assign a MAC address to a container."},{"location":"container/Docker/02.Use_docker/#52-attach-to-other-container-network","title":"5.2 Attach to other container network","text":"<p>In addition to user-defined networks, you can attach a <code>container to another container's networking stack directly,</code>  using the --network container: flag format. <p>The following flags aren't supported for containers using the container: networking mode:</p> <ul> <li>--add-host</li> <li>--hostname</li> <li>--dns</li> <li>--dns-search</li> <li>--dns-option</li> <li>--mac-address</li> <li>--publish</li> <li>--publish-all</li> <li>--expose</li> </ul> <p>The following example runs a Redis container, with Redis binding to localhost, then running the redis-cli command and  connecting to the Redis server over the localhost interface.</p> <pre><code>docker run -d --name redis redis --bind 127.0.0.1\ndocker run --rm -it --network container:redis redis-cli -h 127.0.0.1\n</code></pre>"},{"location":"container/Docker/02.Use_docker/#53-published-ports","title":"5.3 Published ports","text":"<p>By default, when you create or run a container using docker create or docker run, the container doesn't expose any  of its ports to the outside world. Use the --publish or -p flag to make a port available to services outside of  Docker. This creates a firewall rule in the host, mapping a container port to a port on the Docker host to the outside  world. Here are some examples:</p> Flag value Description -p 8080:80 Map port 8080 on the Docker host to TCP port 80 in the container. -p 192.168.1.100:8080:80 Map port 8080 on the Docker host IP 192.168.1.100 to TCP port 80 in the container. -p 8080:80/udp Map port 8080 on the Docker host to UDP port 80 in the container. -p 8080:80/tcp -p 8080:80/udp Map TCP port 8080 on the Docker host to TCP port 80 in the container, and map UDP port 8080 on the Docker host to UDP port 80 in the container. <p>Publishing container ports is insecure by default. Meaning, when you publish a container's ports it becomes available  not only to the Docker host, but to the outside world as well.</p> <p>If you include the localhost IP address (127.0.0.1) with the publish flag, only the Docker host can access the published container port.</p> <pre><code>docker run -p 127.0.0.1:8080:80 nginx\n</code></pre>"},{"location":"container/Docker/02.Use_docker/#6-delete-docker-objects","title":"6. ## Delete docker objects","text":"<p>After we created docker image, container, volume, network, we may need to delete them to clear the working space</p>"},{"location":"container/Docker/02.Use_docker/#61-purging-all-unused-or-dangling-resources","title":"6.1 Purging all unused or dangling resources","text":"<p>The first command is <code>system prune</code>, which will delete all unused Docker objects: - containers - images - networks - volumes</p> <p>Below are some command example</p> <pre><code># remove all unused objects\ndocker system prune\n\n# with the --filter option, we can filter which objects we want to delete.\n# the below example deletes containers that have been stopped for more than 24 hours.\n# -a option can clear the build cache and the intermediate image.\ndocker system prune -a --filter \"until = 24h\"\n</code></pre>"},{"location":"container/Docker/02.Use_docker/#62-deleting-container","title":"6.2 Deleting container","text":"<p>Below commands only delete containers</p> <pre><code># remove a single container\ndocker rm &lt;container_id/name&gt;\n\n# remove multiple containers\ndocker rm container_id1 container_id2 \n\n# remove all stopped containers\ndocker container prune \n\n# when you run a container, you can add option -rm to delete the container when it exists.\ndocker run -rm image_id/name\n\n# show all container id as a list\ndocker ps -a -q\n\n# stop all container\ndocker stop $(docker ps -a -q)\n\n# remove all container\ndocker rm $(docker ps -a -q)\n</code></pre>"},{"location":"container/Docker/02.Use_docker/#63-delete-container-image","title":"6.3 Delete container image","text":"<pre><code># delete a docker image\ndocker rmi image_name/id\n\n# delete multiple docker image\ndocker rmi image_id1 image_id2\n\n# remove image by using tag\ndocker rmi -f tag_name\n\n# remove all dangling image\ndocker image prune\n\n# remove all unused images(not linked to an existing container)\ndocerk image prune -a \n\n# remove all image\ndocker rmi $(docker images -a -q)\n</code></pre> <p>A dangling image just means that you've created the new build of the image, but it wasn't given a new name.  So the old images you have becomes the \"dangling image\". Those old image are the ones that are untagged and  displays \"\" on its name when you run docker images."},{"location":"container/Docker/02.Use_docker/#64-delete-container-volume","title":"6.4 Delete container volume","text":"<pre><code># delete one volume by using its name\ndocker volume rm volume_name\n\n# delete multiple volume\ndocker volume rm vol1 vol2\n\n# remove all unused volume\ndocker volume prune\n\n# add filter to remove\ndocker volume prune --filter \"label=test\"\n</code></pre>"},{"location":"container/Docker/02.Use_docker/#65-delete-docker-networks","title":"6.5 Delete docker networks","text":"<pre><code>docker network rm network_name/id\n\ndocker network rm net1 net2\n\n# remove all unused network\ndocker network prune\n\n# add a filter \ndocker network prune --filter \"until=24h\"\n</code></pre>"},{"location":"container/Docker/02.Use_docker/#66-remove-docker-compose-deployment","title":"6.6 Remove docker compose deployment","text":"<p>The below command example removes containers, images, volumes, networks, and undefined containers.</p> <pre><code># --rmi all Remove all images\n# -v Remove the named volumes declared in the volumes section of docker-compose.yml and the anonymous volumes attached to the container\n# --remove-orphans Remove containers not defined in docker-compose.yml\ndocker-compose down --rmi all -v --remove-orphans\n</code></pre> <p>You can not a delete a volume in use, if you try to delete, an error message <code>volume is in use</code> will be printed</p>"},{"location":"container/Docker/03.Use_docker_compose/","title":"Docker compose","text":"<p>In previous tutorial, we have seen how to use docker to run single container. Imagine that we have a list of container  to run for one service, and they need to be coordinated. For this kind of situation, we can use docker compose.</p> <p>Docker compose is used to manage applications and increase efficiency in container development. Configurations are defined in a single YAML file, making applications easy to build and scale. </p> <p>In short, Docker Compose uses a single docker-compose.yml configuration file to create a list of services(i.e. containers).</p>"},{"location":"container/Docker/03.Use_docker_compose/#1-requirements","title":"1. Requirements","text":"<p>To run docker compose, you need both Docker Engine and Docker Compose binaries. There are two ways:</p> <ul> <li>Install standalone binaries of Docker Engine and Docker Compose.</li> <li>Install Docker Desktop, It contains the Development environment with graphical user interface              including Docker Engine and Docker Compose.</li> </ul>"},{"location":"container/Docker/03.Use_docker_compose/#2-installation","title":"2. Installation","text":"<p>Check the first tutorial 01.Install_docker_dockerCompose.md.</p>"},{"location":"container/Docker/03.Use_docker_compose/#3-important-terms","title":"3. Important terms","text":"<p>There are three important component in the docker-compose.yml file:  - services  - volumes  - networks</p> <p>A simple example of docker-compose.yml</p> <pre><code>version: \"3.7\"\nservices:\n  ...\nvolumes:\n  ...\nnetworks:\n  ...\n</code></pre>"},{"location":"container/Docker/03.Use_docker_compose/#31-services","title":"3.1 Services","text":"<p>services refer to the containers\u2019 configuration.</p> <p>For example, let\u2019s take a dockerized web application consisting of a front end, a back end, and a database.  We\u2019d likely split these components into three images, and define them as three different services in the configuration:</p> <pre><code>services:\n  frontend:\n    image: my-vue-app\n    ...\n  backend:\n    image: my-springboot-app\n    ...\n  db:\n    image: postgres\n    ...\n</code></pre>"},{"location":"container/Docker/03.Use_docker_compose/#32-volumes","title":"3.2 Volumes","text":"<p>Volumes, are physical areas of disk space shared between the host and a container, or even between containers.  In other words, a volume is a shared directory in the host, visible from some or all containers.</p>"},{"location":"container/Docker/03.Use_docker_compose/#33-networks","title":"3.3 Networks","text":"<p>Networks define the communication rules between containers, and between a container and the host. Common network  zones will make the containers\u2019 services discoverable by each other, while private zones will segregate them in virtual sandboxes.</p>"},{"location":"container/Docker/03.Use_docker_compose/#4-more-about-services","title":"4. More about services","text":"<p>A service contains the below parts: - image  - network - volume - Dependencies</p>"},{"location":"container/Docker/03.Use_docker_compose/#41-getting-the-image","title":"4.1 Getting the image","text":"<p>There are two possibility: - pull image from docker registry (e.g docker hub, etc.):  - build locally from a docker file</p>"},{"location":"container/Docker/03.Use_docker_compose/#pull-image-from-docker-registry","title":"Pull image from docker registry","text":"<p>You need to configure the docker registry url (docker hub by default). Then you need to specify the image name and tag.</p> <p>Below is an example, which pulls an image <code>ubuntu</code> with tag <code>latest</code></p> <pre><code>services:\n   my-service:\n      image: ubuntu:latest\n</code></pre>"},{"location":"container/Docker/03.Use_docker_compose/#build-image-from-docker-file","title":"Build image from docker file","text":"<p>We will use the keyword build, and a docker file.</p> <p>Below is an example where the docker file is hosted locally</p> <pre><code>services: \n  my-custom-app:\n    build: /path/to/dockerfile/\n    ...\n</code></pre> <p>The docker file can be hosted remotely too. Below is an example where the docker file is hosted on github</p> <pre><code>services: \n  my-custom-app:\n    build: https://github.com/my-repo/my-project.git\n    ...\n</code></pre> <p>If you want to share the build image with others, you can add another line <code>(image:&lt;image-name&gt;)</code> like in below example</p> <pre><code>services: \n  my-custom-app:\n    build: /path/to/dockerfile/\n    image: my-project-image\n    ...\n</code></pre> <p>This will create an image on your local image registry after the build process</p>"},{"location":"container/Docker/03.Use_docker_compose/#42-configuring-the-network","title":"4.2 Configuring the network","text":"<p>There are two types of communication: - comm between host and containers - comm between containers</p>"},{"location":"container/Docker/03.Use_docker_compose/#communication-between-host-and-containers","title":"Communication between host and containers","text":"<p>** To reach a container from the host, the ports must be exposed declaratively through the ports keyword**. It will  match the container exposed port with the host port. The first value is the host port, the second value is the  container exposing port</p> <p>In below example, we have three services: - helloworld: expose the container port 80, and match it with the host port 80 - myapp1: expose the container port 3000, and match it with the host port 8080 - myapp2: expose the container port 3000, and match it with the host port 8081</p> <p>So if you type  - localhost:80, you will reach the helloworld service - localhost:8080, you will reach the myapp1 service - localhost:8081, you will reach the myapp2 service</p> <pre><code>services:\n  network-example-service:\n    image: helloworld:latest\n    ports:\n      - \"80:80\"\n    ...\n  my-custom-app:\n    image: myapp1:latest\n    ports:\n      - \"8080:3000\"\n    ...\n  my-custom-app-replica:\n    image: myapp2:latest\n    ports:\n      - \"8081:3000\"\n    ...\n</code></pre>"},{"location":"container/Docker/03.Use_docker_compose/#communication-between-containers","title":"Communication between containers","text":"<p><code>Docker containers communicate between themselves in networks created, implicitly or explicily.</code> By default, all  containers in the same services share the same default network. A service can communicate with another service on  the same network by simply referencing it by using : (e.g. container1:80). We can expose a  container port by using the expose keyword. <p>The below example expose port 80 of the service app 1. Other services inside the same network can access it by using <code>app1:80</code></p> <pre><code>services:\n  network-example-service:\n    image: app1:latest\n    expose:\n      - \"80\"\n</code></pre>"},{"location":"container/Docker/03.Use_docker_compose/#custom-networks","title":"Custom networks","text":"<p>If we don't want to use the default network set up, we can use custom network configuration. We can use networks keyword to define virtual networks to segregate containers. In below example, we create two virtual network: - public-network - private-network</p> <p>The <code>pub-service1</code> and <code>pub-service2</code> are in the <code>public-network</code>. so they can communicate between them.  The <code>private-service</code> is the only container in the <code>private-network</code>, so it can't communicate with  <code>pub-service1</code> and <code>pub-service2</code></p> <pre><code>services:\n  pub-service1:\n    image: alpine:latest\n    networks: \n      - public-network\n    ...\n  pub-service2:\n    image: alpine:latest\n    networks: \n      - public-network\n    ...\n  private-service:\n    image: alpine:latest\n    networks: \n      - private-network\n    ...\nnetworks:\n  public-network: {}\n  private-network: {}\n</code></pre>"},{"location":"container/Docker/03.Use_docker_compose/#43-configure-volumes","title":"4.3 Configure Volumes","text":"<p>There are three types of volumes:  - anonymous - named - host</p> <p>Anonymous and named volumes are managed by the Docker engine, Docker will generate the directories and store data  in the host. These volumes are automatically mounted when the container is started. </p> <p>The good practice is to use the named volume. Below are the commands of named volume management</p> <pre><code># create the volume\ndocker volume create &lt;volume-name&gt;\n\n# list existing volume\ndocker volume list\n\n# mount volume on the container\ndocker run --name &lt;container-name&gt; -v &lt;volume-name&gt;:&lt;container-mount-path&gt; &lt;image-name&gt;\n\n# remove volume\ndocker volume remove &lt;volume-name&gt; \n</code></pre> <p>Host volumes allow us to specify an existing folder in the host and mount it with a specific path on the container.</p> <p>In the below example, we have two services: - app1: has three volumes, the two first volumes are <code>host volumes</code> which matches existing host directory with container         directory. The last one uses a <code>named volume</code>. You can also notice, we need to declare the <code>named volume</code>          first in the upper level volumes specs.</p> <p>To mount a volume in read-only mode by appending :ro to the volume declaration. For example <code>/home:/my-volumes/readonly-host-volume:ro</code>  specifies that the <code>/home</code> folder is read only. (we don\u2019t want a Docker container erasing our users by mistake).</p> <pre><code>services:\n  app1:\n    image: alpine:latest\n    volumes: \n      - /tmp:/my-volumes/host-volume\n      - /home:/my-volumes/readonly-host-volume:ro\n      - my-named-volume:/my-volumes/named-global-volume\n    ...\n  app2:\n    image: alpine:latest\n    volumes:\n      - my-named-volume:/another-path/the-same-named-global-volume\n    ...\nvolumes:\n  my-named-volume: \n</code></pre>"},{"location":"container/Docker/03.Use_docker_compose/#44-container-dependencies","title":"4.4 Container dependencies","text":"<p>We need to create a <code>dependency chain between our services</code> so that some services get loaded before (and unloaded after)  other ones. We can achieve this result through the depends_on keyword:</p> <p>Below examples specifies that service kafka needs zookeeper to run first.</p> <pre><code>services:\n  kafka:\n    image: kafka\n    depends_on:\n      - zookeeper\n    ...\n  zookeeper:\n    image: zookeeper\n    ...\n</code></pre> <p>We should be aware, however, that Compose won\u2019t wait for the zookeeper service to finish loading before starting the  kafka service; it\u2019ll simply wait for it to start. If we need a service to be fully loaded before starting another service,  we need to get deeper control of the startup and shutdown order in Compose.</p>"},{"location":"container/Docker/03.Use_docker_compose/#5-managing-environment-variables","title":"5. Managing Environment Variables","text":"<p>Working with environment variables is easy in Compose. We can define static environment variables, as well  as dynamic variables, with the ${} notation:</p> <p>To define the environment values, we have the following approaches: 1. Compose file 2. Shell environment variables 3. Environment file 4. Dockerfile 5. Variable not defined.</p> <p>We can mix the above approaches, but let\u2019s keep in mind that Compose uses the priority order (1 has the highest order),  overwriting the value of less important approaches with the higher priorities approaches</p> <p>Once you have declared the <code>Environment Variables</code>, you can use them in your docker-compose file. Below is an example on how to use env var in the <code>docker-compose file</code>.</p> <pre><code>services:\n  database: \n    image: \"postgres:${POSTGRES_VERSION}\"\n    environment:\n      DB: mydb\n      USER: \"${USER}\"\n</code></pre>"},{"location":"container/Docker/03.Use_docker_compose/#51-declare-env-var-in-docker-compose-file","title":"5.1 Declare env var in docker compose file","text":"<p>You can set environment variables directly in your Compose file. This option has many limitation. The value is visible which makes it hard to version your compose file.</p> <pre><code>services:\n  webapp:\n    image: my-webapp-image\n    environment:\n      DB: mydb\n      USER: toto\n</code></pre> <p>You can also use the -e option in the docker run/compose command. For example</p> <pre><code>docker run -e \"[variable-name]=[new-value]\"\ndocker run -e \"DEBUG=1\"\n\ndocker compose -e \"[variable-name]=[new-value]\"\ndocker compose -e \"DEBUG=1\"\n</code></pre>"},{"location":"container/Docker/03.Use_docker_compose/#52-declare-env-var-in-shell-environment-variables","title":"5.2 Declare env var in Shell environment variables","text":"<pre><code># we declare the env var before calling the docker compose command\nexport POSTGRES_VERSION=alpine\nexport USER=foo\n\ndocker-compose -f docker-compose-file.yaml up\n</code></pre>"},{"location":"container/Docker/03.Use_docker_compose/#53-declare-env-var-in-environment-file","title":"5.3 Declare env var in Environment file","text":"<p>An .env file in Docker Compose is a <code>text file</code> used to define environment variables that should be made  available to Docker containers when running docker compose up. This file typically contains <code>key-value pairs of  environment variables</code>, and it allows you to centralize and manage configuration in one place. </p> <p>The .env file is the default method for setting environment variables in your containers. It is very useful if     you have multiple environment variables you need to store.</p> <p>The .env file should be placed at the root of the project directory next to your compose.yaml file.  For more information on formatting an environment file,  see Syntax for environment files.</p> <p>When you run <code>docker compose up</code>, all the env var inside the compose file will be replaced by the values of the  env file and generate the final config file. You can verify the generated config file by using below command:</p> <pre><code>docker compose config\n</code></pre> <p>For example If you define an environment variable <code>DEBUG=1</code> in your <code>.env file</code>, and your <code>compose.yml</code> file  looks like this:</p> <pre><code> services:\n    webapp:\n      image: my-webapp-image\n      environment:\n        - DEBUG=${DEBUG}\n</code></pre> <p>Docker Compose replaces ${DEBUG} with the value <code>1</code> from the <code>.env file</code>.</p>"},{"location":"container/Docker/03.Use_docker_compose/#multiple-env-file","title":"Multiple env file","text":"<p>You can use multiple .env files in your compose.yml with the env_file attribute, and <code>Docker Compose reads them  in the order specified</code>. If the same variable is defined in multiple files, the last definition takes precedence:</p> <pre><code>services:\n  webapp:\n    image: my-webapp-image\n    env_file:\n      - path: ./default.env\n        required: true # default value\n      - path: ./override.env\n        required: false # this env file is Optional\n</code></pre> <p>You can also use the <code>--env-file</code> to add custom env file while running the docker compose command</p>"},{"location":"container/Docker/03.Use_docker_compose/#54-declare-env-var-in-docker-file","title":"5.4 Declare env var in Docker file","text":"<p>You can define as many env var in the Docker file as want use ENV VAR1=$TEST1</p>"},{"location":"container/Docker/03.Use_docker_compose/#6-scaling-and-replicas","title":"6. Scaling and Replicas","text":"<p>The <code>docker-compose scale</code> command. Newer versions deprecated it, and replaced it with the scale option.</p> <p>Below is an example how to use Docker swarn(a cluster of Docker engines) to autoscale our containers.</p> <p>The deploy section is effective only when deploying to docker swarn.</p> <pre><code>services:\n  worker:\n    image: my-webapp-image\n    networks:\n      - frontend\n      - backend\n    deploy:\n      mode: replicated\n      replicas: 6\n      resources:\n        limits:\n          cpus: '0.50'\n          memory: 50M\n        reservations:\n          cpus: '0.25'\n          memory: 20M\n      ...\n</code></pre>"},{"location":"container/Docker/03.Use_docker_compose/#7-lifecycle-management","title":"7. Lifecycle management","text":"<p>The general docker compose command can be found Here</p> <p>Note the newer version, the command is no longer <code>docker-compose</code>, but <code>docker compose</code> </p> <p>The docker container lifecycle can be described as: - Create - Run - Pause - Stop - Delete</p> <p>The below image shows the commands to change the state of the container </p> <p></p>"},{"location":"container/Docker/03.Use_docker_compose/#71-servicelist-of-containers-creation","title":"7.1 Service(List of containers) creation","text":"<p>The <code>docker compose up</code> command builds, (re)creates, starts, and attaches to containers for a service.</p> <p>Unless they are already running, this command also starts any linked services.</p> <pre><code>docker compose [-f &lt;arg&gt;...] [options] [COMMAND] [ARGS...]\n\n# container creation, If the config file has a different name than the default one (docker-compose.yml), we must use\n# the option -f to specify the config file path\n# the -d option makes the compose process run in the background\ndocker compose -f &lt;docker-compose-file-path&gt; up -d\n</code></pre>"},{"location":"container/Docker/03.Use_docker_compose/#72-running-the-services","title":"7.2 Running the services","text":"<p>Starts existing containers for a service</p> <pre><code># run container, if the containers are already created \ndocker compose -f &lt;docker-compose-file-path&gt; start\n</code></pre>"},{"location":"container/Docker/03.Use_docker_compose/#73-pauseunpause-the-services","title":"7.3 Pause/Unpause the services","text":"<p>Pause/Unpause a running service</p> <pre><code>docker compose -f &lt;docker-compose-file-path&gt; pause/unpasue\n</code></pre>"},{"location":"container/Docker/03.Use_docker_compose/#74-stop-the-services","title":"7.4 Stop the services","text":"<p>There are different level of stop. </p> <pre><code># Stops running containers without removing them. They can be started again with docker compose start.\ndocker compose stop\n\n# Stops containers and removes containers, networks, volumes, and images created by up.\ndocker compose down\n</code></pre>"},{"location":"container/Docker/03.Use_docker_compose/#an-application-example","title":"An application example","text":"<p>You can follow this tutorial to have a first idea how a docker  compose service runs.</p> <p>You can find the source file in src/composetest</p>"},{"location":"container/Helm_chart_registry/01.Deploy_a_helm_chart_registry/","title":"Setup local helm chart registry","text":"<p>A local helm chart registry is essential when your k8s cluster does not have internet connection, or it can't use  <code>public helm chart repo</code> to pull the helm chart. </p> <p>In this tutorial, we will introduce two ways to set up a private helm chart registry - Harbor oci registry - chart museum </p>"},{"location":"container/Helm_chart_registry/01.Deploy_a_helm_chart_registry/#1-use-harbor-oci-registry","title":"1. Use Harbor oci registry","text":"<p>Harbor provides an oci registry which can store, share helm charts. </p> <p>If you want to play with the oci registry in Harbor, you can read this Harbor_helm_chart_management.md </p> <p>But Onyxia does not support OCI registry. So we can not use harbor to manage helm chart.</p>"},{"location":"container/Helm_chart_registry/01.Deploy_a_helm_chart_registry/#2use-chart-museum","title":"2.Use chart museum","text":"<p>chartmuseum is an open-source Helm Chart Repository server  written in Go (Golang), with support for various cloud storage backends.</p>"},{"location":"container/Helm_chart_registry/01.Deploy_a_helm_chart_registry/#21-install-chart-museum","title":"2.1 Install Chart museum","text":"<p>You can find the official installation doc here. In this tutorial, I only focus on linux bare metal installation</p> <pre><code># get the installation script and run it\ncurl https://raw.githubusercontent.com/helm/chartmuseum/main/scripts/get-chartmuseum | bash\n\n# you should see below output, it means the chartmuseum binary is installed in /usr/local/bin\nDownloading https://get.helm.sh/chartmuseum-v0.15.0-linux-amd64.tar.gz\nVerifying checksum... Done.\nPreparing to install chartmuseum into /usr/local/bin\nchartmuseum installed into /usr/local/bin/chartmuseum\n\n# check the version\nchartmuseum --version\n\n# get help\nchartmuseum --help\n</code></pre>"},{"location":"container/Helm_chart_registry/01.Deploy_a_helm_chart_registry/#22-configure-chartmuseum","title":"2.2 Configure chartmuseum","text":"<p>There are three ways to configure chartmuseum - command line options - env var - config file</p> <p>Here we use config file, because it's simpler to communicate how the chartmuseum is built. </p> <p>The options that can be used in the config file can be found in this file</p> <p>Below is a simple <code>config.yaml</code> to run a minimum instance for test. In linux os-system, it's recommended to but the config.yaml file in <code>/etc/chartmuseum</code>.</p> <pre><code>debug: true\nport: 8080\nstorage.backend: local\nstorage.local.rootdir: /data\nbasicauth.user: admin\nbasicauth.pass: changeMe\nauthanonymousget: true\ndepth: 0\n</code></pre> <pre><code># run the chartmuseum with the given config file\nchartmuseum --config /etc/chartmuseum/config.yaml\n\n# you can access the web interface\nhttp://ip:8080\n</code></pre> <p>You can use <code>Nginx as the reverse proxy</code> to protect the chart museum. For more information, please visit this doc</p>"},{"location":"container/Helm_chart_registry/01.Deploy_a_helm_chart_registry/#23-upload-chart-to-chartmuseum","title":"2.3 Upload chart to chartMuseum","text":"<p>There are two ways to push charts to ChartMuseum: - via the <code>api of chartMuseum</code> - via helm cm-push plugin, the easiest way is to use helm cm-push plugin. You can find the official github page here </p>"},{"location":"container/Helm_chart_registry/01.Deploy_a_helm_chart_registry/#231-upload-chart-via-the-api-of-chartmuseum","title":"2.3.1 Upload chart via the api of chartMuseum","text":"<pre><code># push a chart via the api of chartMuseum\ncurl -F \"chart=@hello-world-0.1.0.tgz\" https://chart.casd.local/api/charts\n\ncurl --data-binary \"@hello-world-0.1.0.tgz\" https://chart.casd.local/api/charts\n\n# If you\u2019ve signed your package and generated a provenance file, upload it with:\ncurl --data-binary \"@hello-world-0.1.0.tgz.prov\" http://chart.casd.local/api/prov\n\n# Or you can upload both at same time\ncurl -F \"chart=@hello-world-0.1.0.tgz\" -F \"prov=@hello-world-0.1.0.tgz.prov\" http://chart.casd.local/api/charts\n</code></pre> <p>The name of the .tgz will not impact the version of the chart, the chartMuseum will read the <code>Chart.yaml</code> in the  package to determine version. </p>"},{"location":"container/Helm_chart_registry/01.Deploy_a_helm_chart_registry/#232-upload-chart-via-helm","title":"2.3.2 Upload chart via helm","text":"<pre><code># install the binary of helm push plugin\nhelm plugin install https://github.com/chartmuseum/helm-push\n\n# check the installed plugin\nhelm cm-push  --help\n\n# add your private chartmuseum as a repo\nhelm repo add --username admin --password changeMe cm https://chart.casd.local/\n\n# list all added repo\nhelm repo list\n\n# update the index of a repo\nhelm repo update\n\n# Search a chart on all the added repo with a give keyword\nhelm search repo &lt;keyword&gt;\n\n# if you want to use regex, you need to use option -r\nhelm search repo -r \".*\"\n\n# to further filter your result, you can add an grep after\nhelm search repo -r \"nginx\" | grep -i \"bitnami\"\n\n# push the chart, with the plugin, you don't need to do helm package anymore\n# you can push the directory directly, the plugin will package the chart, then push\nhelm cm-push hello-world/ cm\n\n# Push .tgz package is still supported\nhelm cm-push hello-world-0.1.0.tgz cm\n\n# push with a custom version\nhelm cm-push hello-world/ --version=\"0.2.0\" cm\n\n# If your ChartMuseum install is configured with ALLOW_OVERWRITE=true, chart versions will be automatically overwritten upon re-upload.\n# Otherwise, the upload will be denied with message file already exist. Unless your install is configured with DISABLE_FORCE_OVERWRITE=true (ChartMuseum &gt; v0.7.1), you can use the --force/-f option to to force an upload to overwrite an existing chart\nhelm cm-push --force hello-world-0.2.1.tgz chartmuseum\n\n# push without adding chart repo. Below example shows how to push to an repo directly\nhelm cm-push hello-world-0.2.1.tgz http://chart.casd.local/\n\n\n# Remove a repo\nhelm repo remove &lt;repo-name&gt;\n</code></pre> <p>note you need to run helm repo update to fetch the new index.yaml of each repo to get the latest uploaded chart</p>"},{"location":"container/Helm_chart_registry/01.Deploy_a_helm_chart_registry/#24-chartmuseum-authentication","title":"2.4 chartMuseum Authentication","text":""},{"location":"container/Helm_chart_registry/01.Deploy_a_helm_chart_registry/#basic-auth","title":"Basic auth","text":"<p>If the chartMuseum is installed with basic authentication enabled, you need to add user credential  when you add repo</p> <pre><code># option 1\nhelm repo add --username admin --password changeMe cm https://chart.casd.local/\n\n# option 2\n# The plugin will use the auth info located in ~/.config/helm/repositories.yaml\n\n# option 3\n# Use below env var\nexport HELM_REPO_USERNAME=\"myuser\"\nexport HELM_REPO_PASSWORD=\"mypass\"\n</code></pre>"},{"location":"container/Helm_chart_registry/01.Deploy_a_helm_chart_registry/#tls","title":"TLS","text":"<p>ChartMuseum uses the linux system ca-cert folder. If you use a self signed certificat, you can add the custom CA certificat on the server where you have installed the helm cm-push plugin.  </p> <p>If you don't have admin rights to do so, you can use below option to make changes on the plugin when adding repo</p> <ul> <li>--ca-file string:  Verify certificates of HTTPS-enabled servers using this CA bundle [$HELM_REPO_CA_FILE]</li> <li>--cert-file string:  Identify HTTPS client using this SSL certificate file [$HELM_REPO_CERT_FILE]</li> <li>--key-file string:   Identify HTTPS client using this SSL key file [$HELM_REPO_KEY_FILE]</li> <li>--insecure:          Connect to server with an insecure way by skipping certificate verification [$HELM_REPO_INSECURE]</li> </ul>"},{"location":"container/Helm_chart_registry/01.Deploy_a_helm_chart_registry/#appendix","title":"Appendix","text":""},{"location":"container/Helm_chart_registry/01.Deploy_a_helm_chart_registry/#set-up-a-systemd-daemon","title":"Set up a systemd daemon","text":"<p>To be able to run chartmuseum as a daemon, you can add the following file <code>/etc/systemd/system/chartmuseum.service</code> We recommend you to use the <code>config.yaml</code> to configure the chartmuseum daemon.</p> <pre><code>[Unit]\nDescription=chartmuseum\nDocumentation=Helm Chart Repository\nRequires=network-online.target\nAfter=network.target\n\n[Service]\nUser=root\nRestart=allways\nExecStart=/usr/local/bin/chartmuseum --config /etc/chartmuseum/config.yaml\nExecStop=/usr/local/bin/chartmuseum step-down\n[Install]\nWantedBy=multi-user.target\n</code></pre> <p>There is another way if you don't want to use the config.yaml, you can use $ARGS to specify the configuration. (Not recommended)</p> <pre><code>[Unit]\nDescription=chartmuseum\nDocumentation=Helm Chart Repository\nRequires=network-online.target\nAfter=network-online.target\n\n[Service]\nEnvironmentFile=/etc/chartmuseum/chartmuseum.config\nUser=root\nRestart=allways\nExecStart=/usr/local/bin/chartmuseum $ARGS\nExecStop=/usr/local/bin/chartmuseum step-down\n\n[Install]\nWantedBy=multi-user.target\n</code></pre> <p>The <code>chartmuseum.config</code> looks like</p> <pre><code>ARGS=\\\n--port=8080 \\\n--storage=\"local\" \\\n--storage-local-rootdir=\"/data\" \\\n--log-json \\\n--basic-auth-user=admin \\\n--basic-auth-pass=\"changeMe\" \\\n--auth-anonymous-get\n</code></pre>"},{"location":"container/Helm_chart_registry/01.Deploy_a_helm_chart_registry/#how-to-generate-a-provenance-file","title":"How to generate a provenance file ?","text":""},{"location":"container/Image_registry/04.Use_private_image_registry/","title":"Use private image registry with container runtime","text":"<p>Suppose we have a harbor instance runs at 192.168.0.5. The url of our Harbor instance  is (https://reg.casd.local) and it uses self-signed certificate or singed by a private CA.</p> <p>There are many container runtimes, in this tutorial here we only shows two: - Docker - Containerd</p>"},{"location":"container/Image_registry/04.Use_private_image_registry/#1-add-the-certificate-as-trusted-in-your-system-optional","title":"1. Add the certificate as trusted in your system. (Optional)","text":"<p>If the certificate which enables the https of your harbor is a self-signed certificate, you only need to copy the  certificate. If your certificate is signed by a CA, you need to copy the CA certificate. </p> <p>First add the certificate as accepted root ca in your system.</p> <pre><code># The debian distro only accepts pem or crt as valid certificate. If your certificate is in other format, you need to\n# convert it to the valid format.\ncp your-ca.crt /usr/local/share/ca-certificates/.\n\n# update the certificate cache\nsudo update-ca-certificates\n\n# test it with a site which uses the certificate or signed by the certificate\ncurl https://target-url\n\n# if the certificate is added correctly, you should not see error message\n</code></pre> <p>If you are admin of the Harbor server too, don't copy the private key in any case. </p>"},{"location":"container/Image_registry/04.Use_private_image_registry/#2-docker-client-use-private-image-registry","title":"2. Docker client use private image registry","text":"<p>There is two ways to connect a docker engine to a private image registry: - Add the certificate of the private image registry as trusted certificate. - Add the private image registry as the allowed insecure-registries (by default only localhost is allowed)</p>"},{"location":"container/Image_registry/04.Use_private_image_registry/#21-add-the-private-image-registry-as-the-allowed-insecure-registries","title":"2.1 Add the private image registry as the allowed insecure-registries","text":"<p>This solution is quite simple after you installed docker engine under debian, a directory /etc/docker should be created.</p> <pre><code># create a daemon.json file in /etc/docker\nsudo vim /etc/docker/daemon.json\n\n# put the below line in it, where reg.casd.local is the url of the private image registry. If the service runs on 80 or\n# 443, you don't need to specify the prot. If it runs on another port (e.g. 5000). You need to put \"reg.casd.local:5000\"\n{\n    \"insecure-registries\" : [ \"reg.casd.local\" ]\n}\n\n# update the docker daemon\nsudo systemctl daemon-reload\nsudo systemctl restart docker\n</code></pre> <p>Now let's do some test. Here we recommend you to add the docker group to current user. Because docker login will create credential files and stores on your user home directory. And sudo will change the home directory.</p> <pre><code># add docker group to current user\nsudo usermod -aG docker $USER\n</code></pre> <pre><code># 1. login to the private registry\ndocker login reg.casd.local\n\n# 2. Download an image from docker hub\ndocker pull redis\n\n# 3. tag it to push to private registry, here reg.casd.local is the url. casd is the project name\ndocker tag redis reg.casd.local/casd/redis \n\n# 4. push the image to the private registry\ndocker push reg.casd.local/casd/redis\n\n# 5. pull image from the private registry\ndocker pull reg.casd.local/casd/redis\n</code></pre>"},{"location":"container/Image_registry/04.Use_private_image_registry/#22-add-the-certificate","title":"2.2 Add the certificate","text":"<p>As we mentioned before, the url of our Harbor instance is (https://reg.casd.local) and it uses a certificate signed by a private CA.</p> <p>In your server which runs the docker runtime, you can put all trusted CA inside this folder <code>/etc/docker/certs.d</code>.  For each registry, you need to create a sub-folder named with the <code>url or IP</code> of the image registry. For example, the url our image registry is <code>reg.casd.local</code>. So the folder should be like <code>/etc/docker/certs.d/reg.casd.local</code> Then you put the CA certificate in this folder. (Tested under debian)</p>"},{"location":"container/Image_registry/04.Use_private_image_registry/#23-add-the-private-repo-as-content-trustto-be-tested","title":"2.3 Add the private repo as content trust(To be tested)","text":"<pre><code>export DOCKER_CONTENT_TRUST=1\nexport DOCKER_CONTENT_TRUST_SERVER=https://reg.casd.local:4443\n</code></pre>"},{"location":"container/Image_registry/04.Use_private_image_registry/#k8s-integration","title":"K8s integration","text":"<p>Even thought the containerd daemon can pull/push images from the private registry, k8s deployment does not work directly we still need to add a secret to host the login password of the registry</p> <pre><code># general form\nkubectl create secret docker-registry &lt;secret-name&gt; \\\n--docker-server=&lt;your-registry-server-url&gt; \\\n--docker-username=&lt;your-name&gt; \\\n--docker-password=&lt;your-pword&gt; \\\n--docker-email=&lt;your-email&gt;\n\n# for example\nkubectl create secret docker-registry harbor-auth \\\n--docker-server=\"reg.casd.local\" \\\n--docker-email=pengfei.liu@casd.eu \\\n--docker-username='toto' \\\n--docker-password='changeMe' \n</code></pre> <p>In the <code>deployment.yaml</code> which uses images from the private registry, you need to add the <code>imagePullSecrets:</code> spec which specifies the credential to access the private registry.</p> <p>Below is an example, as the above secret creation example, the secret name is <code>harbor-auth</code></p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mario\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: mario\n  template:\n    metadata:\n      labels:\n        app: mario\n    spec:\n      containers:\n        - name: mario\n          image: reg.casd.local/casd/docker-supermario\n          ports:\n            - name: http\n              containerPort: 8080\n      imagePullSecrets:\n        - name: harbor-auth\n</code></pre>"},{"location":"container/Image_registry/harbor/02.Harbor_installation/","title":"Install Harbor","text":"<p>The official installation doc can be found here</p>"},{"location":"container/Image_registry/harbor/02.Harbor_installation/#1-prepare-prerequisites","title":"1. Prepare prerequisites","text":"<p>You can find the complete requirement here</p>"},{"location":"container/Image_registry/harbor/02.Harbor_installation/#hardware","title":"Hardware","text":"<p>The following table lists the minimum and recommended hardware configurations for deploying Harbor.</p> <pre><code>Resource    Minimum Recommended\nCPU 2 CPU   4 CPU\nMem 4 GB    8 GB\nDisk    40 GB   160 GB\n</code></pre>"},{"location":"container/Image_registry/harbor/02.Harbor_installation/#software","title":"Software","text":"<p>The following table lists the software versions that must be installed on the target host.</p> <ul> <li>docker engine</li> <li>docker compose</li> <li>openssl</li> </ul> <p>To install docker engine and compose, you can follow this doc.</p> <pre><code># install openssl\nsudo apt install openssl\n</code></pre>"},{"location":"container/Image_registry/harbor/02.Harbor_installation/#2-download-the-harbor-installer","title":"2. Download the harbor Installer","text":"<p>The official release page is here. You can find two type of installer: - Online: The online installer downloads the Harbor images from Docker hub. For this reason, the installer is very small in size. - Offline: The offline installer contains pre-built images, so it is larger than the online installer. Use the offline installer if the host to which are deploying Harbor does not have a connection to the Internet. </p> <p>In this tutorial, we use the offline installer of harbor v2.6.1 (latest of 02/11/2022)</p> <pre><code># download the installer \nwget https://github.com/goharbor/harbor/releases/download/v2.6.1/harbor-offline-installer-v2.6.1.tgz\n\n# unzip it\ntar -xzvf harbor-offline-installer-version.tgz\n\n# after unzip, you should see a folder harbor with below content\nharbor\n\u251c\u2500\u2500 common.sh\n\u251c\u2500\u2500 harbor.v2.6.1.tar.gz\n\u251c\u2500\u2500 harbor.yml.tmpl\n\u251c\u2500\u2500 install.sh\n\u251c\u2500\u2500 LICENSE\n\u2514\u2500\u2500 prepare\n</code></pre> <ul> <li>harbor.yml.tmpl: is the config template</li> <li>prepare : is the preconfig script for setup https and required certficate</li> </ul>"},{"location":"container/Image_registry/harbor/02.Harbor_installation/#3-prepare-certificate","title":"3. Prepare certificate","text":"<p>If you don't have CA and client certs, you can follow the PKI_cfssl doc to generate them. </p> <p>If you already have them, you can put them in  - certificate folder of your harbor host: <code>/data/cert/</code>. In the <code>harbor.yml</code>, we will mount <code>/data</code> to the harbor container. - docker certificate folder <code>/etc/docker/certs.d/yourdomain.com/</code>. In our case, it should be <code>/etc/docker/certs.d/casd.local</code></p> <p>The Docker daemon interprets <code>.crt</code> files as <code>CA certificates</code> and <code>.cert</code> files as client certificates. So you may need to convert your client certificate from .crt to .cert format</p> <pre><code># convert client certificate format\n# in fact, the content is the same for the two format, so you can just rename it with .cert.\nopenssl x509 -inform PEM -in casd.local.crt -out casd.local.cert\n\n# copy them into harbor cert folder\ncp casd.local.crt /data/cert/\ncp casd.local.key /data/cert/\n\n# copy them into the docker cert folder\ncp casd.local.cert /etc/docker/certs.d/casd.local/\ncp casd.local.key /etc/docker/certs.d/casd.local/\ncp ca.crt /etc/docker/certs.d/casd.local/\n</code></pre>"},{"location":"container/Image_registry/harbor/02.Harbor_installation/#custom-port","title":"Custom port","text":"<p>If you mapped the default nginx <code>port 443 to a different port</code>, create the folder with the custom port</p> <pre><code># with a domain name\n/etc/docker/certs.d/yourdomain.com:port\n\n# or with an ip if you want to expose harbor with an IP\n/etc/docker/certs.d/harbor_IP:port.\n</code></pre> <p>You need to restart docker <code>systemctl restart docker</code> to make change effective.</p>"},{"location":"container/Image_registry/harbor/02.Harbor_installation/#4-configure-harbor-yaml-file","title":"4. Configure Harbor Yaml file","text":"<pre><code># use the template as the base of the config\ncp harbor.yml.tmpl harbor.yml.\n</code></pre> <p>You can find a complete explication about every attribute on this page. </p> <p>We recommend you to at least change the </p> <ul> <li><code>hostname</code></li> <li><code>https</code> with appropriate certificates</li> <li><code>admin password</code></li> <li><code>data_volume</code></li> </ul> <p>You can find an example in harbor.yaml</p>"},{"location":"container/Image_registry/harbor/02.Harbor_installation/#5-run-the-installer-script","title":"5. Run the installer script","text":"<p>Once you have configured <code>harbor.yml</code>, you can install and run Harbor by using <code>install.sh</code> script.</p> <p>By default, it only deploys Harbor, you can enable other modules with extra options - Notary : The module which can verify the origin of an image. More doc here</p> <ul> <li>Trivy : Vulnerabilites scanner of image. More doc here</li> <li>chartmuseum: an open source <code>helm chart repository server</code>. More doc here</li> </ul> <p>Notary and chartmuseum is deprecated since Harbor v2.7.0.</p> <pre><code># Without any extra module\nsudo ./install.sh\n\n# with all module\nsudo ./install.sh --with-trivy \n</code></pre> <p>This command will first generate all required manifest and config for docker compose in <code>/path/to/harbor/common/config</code>, then apply them with docker compose.</p> <p>--with-notary --with-chartmuseum option are deprecated, don't use them.</p>"},{"location":"container/Image_registry/harbor/02.Harbor_installation/#some-bug","title":"Some bug","text":"<p>There is some kind of bug with the current release that I'm unable to identify. Sometime when you start the harbor service, you can see the tool bar of a project and you can't use docker login to connet with harbor. </p> <p>To overcome this bug, you need to restart it</p> <pre><code># Restart Docker Engine.\n\nsudo systemctl restart docker\n\n# Stop Harbor. This command must run under the /path/to/harbor\ndocker compose down -v\n\n# start harbor. This command must run under the /path/to/harbor\ndocker compose up -d\n</code></pre> <p>You can find the official doc on harbor reconfigure here</p>"},{"location":"container/Image_registry/harbor/02.Harbor_installation/#6-working-with-harbor","title":"6. Working with harbor","text":"<p>https://goharbor.io/docs/1.10/working-with-projects/</p>"},{"location":"container/Image_registry/harbor/02.Harbor_installation/#61-create-a-project-in-harbor","title":"6.1 Create a project in Harbor","text":"<p>There are two types of project in Harbor:</p> <ul> <li>Public: Any user can pull images from this project. This is a convenient way for you to share repositories with others.</li> <li> <p>Private: Only users who are members of the project can pull images </p> </li> <li> <p>Go to Projects and click New Project.</p> </li> <li> <p>Provide a name for the project.</p> </li> <li> <p>(Optional) Check the Public check box to make the project public.</p> </li> </ul> <p>For more detail, please visit this page</p>"},{"location":"container/Image_registry/harbor/02.Harbor_installation/#62-config-a-project","title":"6.2 Config a project","text":"<p>Web User Interface</p>"},{"location":"container/Image_registry/harbor/02.Harbor_installation/#63-push-a-docker-image-to-the-created-project","title":"6.3 Push a docker image to the created project","text":"<p>Note if you want to push an image to harbor, you must tag the image in the local repo with below general form is <code>&lt;harbor-host-name&gt;/&lt;project-name&gt;/&lt;repo-name&gt;:&lt;tag&gt;</code>. tag is optional, if ommited, latest version will be used. </p> <p>For example, below is a minimum docker file. You can find the full example in sample_docker_file</p> <pre><code>FROM busybox:latest\nLABEL MAINTAINER=pengfei.liu@casd.eu\nLABEL version=\"1.0\"\nCOPY config.sh /etc/spark/config.sh\nRUN cat /etc/spark/config.sh        \n</code></pre> <pre><code># login to harbor registry\ndocker login &lt;harbor-url&gt;\n\n# Build an image from this Dockerfile and tag it.\n\ndocker build -t reg.casd.local/test/test-image .\n\n# Push the image from local repo to remote repo\ndocker push reg.casd.local/test/test-image\n</code></pre> <p>If you pull the image from other registry, you need to re-tag it to push to harbor. Below example shows how to pull image from dockerhub, then push the image to harbor</p> <pre><code># pull image from dockerhub\ndocker pull liupengfei99/mlflow\n\n# retag the image, the first argument is the source, second is the destination\ndocker tag liupengfei99/mlflow reg.casd.local/test/mlflow\n</code></pre> <p>For more example on how to push local image to remote repository, you can visit this page</p> <p>After this step, you should see a new repository <code>test-image</code> created in project <code>test</code></p>"},{"location":"container/Image_registry/harbor/02.Harbor_installation/#64-pull-a-docker-image-from-harbor","title":"6.4 Pull a docker image from harbor","text":"<p>To pull an image from harbor via docker client, please follow below command</p> <pre><code># login to harbor registry\ndocker login &lt;harbor-url&gt;\n\n# pull the image from remote repo to local repo\ndocker pull reg.casd.local/test/test-image\n</code></pre>"},{"location":"container/Image_registry/harbor/02.Harbor_installation/#65-managing-labels","title":"6.5 Managing labels","text":""},{"location":"container/Image_registry/harbor/02.Harbor_installation/#global-level-label","title":"Global level label","text":"<p>The Harbor <code>system administrators</code> can list, create, update and delete the <code>global level labels</code> under <code>Administration-&gt;Configuration-&gt;Labels</code></p>"},{"location":"container/Image_registry/harbor/02.Harbor_installation/#project-level-label","title":"Project level label","text":"<p>The <code>project administrators</code> and Harbor <code>system administrators</code> can list, create, update and delete the project level labels under <code>Labels</code> tab.</p>"},{"location":"container/Image_registry/harbor/02.Harbor_installation/#adding-and-removing-labels-to-and-from-images","title":"Adding and Removing Labels to and from Images","text":"<p>Users who have Harbor <code>system administrator, project administrator or project developer</code> role can click the <code>ADD LABELS</code> button to add labels to or remove labels from images. The label list contains both globel level labels(come first) and project level labels.</p>"},{"location":"container/Image_registry/harbor/02.Harbor_installation/#66-tag-and-re-tag-image","title":"6.6 Tag and re-tag image","text":"<p>Harbor allows an image to have multiple tags. Open an image and click on <code>add a tag</code> button to  add a new tag. </p>"},{"location":"container/Image_registry/harbor/02.Harbor_installation/#retag-copy-to-another-project-with-new-tag","title":"Retag (copy to another project with new tag)","text":"<p>Harbor allows you to re-tag an image.</p> <p>For more information, please visit this page</p>"},{"location":"container/Image_registry/harbor/03.Harbor_helm_chart_management/","title":"Harbor helm chart management","text":"<p>Since version 1.6.0, Harbor allows users to manage helm chart.</p> <p>If you are not familliar with Helm chart, please read the helm_chart.md first.</p> <p>There are three options to push helm charts to Harbor</p> <ol> <li>Use the helm chartmuseum/helm-push plugin to push Helm chart to Harbor</li> <li>Use the Harbor web UI to upload and download the helm chart (a *.tgz file)</li> <li>Since version 3.8 Helm support pushing and pulling Charts from OCI compliant container registries such as Harbor.</li> </ol> <p>In this tutorial, we choose <code>option 3</code>, as Chartmuseum is already marked as deprecated in Harbor.</p>"},{"location":"container/Image_registry/harbor/03.Harbor_helm_chart_management/#link-helm-cli-with-harbor","title":"Link helm cli with harbor","text":"<p>As a helm chart repository, Harbor can work smoothly with Helm CLI. Run command <code>helm version</code> to make sure the version of Helm CLI is v3.8.1+.</p> <pre><code># check helm version\nhelm version\n\n# example output\nversion.BuildInfo{Version:\"v3.9.4\", GitCommit:\"dbc6d8e20fe1d58d50e6ed30f09a04a77e4c68db\", GitTreeState:\"clean\", GoVersion:\"go1.17.13\"}\n\n# helm oci registry config \nhelm registry login -u admin reg.casd.local\n</code></pre>"},{"location":"container/Image_registry/harbor/03.Harbor_helm_chart_management/#push-charts-to-repository-server","title":"Push charts to repository server","text":"<pre><code># general form for pushing helm chart to harbor\nhelm push &lt;char-package&gt; oci://&lt;harbor-url&gt;/&lt;project-name&gt;\n\n# an example of pushing chart\nhelm push hello-world-0.1.0.tgz oci://reg.casd.local/test\n</code></pre>"},{"location":"container/Image_registry/harbor/03.Harbor_helm_chart_management/#pull-and-install-charts-from-repository-server","title":"Pull and install charts from repository server","text":"<p>Below pulling command will pull the tgz file to your current directory. Unlike with the common helm command where you would first <code>add a repo</code> and then <code>pull from it</code>. With OCI registry, you can install a Chart with one line without adding the OCI registry repository(project) one by one.</p> <pre><code># general form for pulling\nhelm pull oci://&lt;harbor-url&gt;/&lt;project-name&gt;/&lt;chart-name&gt; --version &lt;chart-version&gt;\n\n# an example for pulling chart\nhelm pull oci://reg.casd.local/test/hello-world --version 0.1.0\n\n# general form for installing a release from a remote chart\nhelm install &lt;release-name&gt; oci://&lt;harbor-url&gt;/&lt;project-name&gt;/&lt;chart-name&gt; --version &lt;chart-version&gt;\n\n# an example for installing a release\nhelm install myrelease  oci://reg.casd.local/test/hello-world --version 0.1.0\n</code></pre>"},{"location":"container/Image_registry/harbor/03.Harbor_helm_chart_management/#extra-command-for-helm-to-interact-with-oci","title":"Extra command for helm to interact with oci","text":"<p>Helm also provides various other subcommands for the oci:// protocol. </p> <pre><code>helm pull\nhelm show\nhelm template\nhelm install\nhelm upgrade\n</code></pre> <p>As OCI registry does not have the notion of repository, you can't do a search on the repo to get all the helm chart list</p>"},{"location":"container/Image_registry/harbor/03.Harbor_helm_chart_management/#onyxia-api-does-not-support-oci-registry","title":"Onyxia API does not support OCI registry","text":""},{"location":"container/k8s/01.Introduction/","title":"Introduction of k8s concepts","text":""},{"location":"container/k8s/01.Introduction/#pod-kubernetes-concept","title":"Pod (Kubernetes Concept)","text":"<p><code>A pod is the smallest deployable unit in Kubernetes</code>. It represents a group of one or more containers that are  scheduled and managed together.</p> <p>Pod Characteristics:  - Shared Environment: Containers within a pod share the same network namespace                            (they can communicate with each other using localhost) and storage volumes.   - Single IP Address: A pod gets a single IP address, and all containers within that pod share this IP.   - Multiple Containers: A pod can have multiple containers, usually working together as a single unit.                          For example, A main container (e.g., an NGINX web server) responsible for serving web content.                         A sidecar container (e.g., a logging agent like Fluentd) to handle logging.   - Lifecycle Management: Kubernetes handles the lifecycle of the pod, ensuring that the desired number of              replicas are running, restarting containers if needed, and ensuring the pod matches its defined state.    - High-Level Abstraction: A pod abstracts away container specifics, letting Kubernetes manage the                            complexity of container scheduling, scaling, networking, and storage.</p>"},{"location":"container/k8s/01.Introduction/#pod-sandbox","title":"Pod Sandbox","text":"<p>A pod sandbox sets up the environment for the containers, including network, storage, and DNS settings. Each pod is  associated with one sandbox. All containers within the same pod share the same sandbox, meaning  they share the same network namespace and IP address.</p> <p>The sandbox also isolates the resources that belong to a pod from others.</p>"},{"location":"container/k8s/01.Introduction/#sandbox-status","title":"Sandbox status","text":""},{"location":"container/k8s/01.Introduction/#container-containerd-concept","title":"Container (containerd Concept):","text":"<p>A container is a runtime instance of a containerized application (such as an individual Docker container).  It is a <code>single, isolated process</code> on the system with its own filesystem, networking, and process tree.</p> <p>Container Characteristics:  - Single Process Isolation: Containers are isolated environments, running a single application process.               Each container has its own filesystem, but by default, it is isolated from other containers.   - Managed by containerd: In Kubernetes, containerd is responsible for creating, starting, stopping,          and managing containers on each node. Each pod consists of one or more containers managed by containerd.   - Networking: A container has its own network namespace (unless it is part of a pod where containers                       share the same network).   - Single Unit: A container is usually thought of as a single unit of an application, typically mapped to             one image (e.g., an NGINX server running in a container).</p>"},{"location":"container/k8s/04.Managing_k8s_certificate/","title":"Certificate management with kubeadm","text":"<p>The official doc of the certificate management for v1.30 can be found here </p>"},{"location":"container/k8s/04.Managing_k8s_certificate/#default-behavior","title":"Default behavior","text":"<p>If you are doing nothing special before running <code>kubeadm init</code> in the master, all the certificates needed for a cluster to run are generated by kubeadm. The generated certificates and private keys are located in folder <code>/etc/kubernetes/pki/</code>.</p>"},{"location":"container/k8s/04.Managing_k8s_certificate/#use-custom-certificates","title":"Use custom certificates","text":"<p>You can also generate all the required certificates in a specific folder and tell kubeadm to use this folder as  the certificate root dir.</p> <p>The cert directory path can be specified by the <code>--cert-dir</code> flag or the <code>certificatesDir</code> field of  kubeadm's <code>ClusterConfiguration</code>. The default value is <code>/etc/kubernetes/pki/</code>.</p>"},{"location":"container/k8s/04.Managing_k8s_certificate/#use-custom-ca-recommended","title":"Use custom CA (Recommended).","text":"<p>The simplest way is to put your root CA certificate and private key in <code>/etc/kubernetes/pki/</code> before calling  <code>kubeadm init</code>. After calling <code>kubeadm init</code>, all the required certificate will be signed by this CA.</p> <pre><code># copy the ca cert and private key\ncp ca.crt /etc/kubernetes/pki/ca.crt\ncp ca.key /etc/kubernetes/pki/ca.key\n\n# run the kubeadm init\n</code></pre>"},{"location":"container/k8s/04.Managing_k8s_certificate/#renew-certificates-of-an-existing-cluster","title":"Renew certificates of an existing cluster","text":"<pre><code># step0: view the validity of the current certificates\nsudo kubeadm certs check-expiration\n\n# step1: backup existing certificates\nsudo cp -r /etc/kubernetes/pki /etc/kubernetes/pki-backup\n\n# step2: copy your root ca certificate and private key to the below file\nsudo vim /etc/kubernetes/pki/ca.crt  \nsudo vim /etc/kubernetes/pki/ca.key\n\n# step3: CALL the renew command to renew the certificates for all services\nsudo kubeadm certs renew all\n</code></pre>"},{"location":"container/k8s/04.Managing_k8s_certificate/#manage-certificate-with-kubeadm-post-installation","title":"Manage certificate with kubeadm (post installation)","text":"<p>https://v1-30.docs.kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-certs/</p>"},{"location":"container/k8s/04.Managing_k8s_certificate/#best-practices","title":"best practices","text":"<p>https://v1-30.docs.kubernetes.io/docs/setup/best-practices/certificates/</p>"},{"location":"container/k8s/05.k8s_cluster_supervision/","title":"supervision tools","text":"<p>kubernetesui/dashboard kubernetesui/metric-scraper</p>"},{"location":"container/k8s/Debug_application_in_cluster_k8s/","title":"Debug application in a cluster","text":""},{"location":"container/k8s/Debug_application_in_cluster_k8s/#identify-bug-level","title":"Identify bug level","text":"<p>One application needs three levels to work: - pod level - service level - ingress level</p> <p>We need to identify which level has problems</p>"},{"location":"container/k8s/Debug_application_in_cluster_k8s/#debug-a-pod-level-problem","title":"Debug a pod level problem","text":""},{"location":"container/k8s/Debug_application_in_cluster_k8s/#1-check-pod-status","title":"1. Check Pod Status","text":"<p>Each Pod has a status, we start by identifying its current status:</p> <pre><code># general form\nkubectl get pod &lt;pod-name&gt; -n &lt;name-space&gt; -o wide\n\n# an example\nkubectl get pod ingress-nginx-controller-qt489 -n ingress-nginx -o wide\n\n# output example\nNAME                                  READY   STATUS    RESTARTS   AGE   IP               NODE         NOMINATED NODE   READINESS GATES\nargocd-repo-server-57b9648b6c-g7dmx   1/1     Running   0          21m   192.168.14.203   onyxia-w01   &lt;none&gt;           &lt;none&gt;\n</code></pre> <p>Look at <code>STATUS, RESTARTS, and NODE</code>.</p> <p>Typical statuses:</p> <ul> <li>Pending: can't be scheduled</li> <li>ContainerCreating: image pull, volume, or init issues</li> <li>CrashLoopBackOff: container repeatedly fails</li> <li>Error: container exited non-zero</li> </ul>"},{"location":"container/k8s/Debug_application_in_cluster_k8s/#2-inspect-events","title":"2. Inspect Events","text":"<pre><code>kubectl describe pod ingress-nginx-controller-qt489 -n ingress-nginx\n</code></pre> <p>Look at the \"Events\" section at the bottom, check if there are: - Volume mount errors - Image pull errors - Init container failures - Admission webhook issues - Node scheduling constraints</p>"},{"location":"container/k8s/Debug_application_in_cluster_k8s/#3-check-container-logs","title":"3. Check Container Logs","text":"<p>If the pod reached running state briefly:</p> <pre><code>kubectl logs ingress-nginx-controller-qcd  -n ingress-nginx\n</code></pre> <p>If the pod has multiple containers (e.g., controller + admission):</p> <pre><code>kubectl logs ingress-nginx-controller-qt489 -n ingress-nginx -c &lt;container-name&gt;\n</code></pre> <p>If restarting:</p> <pre><code>kubectl logs --previous ingress-nginx-controller-qt489 -n ingress-nginx\n</code></pre>"},{"location":"container/k8s/Debug_application_in_cluster_k8s/#4-check-events-on-node-if-stuck-in-pending","title":"4. Check Events on Node (if stuck in Pending)","text":"<pre><code>kubectl get events --sort-by='.metadata.creationTimestamp' -A | grep ingress-nginx\n</code></pre> <p>You might see: - Insufficient CPU/memory - Taints not tolerated - Node selector mismatch</p>"},{"location":"container/k8s/Debug_application_in_cluster_k8s/#5verify-volume-mounts","title":"5.Verify Volume Mounts","text":"<p>If you mounted the CA:</p> <p>Ensure secret exists:</p> <pre><code>kubectl get secret root-ca -n ingress-nginx -o yaml\n</code></pre> <p>Ensure volume and volumeMount path is correct. Check file permissions (readOnly: true + non-root user?).</p>"},{"location":"container/k8s/k8s_cluster_upgrade/","title":"Upgrade k8s cluster","text":"<p>The official doc</p> <p>https://v1-30.docs.kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/</p>"},{"location":"container/k8s/k8s_cluster_upgrade/#changing-the-k8s-package-repository","title":"Changing the k8s package repository","text":"<p>https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/change-package-repository/</p>"},{"location":"container/k8s/k8s_cluster_upgrade/#update-repo-gpg-key","title":"update repo gpg key","text":"<p>When you update k8s package from the repo, you may encounter the below problems</p> <pre><code>Err:4 https://prod-cdn.packages.k8s.io/repositories/isv:/kubernetes:/core:/stable:/v1.31/deb  InRelease\n  The following signatures were invalid: EXPKEYSIG 234654DA9A296436 isv:kubernetes OBS Project &lt;isv:kubernetes@build.opensuse.org&gt;\n\nW: An error occurred during the signature verification. The repository is not updated and the previous index files will be used. GPG error: https://prod-cdn.packages.k8s.io/repositories/isv:/kubernetes:/core:/stable:/v1.31/deb  InRelease: The following signatures were invalid: EXPKEYSIG 234654DA9A296436 isv:kubernetes OBS Project &lt;isv:kubernetes@build.opensuse.org&gt;\n\nW: Failed to fetch https://pkgs.k8s.io/core:/stable:/v1.31/deb/InRelease  The following signatures were invalid: EXPKEYSIG 234654DA9A296436 isv:kubernetes OBS Project &lt;isv:kubernetes@build.opensuse.org&gt;\n\nW: Some index files failed to download. They have been ignored, or old ones used instead.\n</code></pre> <p>The problem is caused by the repo who has changed its pgp key. To fix it, you need to download the new gpg key.</p> <pre><code>sudo apt-get update\n# apt-transport-https may be a dummy package; if so, you can skip that package\nsudo apt-get install -y apt-transport-https ca-certificates curl gpg\n\ncurl -fsSL https://pkgs.k8s.io/core:/stable:/v1.31/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg\n</code></pre>"},{"location":"container/k8s/deploy_k8s_offline/02.Prepare_env_for_installing_k8s_offline/","title":"Prepare environment for installing k8s offline","text":"<p>We need to prepare three things before we are able to install k8s offline - A system packages repo which provides below packages (e.g. kubeadm, containerd, crictl, runc, etc. ) - A container image repo which provides container images (e.g. kube-apiserver, kube-proxy, etc ) - A helm chart repo which provides chart to deploy services on k8s cluster (e.g. ingress-nginx).</p>"},{"location":"container/k8s/deploy_k8s_offline/02.Prepare_env_for_installing_k8s_offline/#1-build-a-private-apt-package-repo","title":"1. Build a private apt package repo","text":"<p>As our scenario is offline installation, so we need to have a private debian package repo.</p> <p>For more details on how to build a private apt package repo, you can go to docs/debian_server/private_package_repo</p>"},{"location":"container/k8s/deploy_k8s_offline/02.Prepare_env_for_installing_k8s_offline/#11-configure-all-vms-in-k8s-cluster-to-use-the-private-apt-repo-as-system-package-repo","title":"1.1 Configure all vms in k8s cluster to use the private apt repo as system package repo","text":"<p>Suppose we already have a debian package repo is built by using aptly. It has all the basic packages of  debian 11, k8s-main(kubeadm, kubelet, etc.), containerd, and docker. The url of this repo server is <code>deb.casd.local</code></p> <p>To configure vms to use it, follow the below steps</p> <pre><code># step1: add the repo in your source list of the target server\n# open the config file\nsudo vim /etc/apt/sources.list\n# comments the default config, below are some example\n# deb http://deb.debian.org/debian bullseye main\n# deb http://security.debian.org/debian-security bullseye-security main\n# deb http://deb.debian.org/debian bullseye-updates main\n\n# add the private repo, suppose the url is deb.casd.local. we don't want to use ssl\ndeb [trusted=yes] http://deb.casd.local/ bullseye main\n\n# if you want to enable ssl, you need to add the pgp key of the repo into your target server\nwget -qO- http://deb.casd.local/casd_gpg_key.asc | sudo tee /etc/apt/trusted.gpg.d/casd_gpg_key.asc\ndeb https://deb.casd.local/ bullseye main\n\n# step2: Update the package cache in the target server\nsudo apt update\n\n# step3: install the containerd package to test\nsudo apt install containerd.io\n</code></pre>"},{"location":"container/k8s/deploy_k8s_offline/02.Prepare_env_for_installing_k8s_offline/#2-container-image-registry","title":"2. Container image registry","text":"<p>As kubeadm can't pull image from the internet, we need to build a private image repo. For more details on how to build a private image repo, you can go to docs/container/Image_registry/harbor/02.Harbor_installation.md</p> <p>The official installation guide of harbor can be found here: https://goharbor.io/docs/2.12.0/install-config/</p>"},{"location":"container/k8s/deploy_k8s_offline/02.Prepare_env_for_installing_k8s_offline/#21-get-the-required-container-image-in-image-registry","title":"2.1 Get the required container image in image registry","text":"<p>To init a cluster k8, we must have the required images in the image registry.</p> <p>The below list is the minimum container images that you need to deploy a k8s cluster: - k8s cluster required images:         - pause: Every Kubernetes Pod has a <code>pause container</code> that holds the network namespace and acts as the parent of all                    other containers in the Pod. Other containers in the Pod share its <code>PID, network, and IPC namespaces</code>.                   It ensures that networking and IPC resources remain stable even if app containers restart.         - kube-apiserver:         - kube-controller-manager         - kube-scheduler         - kube-proxy         - etcd: image to run etcd(a distributed database to store the k8s cluster stat and information).         - coredns - calico required images:         - kube-controllers         - node         - cni - ingress-nginx require images:         - controller </p>"},{"location":"container/k8s/deploy_k8s_offline/02.Prepare_env_for_installing_k8s_offline/#211-mirror-k8s-cluster-required-images","title":"2.1.1 Mirror k8s cluster required images","text":"<p>You can get the complete image list that the k8s cluster(of a specific version) requires with the below command</p> <pre><code>k8s_version=1.31.1\nkubeadm config images list --kubernetes-version=$k8s_version\n\n# output example\nregistry.k8s.io/kube-apiserver:v1.31.1\nregistry.k8s.io/kube-controller-manager:v1.31.1\nregistry.k8s.io/kube-scheduler:v1.31.1\nregistry.k8s.io/kube-proxy:v1.31.1\nregistry.k8s.io/coredns/coredns:v1.11.3\nregistry.k8s.io/pause:3.10\nregistry.k8s.io/etcd:3.5.15-0\n</code></pre> <p>The official Kubernetes image registry on Google Container Registry (GCR) is called <code>registry.k8s.io</code> </p> <p>Below script (<code>k8s_img_sync.bash</code>) pull k8s images from official repo and pushes them to casd repo</p> <pre><code>#!/bin/bash\n# before running the script, make sure to adapt your config\nrepo_url=reg.casd.local\nproject_name=k8s_image\n\nimages=(\nregistry.k8s.io/kube-apiserver:v1.31.1\nregistry.k8s.io/kube-controller-manager:v1.31.1\nregistry.k8s.io/kube-scheduler:v1.31.1\nregistry.k8s.io/kube-proxy:v1.31.1\nregistry.k8s.io/coredns/coredns:v1.11.3\nregistry.k8s.io/pause:3.10\nregistry.k8s.io/etcd:3.5.15-0\n)\n\nfor image_name in ${images[@]} ; do\ndocker pull $image_name\ncasd_image_name=\"${repo_url}/${project_name}/${image_name#*/}\"\ndocker tag $image_name $casd_image_name\ndocker push $casd_image_name\ndone\n</code></pre>"},{"location":"container/k8s/deploy_k8s_offline/02.Prepare_env_for_installing_k8s_offline/#212-mirror-the-calico-required-images","title":"2.1.2 Mirror the calico required images","text":"<p>calico network addon handles all the virtual networks of the k8s cluster. The calico project git page  is here. You need to choose the version which fits better your k8s cluster.</p> <p>The calico service needs the below images to run - docker.io/calico/cni:<code>&lt;version&gt;</code> - docker.io/calico/node:<code>&lt;version&gt;</code> - docker.io/calico/kube-controllers:<code>&lt;version&gt;</code></p>"},{"location":"container/k8s/deploy_k8s_offline/02.Prepare_env_for_installing_k8s_offline/#22-configure-all-vms-in-k8s-cluster-to-use-the-private-image-registry","title":"2.2 Configure all vms in k8s cluster to use the private image registry","text":"<p>We build a container image repo by using harbor. You need to configure the containerd daemon of all the servers in the k8s cluster to use the private image repo for pulling images.</p>"},{"location":"container/k8s/deploy_k8s_offline/02.Prepare_env_for_installing_k8s_offline/#23-use-private-image-registry-to-init-k8s-cluster","title":"2.3 Use private image registry to init k8s cluster","text":"<p>You can find the official doc of kubeadm here.</p> <p>The complete list of configuration options for kubeadm init can be found here</p> <pre><code>kubeadmin init \\\n  --apiserver-advertise-address=192.168.32.128\\\n  --image-repository reg.casd.local/k8s_images\n  --control-plane-endpoint=k8s-master \\\n  --kubernetes-version v1.31.1\n</code></pre> <p>The default value of the image-repository is <code>k8s.gcr.io</code> for <code>kubeadmin</code>. So to user our private image registry, we  need to change the default value. </p> <p>We recommend you to use a <code>config.yaml</code> to encapsulate all k8s configurations </p>"},{"location":"container/k8s/deploy_k8s_offline/02.Prepare_env_for_installing_k8s_offline/#24-use-private-image-registry-to-init-calico","title":"2.4 Use private image registry to init calico","text":"<p>Below is an exampl of yaml file to deploy calico kube controllers. If you use the private image registry, you need to change the <code>docker.io/calico/kube-controllers:v3.25.1</code> to <code>reg.casd.local/calico/kube-controllers:v3.25.1</code>. If there is  authentication required, you need to add also <code>imagePullSecrets</code> specs.</p> <pre><code>---\n# Source: calico/templates/calico-kube-controllers.yaml\n# See https://github.com/projectcalico/kube-controllers\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: calico-kube-controllers\n  namespace: kube-system\n  labels:\n    k8s-app: calico-kube-controllers\nspec:\n  # The controllers can only have a single active instance.\n  replicas: 1\n  selector:\n    matchLabels:\n      k8s-app: calico-kube-controllers\n  strategy:\n    type: Recreate\n  template:\n    metadata:\n      name: calico-kube-controllers\n      namespace: kube-system\n      labels:\n        k8s-app: calico-kube-controllers\n    spec:\n      nodeSelector:\n        kubernetes.io/os: linux\n      tolerations:\n        # Mark the pod as a critical add-on for rescheduling.\n        - key: CriticalAddonsOnly\n          operator: Exists\n        - key: node-role.kubernetes.io/master\n          effect: NoSchedule\n        - key: node-role.kubernetes.io/control-plane\n          effect: NoSchedule\n      serviceAccountName: calico-kube-controllers\n      priorityClassName: system-cluster-critical\n      containers:\n        - name: calico-kube-controllers\n          image: docker.io/calico/kube-controllers:v3.25.1\n          imagePullPolicy: IfNotPresent\n          env:\n            # Choose which controllers to run.\n            - name: ENABLED_CONTROLLERS\n              value: node\n            - name: DATASTORE_TYPE\n              value: kubernetes\n          livenessProbe:\n            exec:\n              command:\n              - /usr/bin/check-status\n              - -l\n            periodSeconds: 10\n            initialDelaySeconds: 10\n            failureThreshold: 6\n            timeoutSeconds: 10\n          readinessProbe:\n            exec:\n              command:\n              - /usr/bin/check-status\n              - -r\n            periodSeconds: 10\n</code></pre>"},{"location":"container/k8s/deploy_k8s_offline/02.Prepare_env_for_installing_k8s_offline/#appendix-download-the-image-as-tar-files","title":"Appendix: Download the image as tar files","text":"<p>If you don't have an image registry, you can download the image and package it as a tar file.</p> <p>The below script <code>save_k8s_images.bash</code>, save the all images in the list as <code>.tar</code> file.</p> <pre><code>#!/bin/bash\n#change the output path to a dir where you want\nout_path=.\n\nimages=(\nregistry.k8s.io/kube-apiserver:v1.31.1\nregistry.k8s.io/kube-controller-manager:v1.31.1\nregistry.k8s.io/kube-scheduler:v1.31.1\nregistry.k8s.io/kube-proxy:v1.31.1\nregistry.k8s.io/coredns/coredns:v1.11.3\nregistry.k8s.io/pause:3.10\nregistry.k8s.io/etcd:3.5.15-0\n)\n\nfor image_name in ${images[@]} ; do\ndocker pull $image_name\ntar_name=\"${out_path}/${image_name##*/}.tar\"\ndocker save -o $tar_name $image_name\ndone\n</code></pre> <p>The image in .tar still has the origin repository tag. For example, the api server image still has  the tag <code>registry.k8s.io/kube-apiserver</code> </p> <p>You can use the below script to mirror the calico images</p> <p>Make sure the image version is compatible with the calico.yaml version. And make sure the calico you want to  install is compatible with the k8s cluster.</p> <pre><code>#!/bin/bash\n# before running the script, make sure to adapt your config\nrepo_url=reg.casd.local\nproject_name=calico\n\nimages=(\ndocker.io/calico/cni:v3.28.2\ndocker.io/calico/node:v3.28.2\ndocker.io/calico/kube-controllers:v3.28.2\n)\n\nfor image_name in \"${images[@]}\" ; do\ndocker pull \"${image_name}\"\ncasd_image_name=\"${repo_url}/${project_name}/${image_name#*/}\"\ndocker tag \"${image_name}\" \"${casd_image_name}\"\ndocker push \"${casd_image_name}\"\ndone\n</code></pre> <p>The below script download calico image as tar </p> <pre><code>#!/bin/bash\n#change the output path to a dir where you want\nout_path=.\n\nimages=(\ndocker.io/calico/cni:v3.28.2\ndocker.io/calico/node:v3.28.2\ndocker.io/calico/kube-controllers:v3.28.2\n)\n\nfor image_name in \"${images[@]}\" ; do\ndocker pull \"${image_name}\"\ntar_name=\"${out_path}/${image_name##*/}.tar\"\ndocker save -o \"${tar_name}\" \"${image_name}\"\ndone\n</code></pre>"},{"location":"container/k8s/deploy_k8s_offline/03.Install_k8s_offline/","title":"Install a cluster k8s without internet access","text":""},{"location":"container/k8s/deploy_k8s_offline/03.Install_k8s_offline/#1-cluster-setup","title":"1.  Cluster setup","text":""},{"location":"container/k8s/deploy_k8s_offline/03.Install_k8s_offline/#2-cluster-network-config","title":"2. Cluster Network config","text":""},{"location":"container/k8s/deploy_k8s_offline/03.Install_k8s_offline/#3-diable-swap","title":"3. Diable swap","text":""},{"location":"container/k8s/deploy_k8s_offline/03.Install_k8s_offline/#4-configure-firewall-rules","title":"4. Configure Firewall Rules","text":"<p>Step 1. to 4. do not require internet connection, so follow the doc of 01.Install_with_internet.md </p>"},{"location":"container/k8s/deploy_k8s_offline/03.Install_k8s_offline/#5-install-containerd-run-times-on-all-nodes","title":"5. Install Containerd run times on all nodes","text":"<p>The containerd.io deb package should be in the local deb repo (deb.casd.local). So follow the doc  of 01.Install_with_internet.md. </p>"},{"location":"container/k8s/deploy_k8s_offline/03.Install_k8s_offline/#6-setup-k8s-apt-repository","title":"6. Setup k8s apt repository","text":"<p>SKIP, no need</p>"},{"location":"container/k8s/deploy_k8s_offline/03.Install_k8s_offline/#7-install-kubelet-kubectl-and-kubeadm-on-all-nodes","title":"7. Install kubelet, kubectl and kubeadm on all nodes","text":"<p>The kubelet kubeadm kubectl deb package should be in the local deb repo (deb.casd.local). So follow the doc  of 01.Install_with_internet.md. </p>"},{"location":"container/k8s/deploy_k8s_offline/03.Install_k8s_offline/#8-create-kubernetes-cluster-with-kubeadm","title":"8. Create Kubernetes Cluster with Kubeadm","text":"<p>For <code>running kubeadm without an Internet connection</code> you have to pre-pull the required control-plane images.</p> <p>You can list and pull the images using the kubeadm config images sub-command:</p> <pre><code>kubeadm config images list\nkubeadm config images pull\n</code></pre> <p>You can pass --config to the above commands with a kubeadm configuration file to control the kubernetesVersion and imageRepository fields.</p> <p>All default registry.k8s.io images that kubeadm requires support multiple architectures.</p>"},{"location":"container/k8s/deploy_k8s_offline/03.Install_k8s_offline/#81-init-the-k8s-control-plane-master-node","title":"8.1 Init the k8s control plane (master node)","text":""},{"location":"container/k8s/deploy_k8s_with_kubeadm/01.Introduction_of_Kubeadm/","title":"What is Kubeadm?","text":"<p>Kubeadm is a tool to set up a minimum viable Kubernetes cluster without much complex configuration. Also, Kubeadm makes the whole process easy by running a series of prechecking to ensure that the server has all the essential components and configs to run Kubernetes.</p> <p>It is developed and maintained by the official Kubernetes community. There are other options like <code>minikube</code>, <code>kind</code>, etc., that are pretty easy to set up.</p>"},{"location":"container/k8s/deploy_k8s_with_kubeadm/01.Introduction_of_Kubeadm/#how-does-kubeadm-work","title":"How Does Kubeadm Work?","text":"<p>When you initialize a Kubernetes cluster using Kubeadm, it does the following.</p> <ol> <li>When you initialize kubeadm, first it runs all the preflight checks to validate the system state,      and it downloads all the <code>required cluster container images</code> from the <code>registry.k8s.io</code> container registry.</li> <li>It then generates required TLS certificates and stores them in the /etc/kubernetes/pki folder.</li> <li>Next, it generates all the kubeconfig files for the cluster components in the /etc/kubernetes folder.</li> <li>Then it starts the kubelet service and generates the static pod manifests for all the cluster components and saves it in the <code>/etc/kubernetes/manifests</code> folder.</li> <li>Next, it starts all the control plane components from the static pod manifests.</li> <li>Then it installs core DNS and Kubeproxy components</li> <li>Finally, it generates the node bootstrap token.</li> <li>Worker nodes use this token to join the control plane.</li> </ol> <p></p>"},{"location":"container/k8s/deploy_k8s_with_kubeadm/01.Introduction_of_Kubeadm/#kubeadm-port-requirements","title":"Kubeadm Port Requirements","text":"<p>Please refer to the following image and make sure all the ports are allowed for the control plane (master) and the worker nodes. If you are setting up the kubeadm cluster cloud servers, ensure you allow the ports in the firewall configuration.</p> <p></p>"},{"location":"container/k8s/deploy_k8s_with_kubeadm/02.Deploy_k8s_cluster_online/","title":"Deploy a k8s cluster","text":"<p>This tutorial shows how to deploy a k8s cluster with internet access on debian servers.</p>"},{"location":"container/k8s/deploy_k8s_with_kubeadm/02.Deploy_k8s_cluster_online/#1-prerequisites","title":"1. Prerequisites","text":"<p>Suppose we have three servers with Debian 11 and below hardware: - 4 CPU / vCPU - 8 GB RAM - 20 GB free disk space - Sudo User with Admin rights - Stable Internet Connectivity (optional)</p>"},{"location":"container/k8s/deploy_k8s_with_kubeadm/02.Deploy_k8s_cluster_online/#11-cluster-setup","title":"1.1 Cluster setup","text":"<ul> <li>Master Node (k8s-master) \u2013 10.50.5.67</li> <li>Worker Node 1 (k8s-worker1) \u2013 10.50.5.68</li> <li>Worker Node 2 (k8s-worker2) \u2013 10.50.5.69</li> </ul>"},{"location":"container/k8s/deploy_k8s_with_kubeadm/02.Deploy_k8s_cluster_online/#12-cluster-network-config","title":"1.2 Cluster Network config","text":"<p>To enable the communication between Master node and worker node, we need to set up hostnames</p>"},{"location":"container/k8s/deploy_k8s_with_kubeadm/02.Deploy_k8s_cluster_online/#121-change-server-hostname","title":"1.2.1: Change server hostname","text":"<pre><code># run this on master node\nsudo hostnamectl set-hostname k8s-master\n\n# run this on worker1\nsudo hostnamectl set-hostname k8s-worker1\n\n# run this on worker2\nsudo hostnamectl set-hostname k8s-worker2\n</code></pre>"},{"location":"container/k8s/deploy_k8s_with_kubeadm/02.Deploy_k8s_cluster_online/#122-list-server-hostnames-of-the-cluster-in-the-etchosts","title":"1.2.2: List server hostnames of the cluster in the <code>/etc/hosts</code>","text":"<p>Add the following lines into <code>/etc/hosts</code>:</p> <pre><code>10.50.5.67       k8s-master\n10.50.5.68       k8s-worker1\n10.50.5.69       k8s-worker2\n</code></pre>"},{"location":"container/k8s/deploy_k8s_with_kubeadm/02.Deploy_k8s_cluster_online/#123-check-connectivity","title":"1.2.3: Check connectivity","text":"<p>You can try to ping each workder node from the master and vice-versa</p> <pre><code># from master\nping k8s-worker1\nping k8s-worker2\n\n# from the worker\nping k8s-master\n</code></pre>"},{"location":"container/k8s/deploy_k8s_with_kubeadm/02.Deploy_k8s_cluster_online/#124-enable-ipv4-packet-forwarding","title":"1.2.4 Enable IPv4 packet forwarding","text":"<p>By default, the <code>Linux kernel does not allow IPv4 packets to be routed between interfaces</code>. Most Kubernetes  cluster networking implementations will change this setting (if needed), but some might expect the administrator  to do it for them. (Some might also expect other sysctl parameters to be set, kernel modules to be loaded, etc;  consult the documentation for your specific network implementation.</p> <p>We will provide the complete procedure on how to set up this in docs/Container/Containerd/02.Install_config_containerd.md</p>"},{"location":"container/k8s/deploy_k8s_with_kubeadm/02.Deploy_k8s_cluster_online/#125-check-your-cgroup-drivers","title":"1.2.5 Check your cgroup drivers","text":"<p>On Linux, control groups are used to constrain resources that are allocated to processes.</p> <p>Both the <code>kubelet and the underlying container runtime</code> need to interface with <code>control groups</code> to enforce resource  management for pods and containers and set resources such as cpu/memory requests and limits.  <code>To interface with control groups, the kubelet and the container runtime need to use a cgroup driver</code>.  It's critical that the kubelet and the container runtime use the same cgroup driver and are configured the same.</p> <p>There are two cgroup drivers available:</p> <ul> <li>cgroupfs</li> <li>systemd</li> </ul> <p>In our case, as we use debian 11, the default cgroup is cgroup v2(Uses a unified hierarchy, improving resource  delegation and security), and the default cgroup driver is systemd. You can check the cgroup value with below  command</p> <pre><code>mount | grep cgroup\n\n# expected output\ncgroup2 on /sys/fs/cgroup type cgroup2 (rw,nosuid,nodev,noexec,relatime,nsdelegate,memory_recursiveprot)\n</code></pre>"},{"location":"container/k8s/deploy_k8s_with_kubeadm/02.Deploy_k8s_cluster_online/#126-disable-firewalls","title":"1.2.6 Disable firewalls","text":"<p>If you have firewalls installed on your severs, the easiest way is to disable them.</p> <pre><code>ufw disable\n\nsudo systemctl stop apparmor\nsudo systemctl disable apparmor\n</code></pre> <p>Or you can follow the below commands to set up specific rules</p> <pre><code># On Master node, run\n$ sudo ufw allow 6443/tcp\n$ sudo ufw allow 2379/tcp\n$ sudo ufw allow 2380/tcp\n$ sudo ufw allow 10250/tcp\n$ sudo ufw allow 10251/tcp\n$ sudo ufw allow 10252/tcp\n$ sudo ufw allow 10255/tcp\n$ sudo ufw reload\n</code></pre> <pre><code># On Worker Nodes,\n$ sudo ufw allow 10250/tcp\n$ sudo ufw allow 30000:32767/tcp\n$ sudo ufw reload\n</code></pre>"},{"location":"container/k8s/deploy_k8s_with_kubeadm/02.Deploy_k8s_cluster_online/#2-install-container-runtime","title":"2. Install container runtime","text":"<p>Containers require a <code>container runtime</code> to run on the host machine. As a result, we must install a container runtime  before deploying a k8s cluster.</p> <p>For now, <code>Containerd is the industry standard container run time</code>, we must install containerd on all master and worker nodes.</p> <p>Don't use the containerd binary of the native apt repo. Use the version of containerd.io</p> <p>The detailed installation guide is in docs/Container/Containerd/02.Install_config_containerd.md</p>"},{"location":"container/k8s/deploy_k8s_with_kubeadm/02.Deploy_k8s_cluster_online/#3-diable-swap","title":"3. Diable swap","text":"<p>For kubelet to work smoothly, it is recommended to disable swap. Run following commands to turn off swap. This step can be skipped if your server does not have swap</p> <pre><code>$ sudo swapoff -a\n$ sudo sed -i '/ swap / s/^\\(.*\\)$/#\\1/g' /etc/fstab\n</code></pre>"},{"location":"container/k8s/deploy_k8s_with_kubeadm/02.Deploy_k8s_cluster_online/#4-install-k8s-packages","title":"4. Install k8s packages","text":"<p>The k8s releases are updated every 6 months. So the below docs maybe obsolete. The official doc can be found here https://kubernetes.io/docs/tasks/tools/install-kubectl-linux/#install-using-native-package-management</p> <p>The below docs are tested on debian 11 server with k8s v1.33.</p>"},{"location":"container/k8s/deploy_k8s_with_kubeadm/02.Deploy_k8s_cluster_online/#41-setup-k8s-apt-repository","title":"4.1 Setup k8s apt repository","text":"<p>You need to set up k8s apt repository on all nodes</p> <pre><code># install required dependencies\nsudo apt install gnupg gnupg2 curl software-properties-common apt-transport-https -y\n\n# create the keyrings folder\nsudo mkdir -p /etc/apt/keyrings\n\n# add GPG key\ncurl -fsSL https://pkgs.k8s.io/core:/stable:/v1.33/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg\n\n# allow unprivileged APT programs to read this keyring\nsudo chmod 644 /etc/apt/keyrings/kubernetes-apt-keyring.gpg \n\n# This overwrites any existing configuration in /etc/apt/sources.list.d/kubernetes.list\n# add v1.33 k8s repo to source.list \necho 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.33/deb/ /' | sudo tee /etc/apt/sources.list.d/kubernetes.list\n\n# helps tools such as command-not-found to work correctly\nsudo chmod 644 /etc/apt/sources.list.d/kubernetes.list   \n</code></pre> <p>In releases older than Debian 12 and Ubuntu 22.04, folder /etc/apt/keyrings does not exist by default, and it should be created before the curl command.</p>"},{"location":"container/k8s/deploy_k8s_with_kubeadm/02.Deploy_k8s_cluster_online/#7-install-kubelet-kubectl-and-kubeadm-on-all-nodes","title":"7. Install kubelet, kubectl and kubeadm on all nodes","text":"<p>Run the following apt commands on all the nodes to install Kubernetes cluster components like kubelet, kubectl and Kubeadm.</p> <pre><code>sudo apt update\n\n# you can check the available version before install\napt-cache madison kubeadm\n\n# expected output\nkubeadm | 1.33.2-1.1 | https://pkgs.k8s.io/core:/stable:/v1.33/deb  Packages\nkubeadm | 1.33.1-1.1 | https://pkgs.k8s.io/core:/stable:/v1.33/deb  Packages\nkubeadm | 1.33.0-1.1 | https://pkgs.k8s.io/core:/stable:/v1.33/deb  Packages\n\nsudo apt install kubelet kubeadm kubectl -y\n\n# check the installed version\napt list --installed kubeadm\n\n# hold is used to mark a package as held back, which will prevent the package from being automatically installed, upgraded or removed.\nsudo apt-mark hold kubelet kubeadm kubectl\n</code></pre>"},{"location":"container/k8s/deploy_k8s_with_kubeadm/02.Deploy_k8s_cluster_online/#8-create-kubernetes-cluster-with-kubeadm","title":"8. Create Kubernetes Cluster with Kubeadm","text":"<p>Now, we need to use kubeadm to create a k8s cluster.</p>"},{"location":"container/k8s/deploy_k8s_with_kubeadm/02.Deploy_k8s_cluster_online/#81-use-custom-root-ca","title":"8.1 Use custom root CA","text":"<p>By default, the k8s cluster will generate a root CA for TLS communication. If you want to use a custom root CA certificate, you need to do the following steps:</p> <pre><code># Step1: put your custom CA files in:\n# The ca.crt is a valid X.509 root certificate\n/etc/kubernetes/pki/ca.crt\n# The ca.key is the corresponding private key (PEM format, unencrypted)\n/etc/kubernetes/pki/ca.key\n\n# Step2: Permissions Check\nchmod 600 /etc/kubernetes/pki/ca.key\nchown root:root /etc/kubernetes/pki/ca.key\n\n# step3: prepare the config (check 8.2)\n\n# step4: init the cluster with the config file\nkubeadm init --config kubeadm-config.yaml --upload-certs\n\n# step5: Optional, if certs were already created with a different CA and you want to re-sign:\nkubeadm certs renew all --config kubeadm-config.yaml\n</code></pre> <p>Do not pass --skip-phases or --certificate-key, unless managing every phase manually</p>"},{"location":"container/k8s/deploy_k8s_with_kubeadm/02.Deploy_k8s_cluster_online/#82-init-the-k8s-control-plane-master-node","title":"8.2 Init the k8s control plane (master node)","text":"<p>Run the following command only from the master node, it will init the master node as a control plane endpoint</p> <pre><code># short version\nsudo kubeadm init\n\n# long version\nsudo kubeadm init --control-plane-endpoint=k8s-master --kubernetes-version v1.27.0\n\n# with a custom config file, all the configuration is in a file, it's better for versioning\nkubeadm init --config kubeadm-config.yaml --upload-certs\n</code></pre> <p>Below is an example of the <code>kubeadm-config.yaml</code></p> <pre><code>apiVersion: kubeadm.k8s.io/v1beta3\nkind: InitConfiguration\n# Configuration for the local kubelet.\nnodeRegistration:\n  # the hostname used for the node in the cluster.\n  name: onyxia-master\n  # The path to the container runtime interface socket (here: containerd).\n  criSocket: unix:///run/containerd/containerd.sock\n  # Forces kubelet to advertise the correct internal IP. Prevents wrong IP detection on multi-interface hosts.\n  kubeletExtraArgs:\n    node-ip: 10.50.5.67\n\nlocalAPIEndpoint:\n  # The IP address the kube-apiserver binds to on this node.\n  advertiseAddress: 10.50.5.67\n  # Port exposed for control-plane communication \n  bindPort: 6443\n\n---\napiVersion: kubeadm.k8s.io/v1beta3\nkind: ClusterConfiguration\n# Target Kubernetes version to install \nkubernetesVersion: v1.33.2\n# DNS name or IP + port of the cluster\u2019s load balancer or primary API server. In single-node, it's the master's IP.\ncontrolPlaneEndpoint: \"10.50.5.67:6443\"\nnetworking:\n  # CIDR used by the CNI plugin \n  # REQUIRED to match Calico default\n  podSubnet: 192.168.0.0/16       \n  serviceSubnet: 10.96.0.0/12\n  dnsDomain: cluster.local\napiServer:\n  # Additional Subject Alternative Names added to the kube-apiserver certificate. Allows API to be reached via IP or DNS.\n  certSANs:\n    - \"10.50.5.67\"\n    - \"onyxia-master\"\n  # Configures the authorization model \n  extraArgs:\n    authorization-mode: Node,RBAC\n\n---\napiVersion: kubeproxy.config.k8s.io/v1alpha1\nkind: KubeProxyConfiguration\nmode: iptables\n</code></pre> <p>You can notice the config file has three main parts: - InitConfiguration: It controls the local node's behavior - ClusterConfiguration: It defines the global cluster settings - KubeProxyConfiguration: It defines kube-proxy behavior</p> <p>I had a warning, because the api <code>v1beta3</code> is too old, kubeadm has a command to convert it to <code>v1beta4</code></p> <pre><code># Run this command to convert the config\nkubeadm config migrate --old-config kubeadm-config.yaml --new-config new-config.yaml\n</code></pre> <p>Below is the generated new config in <code>v1beta4</code></p> <pre><code>apiVersion: kubeadm.k8s.io/v1beta4\nbootstrapTokens:\n- groups:\n  - system:bootstrappers:kubeadm:default-node-token\n  token: 56mm95.5r9xhf31zr9r9gpm\n  ttl: 24h0m0s\n  usages:\n  - signing\n  - authentication\nkind: InitConfiguration\nlocalAPIEndpoint:\n  advertiseAddress: 10.50.5.67\n  bindPort: 6443\nnodeRegistration:\n  criSocket: unix:///run/containerd/containerd.sock\n  imagePullPolicy: IfNotPresent\n  imagePullSerial: true\n  kubeletExtraArgs:\n  - name: node-ip\n    value: 10.50.5.67\n  name: onyxia-master\n  taints:\n  - effect: NoSchedule\n    key: node-role.kubernetes.io/control-plane\ntimeouts:\n  controlPlaneComponentHealthCheck: 4m0s\n  discovery: 5m0s\n  etcdAPICall: 2m0s\n  kubeletHealthCheck: 4m0s\n  kubernetesAPICall: 1m0s\n  tlsBootstrap: 5m0s\n  upgradeManifests: 5m0s\n---\napiServer:\n  certSANs:\n  - 10.50.5.67\n  - onyxia-master\n  extraArgs:\n  - name: authorization-mode\n    value: Node,RBAC\napiVersion: kubeadm.k8s.io/v1beta4\ncaCertificateValidityPeriod: 87600h0m0s\ncertificateValidityPeriod: 8760h0m0s\ncertificatesDir: /etc/kubernetes/pki\nclusterName: kubernetes\ncontrolPlaneEndpoint: 10.50.5.67:6443\ncontrollerManager: {}\ndns: {}\nencryptionAlgorithm: RSA-2048\netcd:\n  local:\n    dataDir: /var/lib/etcd\nimageRepository: registry.k8s.io\nkind: ClusterConfiguration\nkubernetesVersion: v1.33.2\nnetworking:\n  dnsDomain: cluster.local\n  podSubnet: 192.168.0.0/16\n  serviceSubnet: 10.96.0.0/12\nproxy: {}\nscheduler: {}\n</code></pre> <p>Now you have you needed to run <code>kubeadm init --config kubeadm-config.yaml --upload-certs</code> If everything works well, you should see the below output</p> <pre><code>Your Kubernetes control-plane has initialized successfully!\n\nTo start using your cluster, you need to run the following as a regular user:\n\n  mkdir -p $HOME/.kube\n  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n  sudo chown $(id -u):$(id -g) $HOME/.kube/config\n\nAlternatively, if you are the root user, you can run:\n\n  export KUBECONFIG=/etc/kubernetes/admin.conf\n\nYou should now deploy a pod network to the cluster.\nRun \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at:\n  https://kubernetes.io/docs/concepts/cluster-administration/addons/\n\nYou can now join any number of control-plane nodes by copying certificate authorities\nand service account keys on each node and then running the following as root:\n\n  kubeadm join k8s-master:6443 --token 48elby.xre538l1ytebqe7q \\\n        --discovery-token-ca-cert-hash sha256:e0cccf7851ec76248163359058ea8e9aad478daefe14180c82f881a5e433dbda \\\n        --control-plane\n\nThen you can join any number of worker nodes by running the following on each as root:\n\nkubeadm join k8s-master:6443 --token 48elby.xre538l1ytebqe7q \\\n        --discovery-token-ca-cert-hash sha256:e0cccf7851ec76248163359058ea8e9aad478daefe14180c82f881a5e433dbda\n</code></pre> <p>You can notice there are three commands : - setup kubectl (k8s client) to connect the k8s cluster (regular user and root user) - To join any number of master nodes to control plane - To join any number of worker nodes to the cluster</p>"},{"location":"container/k8s/deploy_k8s_with_kubeadm/02.Deploy_k8s_cluster_online/#82-setup-kubectl","title":"8.2 Setup kubectl","text":"<p>To start interacting with cluster as a regular user, run following commands on master node</p> <pre><code>$ mkdir -p $HOME/.kube\n$ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n$ sudo chown $(id -u):$(id -g) $HOME/.kube/config\n</code></pre> <p>Run following kubectl command to get nodes and cluster information,</p> <pre><code>$ kubectl get nodes\n$ kubectl cluster-info\n</code></pre>"},{"location":"container/k8s/deploy_k8s_with_kubeadm/02.Deploy_k8s_cluster_online/#83-join-worker-node","title":"8.3 Join worker node","text":"<p>If you fogot the token to join the cluster, you can generate a new one with below command:</p> <pre><code># you need to have k8s admin right\nkubeadm token create --print-join-command\n\n# you should see below outputs\nkubeadm join 10.50.5.67:6443 --token 03mxyl.eg12gb36v3ya2bcs --discovery-token-ca-cert-hash sha256:1b19519e76812d286a93413320499bfd7ac1e06f7bd795994e086d0d1d0e6661\n\n# list existing token\nkubeadm token list\n\n# you should see below outputs\nTOKEN                     TTL         EXPIRES                USAGES                   DESCRIPTION                                                EXTRA GROUPS\n03mxyl.eg12gb36v3ya2bcs   23h         2023-04-18T15:05:50Z   authentication,signing   &lt;none&gt;                                                     system:bootstrappers:kubeadm:default-node-token\n</code></pre> <p>You can notice the token has a TTL, so it expires in 23hours</p> <p>The general form of the join command is shown below:</p> <pre><code>kubeadm join &lt;api-server-ip:port&gt; --token &lt;token-value&gt; \\\n--discovery-token-ca-cert-hash sha256:&lt;hash value&gt;\n</code></pre> <p>So we need three information, </p> <ul> <li>k8s Api-server-ip and port</li> <li>a Valid token</li> <li>Token-ca-cert-hash value</li> </ul> <p>You can run below command to get the api server ip and port</p> <pre><code>kubectl config view --minify -o jsonpath='{.clusters[0].cluster.server}' &amp;&amp; echo \"\"\n</code></pre> <p>You need to have root privilege to run kubeadm join</p>"},{"location":"container/k8s/deploy_k8s_with_kubeadm/02.Deploy_k8s_cluster_online/#84-check-your-k8s-status","title":"8.4 Check your k8s status","text":"<pre><code># get available nodes\nNAME            STATUS     ROLES           AGE     VERSION\nonyxia-master   NotReady   control-plane   5m43s   v1.33.2\nonyxia-w01      NotReady   &lt;none&gt;          20s     v1.33.2\nonyxia-w02      NotReady   &lt;none&gt;          9s      v1.33.2\n\n# get pods in name space\nkubectl get pods -n kube-system\n</code></pre> <p>If you see the nodes status are <code>Not-Ready</code>, you can check the pods status in kube-system with the below command.  <code>kubectl get pods -n kube-system</code>. If you see coredns is pending, it's normal. Because it requires a network addon to run. We will install it in the next section</p>"},{"location":"container/k8s/deploy_k8s_with_kubeadm/02.Deploy_k8s_cluster_online/#9-reset-the-cluster","title":"9. Reset the cluster","text":"<p>https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm-reset/</p>"},{"location":"container/k8s/deploy_k8s_with_kubeadm/02.Deploy_k8s_cluster_online/#10-install-calico-pod-network-addon","title":"10. Install Calico Pod Network Addon","text":"<p>To enable communication between nodes and services in k8s cluster, we need a network addon.  In our case, we use Calico. The project page is here</p> <p>On the master node, run beneath command to install calico. Here I choose the current latest version v3.25.1. You can  visit the project page and get the latest version.</p> <pre><code># general form\nkubectl apply -f https://raw.githubusercontent.com/projectcalico/calico/{calico-versioin}/manifests/calico.yaml\n\n# example\nkubectl apply -f https://raw.githubusercontent.com/projectcalico/calico/v3.25.1/manifests/calico.yaml\n</code></pre> <p>You need to check the compatibility between your k8s cluster version and the calico version.  For </p>"},{"location":"container/k8s/deploy_k8s_with_kubeadm/02.Deploy_k8s_cluster_online/#11-test-your-k8s-cluster","title":"11. Test your k8s cluster","text":"<p>To test Kubernetes cluster installation, let\u2019s try to deploy nginx-based application via deployment. Run beneath commands,</p> <pre><code># get general status of your cluster\nkubectl cluster-info\n\n# create a deployment with nginx image\nkubectl create deployment nginx-app --image=nginx --replicas 2\n\n# create a service which uses the deployment\nkubectl expose deployment nginx-app --name=nginx-web-svc --type NodePort --port 80 --target-port 80\n\n# get the pod info the deployment\nkubectl get pods -o wide\n\nNAME                         READY   STATUS    RESTARTS   AGE   IP               NODE          NOMINATED NODE   READINESS GATES\nnginx-app-7df7b66fb5-b6lhk   1/1     Running   0          83m   192.168.194.68   k8s-worker1   &lt;none&gt;           &lt;none&gt;\nnginx-app-7df7b66fb5-qtsw7   1/1     Running   0          83m   192.168.194.66   k8s-worker1   &lt;none&gt;           &lt;none&gt;\n\n# get the info of the service, you need to get the node port\nkubectl describe svc nginx-web-svc\n\n# the output\n\nName:                     nginx-web-svc\nNamespace:                default\nLabels:                   app=nginx-app\nAnnotations:              &lt;none&gt;\nSelector:                 app=nginx-app\nType:                     NodePort\nIP Family Policy:         SingleStack\nIP Families:              IPv4\nIP:                       10.103.208.99\nIPs:                      10.103.208.99\nPort:                     &lt;unset&gt;  80/TCP\nTargetPort:               80/TCP\nNodePort:                 &lt;unset&gt;  31169/TCP\nEndpoints:                &lt;none&gt;\nSession Affinity:         None\nExternal Traffic Policy:  Cluster\nEvents:                   &lt;none&gt;\n\n# with the above two commands, you know that the pods runs on `k8s-worker1`, the node port is 31169.\n# You can try to access the nginx service with the below command.\n# you need to modify the url and port based on the svc output\ncurl http://k8s-worker1:31169\n\n# clean the cluster after test\nkubectl delete deployment nginx-app\nkubectl delete service nginx-web-svc\n</code></pre> <p>If you get a HTML response from the nginx server with success, it means your k8s cluster is good.</p>"},{"location":"container/k8s/deploy_k8s_with_kubeadm/02.Deploy_k8s_cluster_online/#appendix1-cgroup-and-systemd","title":"Appendix1: cgroup and systemd","text":"<p><code>Systemd</code> organizes processes using <code>cgroups</code> to track and manage resource usage. Each systemd unit (like a service)  runs in its own cgroup. For example, the <code>nginx.service</code> runs in <code>/sys/fs/cgroup/system.slice/nginx.service/</code> This ensures services are isolated and can have specific resource limits.</p> <p>Systemd provides commands to control resource usage dynamically:</p> <pre><code># Limit CPU usage:\nsystemctl set-property nginx.service CPUQuota=50%\n\n# Limit Memory usage:\nsystemctl set-property nginx.service MemoryMax=500M\n</code></pre> <p>These settings are applied via cgroup controllers in the background.</p>"},{"location":"container/k8s/deploy_k8s_with_kubeadm/02.Deploy_k8s_cluster_online/#cgroupfs-driver","title":"cgroupfs driver","text":"<p>The cgroupfs driver is the default cgroup driver in the kubelet. When the cgroupfs driver is used, the kubelet  and the container runtime directly interface with the cgroup filesystem to configure cgroups.</p> <p>The cgroupfs driver is not recommended when systemd is the init system because systemd expects a single cgroup manager on the system. Additionally, if you use cgroup v2 , use the systemd cgroup driver instead of cgroupfs.</p>"},{"location":"container/k8s/deploy_k8s_with_kubeadm/02.Deploy_k8s_cluster_online/#systemd-cgroup-driver","title":"systemd cgroup driver","text":"<p>When systemd is chosen as the init system for a Linux distribution, the init process generates and consumes a root control group (cgroup) and acts as a cgroup manager.</p> <p>systemd has a tight integration with cgroups and allocates a cgroup per systemd unit. As a result, if you use systemd as the init system with the cgroupfs driver, the system gets two different cgroup managers.</p> <p>Two cgroup managers result in two views of the available and in-use resources in the system. In some cases, nodes that are configured to use cgroupfs for the kubelet and container runtime, but use systemd for the rest of the processes become unstable under resource pressure.</p> <p>The approach to mitigate this instability is to use systemd as the cgroup driver for the kubelet and the container runtime when systemd is the selected init system.</p> <p>To set <code>systemd</code> as the cgroup driver, edit the KubeletConfiguration option of cgroupDriver and set it to systemd. For example: </p> <pre><code>apiVersion: kubelet.config.k8s.io/v1beta1\nkind: KubeletConfiguration\n...\ncgroupDriver: systemd\n</code></pre> <p>If you configure systemd as the cgroup driver for the kubelet, you must also configure systemd as the cgroup driver  for the container runtime. Refer to the documentation for your container runtime for instructions. For example:</p> <ul> <li>containerd</li> <li>CRI-O</li> </ul> <p>Caution: Changing the cgroup driver of a Node that has joined a cluster is a sensitive operation. If the kubelet  has created Pods using the semantics of one cgroup driver, changing the container runtime to another cgroup  driver can cause errors when trying to re-create the Pod sandbox for such existing Pods.  Restarting the kubelet may not solve such errors.</p> <p>If you have automation that makes it feasible, replace the node with another using the updated configuration, or reinstall it using automation.</p>"},{"location":"container/k8s/deploy_k8s_with_kubeadm/02.Deploy_k8s_cluster_online/#appendix-install-containerd-via-default-apt-repo-not-recommended","title":"Appendix : Install containerd via default apt repo (not recommended)","text":"<p>You can find the offical intallation doc of containd here</p>"},{"location":"container/k8s/deploy_k8s_with_kubeadm/02.Deploy_k8s_cluster_online/#configure-containerd","title":"Configure containerd","text":"<p>If you have problems with containerd, check this 02.Install_config_containerd.md</p>"},{"location":"container/k8s/deploy_k8s_with_kubeadm/02.Deploy_k8s_cluster_online/#appendix-kubeadm-init-without-internet-access","title":"Appendix: Kubeadm init without internet access","text":"<p>Get all images that you need to pull</p> <pre><code>kubectl get pods --all-namespaces -o jsonpath=\"{.items[*].spec.containers[*].image}\" |\\\ntr -s '[[:space:]]' '\\n' |\\\nsort |\\\nuniq -c\n</code></pre> <p>You need to pull below image into local containerd cache - registry.k8s.io/coredns/coredns:v1.10.1 - registry.k8s.io/etcd:3.5.7-0 - registry.k8s.io/kube-apiserver:v1.27.0 - registry.k8s.io/kube-controller-manager:v1.27.0 - registry.k8s.io/kube-proxy:v1.27.0 - registry.k8s.io/kube-scheduler:v1.27.0</p>"},{"location":"container/k8s/deploy_k8s_with_kubeadm/03.K8s_cluster_management/","title":"K8s cluster management","text":""},{"location":"container/k8s/deploy_k8s_with_kubeadm/03.K8s_cluster_management/#control-plane-management","title":"Control plane management","text":""},{"location":"container/k8s/deploy_k8s_with_kubeadm/03.K8s_cluster_management/#1-get-the-status-of-the-control-plane","title":"1. Get the status of the control plane","text":"<pre><code># use kubectl (deprecated)\nkubectl get componentstatuses\n\n# expected output\nNAME                 STATUS    MESSAGE             ERROR\nscheduler            Healthy   ok\ncontroller-manager   Healthy   ok\netcd-0               Healthy   {\"health\":\"true\"}\n\n# get pods status of the components\nkubectl get pods -n kube-system\n\n# expected output\ncalico-kube-controllers-6dd874f784-cmb99   1/1     Running            5768 (294d ago)     2y285d\ncalico-node-4bclg                          1/1     Running            3 (606d ago)        2y285d\ncalico-node-c2sds                          1/1     Running            5 (606d ago)        2y277d\ncalico-node-ccqqk                          1/1     Running            5 (606d ago)        2y282d\ncalico-node-khcv2                          1/1     Running            4 (606d ago)        2y285d\ncoredns-76b4fb4578-cbsr6                   1/1     Running            35 (572d ago)       2y277d\ncoredns-76b4fb4578-wcrr9                   1/1     Running            31 (572d ago)       2y277d\ndns-autoscaler-7979fb6659-z9gkw            1/1     Running            3 (606d ago)        2y285d\nkube-controller-manager-controlplane1      1/1     Running            63 (276d ago)       606d\nkube-proxy-bc9dw                           1/1     Running            0                   606d\nkube-proxy-hp947                           1/1     Running            0                   606d\nkube-proxy-nfwxv                           1/1     Running            0                   606d\nkube-proxy-xgqjc                           1/1     Running            0                   606d\nkube-scheduler-controlplane1               1/1     Running            62 (276d ago)       606d\nnginx-proxy-worker1                        1/1     Running            7 (606d ago)        606d\nnginx-proxy-worker2                        1/1     Running            3 (606d ago)        606d\nnginx-proxy-worker3                        1/1     Running            5 (606d ago)        606d\nnode-custom-setup-bsxt8                    1/1     Running            2 (606d ago)        2y220d\nnode-custom-setup-gp7tk                    1/1     Running            1 (606d ago)        2y220d\nnode-custom-setup-vkf66                    1/1     Running            1 (606d ago)        2y220d\nnodelocaldns-9sg7w                         1/1     Running            59 (572d ago)       2y281d\nnodelocaldns-dklqj                         1/1     Running            35 (573d ago)       2y277d\nnodelocaldns-lfk5v                         0/1     CrashLoopBackOff   101523 (245d ago)   606d\nnodelocaldns-pz7h6                         1/1     Running            57 (572d ago)       2y281d\n</code></pre> <p>The pod manifests of the control plane components are located in <code>/etc/kubernetes/manifests/</code></p> <pre><code>ls /etc/kubernetes/manifests/\n\n# expected output\nkube-apiserver.yaml\nkube-scheduler.yaml\nkube-controller-manager.yaml\n</code></pre>"},{"location":"container/k8s/deploy_k8s_with_kubeadm/03.K8s_cluster_management/#11-etcd-status","title":"1.1 ETCD status","text":"<p>The etcd is launched as an external cluster, you should find the config in <code>/etc/kubernetes/kubeadm-config.yaml</code></p> <pre><code>etcd:\n  external:\n    endpoints:\n      - https://&lt;etcd-ip&gt;:2379\n</code></pre>"},{"location":"container/k8s/deploy_k8s_with_kubeadm/03.K8s_cluster_management/#12-api-server-status","title":"1.2 API server status","text":"<pre><code>curl -k https://localhost:6443/healthz\ncurl -k https://localhost:6443/readyz\ncurl -k https://localhost:6443/livez\n\n# expected output\nok\n</code></pre>"},{"location":"container/k8s/deploy_k8s_with_kubeadm/03.K8s_cluster_management/#stop-the-k8s-cluster","title":"Stop the k8s cluster","text":"<p>Step 1: Drain and cordon worker nodes (optional but safe)</p> <pre><code># Repeat for all worker nodes.\nkubectl drain &lt;worker-node-name&gt; --ignore-daemonsets --delete-emptydir-data\nkubectl cordon &lt;worker-node-name&gt;\n</code></pre> <p>This ensures that workloads are gracefully evicted and won't get rescheduled.</p> <p>Step 2: Stop control plane components (on the master)</p> <p>Move static pod manifests out of the kubelet watch path, kubelet will decommission the related pods.</p> <p>The below procedure only works on control plane that is deployed via <code>kubeadm</code>.</p> <pre><code>sudo mkdir -p /etc/kubernetes/manifests.bak\nsudo mv /etc/kubernetes/manifests/*.yaml /etc/kubernetes/manifests.bak/\n\n# get pods status of the components, they should be terminated\nkubectl get pods -n kube-system\n\n# if it does not work, you can try to shut the pod down manually, based on your container runtime, the commands are bit \n# different\n# for containerd\ncrictl ps -a | grep kube\n# or for Docker\ndocker ps -a | grep kube\n\n# Manual Kill (if you want to force stop)\n# for containerd\nsudo crictl ps | grep kube | awk '{print $1}' | xargs -r sudo crictl stop\n\n# for docker\nsudo docker ps | grep kube | awk '{print $1}' | xargs -r sudo docker stop\n</code></pre> <p>Kubelet will detect file removal and terminate the related pods: kube-apiserver, kube-controller-manager, kube-scheduler </p> <p>Step 3: Stop kubelet and container runtime (on all nodes)</p> <p>On all control plane and worker nodes:</p> <pre><code># \nsudo systemctl stop kubelet\n# stop container runtime depending on your setup\n# for containerd\nsudo systemctl stop containerd\n# or for Docker\nsudo systemctl stop docker     \n</code></pre>"},{"location":"container/k8s/deploy_k8s_with_kubeadm/03.K8s_cluster_management/#restart-the-cluster","title":"Restart the cluster","text":"<p>Step 1: Start kubelet and container runtime (on all nodes)</p> <p>On all control plane and worker nodes:</p> <pre><code># start container runtime depending on your setup\n# for containerd\nsudo systemctl start containerd\n# or for Docker\nsudo systemctl start docker     \n\n# start kubelet \nsudo systemctl start kubelet\n</code></pre> <p>Step 2: Restore control plane</p> <p>On the control plane node, restore static manifests:</p> <pre><code>sudo mv /etc/kubernetes/manifests.bak/*.yaml /etc/kubernetes/manifests/\n</code></pre> <p>Cluster should become available within 30\u201360 seconds.</p>"},{"location":"container/k8s/deploy_k8s_with_kubeadm/03.K8s_cluster_management/#destroy-the-cluster","title":"Destroy the cluster","text":"<p>On the control plane:</p> <pre><code>sudo kubeadm reset -f\n# This command stops and removes Kubernetes state\n# 1. Stops the kubelet process (indirectly, by removing configs)\n# Removes the local etcd data if it was part of the control plane\n# Deletes Kubernetes certificates, kubeconfig files, manifests, and state:\n- /etc/kubernetes/admin.conf\n- /etc/kubernetes/kubelet.conf\n- /etc/kubernetes/controller-manager.conf\n- /etc/kubernetes/scheduler.conf\n- /etc/kubernetes/pki/*\n- /etc/kubernetes/manifests/*\n\n# 2. It tries to revert changes made by kube-proxy and CNI plugins:\niptables -t nat -F\niptables -t mangle -F\niptables -F\niptables -X\n\n# 3. It attempts to remove:\n/var/lib/cni/\n/etc/cni/net.d/\n/var/lib/kubelet/\n\n\n# clean the credentials\nsudo rm -rf ~/.kube\n\nsudo systemctl stop kubelet\nsudo systemctl stop containerd \n\n# clean up the config and bin\nsudo rm -rf /etc/kubernetes\nsudo rm -rf /var/lib/etcd\nsudo rm -rf /var/lib/kubelet\nsudo rm -rf /etc/cni \nsudo rm -rf /var/lib/cni\n</code></pre> <p>On the workers:</p> <pre><code>sudo kubeadm reset -f\nsudo rm -rf /var/lib/kubelet /etc/kubernetes\n</code></pre>"},{"location":"container/k8s/deploy_k8s_with_kubeadm/04.Post_k8s_cluster_installation/","title":"Post k8s installation config","text":"<p>After k8s installation, you need to install other tools such as:   - helm   - reverse proxy</p> <p>I consider <code>cni plugin (e.g. calico, flannel, etc.)</code> is a part of basic component of k8s cluster.</p>"},{"location":"container/k8s/deploy_k8s_with_kubeadm/04.Post_k8s_cluster_installation/#1-install-helm","title":"1. Install helm","text":"<p>The official release page of helm can be found here</p> <p>You can use the below bash script to install the latest version.</p> <pre><code>vim install_helm.bash\n\n# put the below content and run it\nbash install_helm.bash\n\n#!/bin/bash\n\nset -euo pipefail\n\nHELM_VERSION=\"v3.18.4\"\nHELM_TAR=\"helm-${HELM_VERSION}-linux-amd64.tar.gz\"\nHELM_URL=\"https://get.helm.sh/${HELM_TAR}\"\nTMP_DIR=\"/tmp/helm-install\"\nHELM_DIR=\"linux-amd64\"\n\nmkdir -p \"$TMP_DIR\"\ncd \"$TMP_DIR\"\n\necho \"Downloading Helm ${HELM_VERSION} to ${TMP_DIR}...\"\nwget -q \"${HELM_URL}\"\n\necho \"Extracting Helm...\"\ntar -xzf \"${HELM_TAR}\"\n\necho \"Setting execution permission...\"\nchmod a+x \"${HELM_DIR}/helm\"\n\necho \"Moving Helm binary to /usr/local/bin...\"\nsudo mv \"${HELM_DIR}/helm\" /usr/local/bin/helm\n\necho \"Cleaning up...\"\nrm -rf \"$TMP_DIR\"\n\necho \"Verifying Helm installation...\"\nif command -v helm &gt;/dev/null 2&gt;&amp;1; then\n    helm version\n    echo \"Helm installed successfully.\"\nelse\n    echo \"Helm installation failed.\"\n    exit 1\nfi\n</code></pre> <p>You should see the helm version and the success message. You need to change version and target system architecture if you use another OS other than debian 11.</p>"},{"location":"container/k8s/deploy_k8s_with_kubeadm/04.Post_k8s_cluster_installation/#2-set-up-a-reverse-proxy","title":"2. Set up a reverse proxy","text":"<p>A <code>reverse proxy</code> is essential for a k8s cluster. Otherwise, the applications deployed in the cluster are not accessible from  the outside world. There are many possible reverse proxy solutions such as: - Kong (commercial alternative): https://konghq.com/ - Traefik (commercial alternative): https://traefik.io/</p> <p>In this tutorial, we choose ingress-nginx.</p>"},{"location":"container/k8s/deploy_k8s_with_kubeadm/04.Post_k8s_cluster_installation/#21-the-ingress-nginx-controller-mode","title":"2.1 The ingress nginx controller mode","text":"<p>There are three modes to set up the proxy and reverse proxy for a k8s cluster: - host - load balancer - nodePort</p>"},{"location":"container/k8s/deploy_k8s_with_kubeadm/04.Post_k8s_cluster_installation/#211-host-mode","title":"2.1.1 Host mode","text":"<p>In host mode, the <code>Ingress controller</code> it uses the host's network namespace. This means that the Ingress  controller binds directly to the host's network interfaces and ports. </p> <p>The advantage of the host mode is that it can achieve higher performance compared to other modes,  as it eliminates the overhead of the kube-proxy layer.</p> <p>The disadvantage is that you cannot run multiple instances of the Ingress controller on the same host with the  same ports, as there would be port conflicts.</p> <p>To view the detailed configuration of host mode, check the section of <code>hostNetwork: true</code> section in the <code>values.yaml</code>  template.</p>"},{"location":"container/k8s/deploy_k8s_with_kubeadm/04.Post_k8s_cluster_installation/#212-load-balancer-mode","title":"2.1.2 Load balancer mode","text":"<p>In the load balancer mode, the Ingress controller typically runs as a service, and an <code>external load balancer</code> (normally provided by the cloud provider) is provisioned to distribute incoming traffic to the Ingress controller service.</p> <p>This mode is suitable for cloud environments where a load balancer service can be provisioned dynamically (e.g., AWS ELB, GCP Load Balancer). The external load balancer takes care of distributing traffic to the nodes running the Ingress controller service.</p> <p>To view the detailed configuration, check the section of <code>appProtocol:True</code> section</p>"},{"location":"container/k8s/deploy_k8s_with_kubeadm/04.Post_k8s_cluster_installation/#213-nodeport-mode","title":"2.1.3 nodePort mode","text":"<p>In NodePort mode, the Ingress controller service is exposed on a static port on each node in the cluster.  This port is accessible from outside the cluster, and the traffic is then forwarded to the Ingress controller.</p> <p>This mode is often used in on-premises or bare-metal environments where cloud load balancers are not available or  in development/testing scenarios.</p> <p>While it provides external access, it might not be as suitable for production environments due to potential  challenges in scaling and managing external access.</p>"},{"location":"container/k8s/deploy_k8s_with_kubeadm/04.Post_k8s_cluster_installation/#3-a-real-example","title":"3. A real example","text":"<p>In this example, we choose the host mode. So the <code>ingress-nginx</code> listens to the network interface of the host server. As a result, only one ingress nginx pod can be deployed on each node. And we don't want to have <code>more than one ingress</code>.  So we added a <code>node selector</code> on the <code>ingress nginx controller service is only deployed on a specific node</code>.</p>"},{"location":"container/k8s/deploy_k8s_with_kubeadm/04.Post_k8s_cluster_installation/#31-select-which-node-to-deploy-the-ingress-nginx-controller","title":"3.1 Select which node to deploy the ingress nginx controller","text":"<p>To deploy <code>ingress nginx controller service on a specific node</code>: - Label a worker node with a specific label (e.g. ingress-node) - Add a <code>node selector</code> on the ingress nginx controller service</p> <p>We label only one node, because we need to set up a dns resolver entry, so <code>all the incoming querier can be redirected to the node which contains the ingress controller</code>. </p> <p>Even we have two pods of Ingress controller. The second one that is not in the DNS will never be used. </p> <pre><code># our k8s cluster \n- Master Node (k8s-master) \u2013 10.50.5.67\n- Worker Node 1 (k8s-worker1) \u2013 10.50.5.68\n- Worker Node 2 (k8s-worker2) \u2013 10.50.5.69\n\n# Here we choose worker 1 to host ingress\n# FQDN for k8s Ingress controller\n10.50.5.68   *.casd.local\n</code></pre>"},{"location":"container/k8s/deploy_k8s_with_kubeadm/04.Post_k8s_cluster_installation/#32-label-the-node","title":"3.2 Label the node","text":"<p>The below commands show you how to label a node with a specific label</p> <pre><code># get all available nodes\nkubectl get nodes\n\n# output example\nNAME            STATUS   ROLES           AGE   VERSION\nonyxia-master   Ready    control-plane   19h   v1.33.2\nonyxia-w01      Ready    &lt;none&gt;          19h   v1.33.2\nonyxia-w02      Ready    &lt;none&gt;          19h   v1.33.2\n\n# general form to label a node, \nkubectl label node &lt;nodename&gt; &lt;label-key&gt;=&lt;label-value&gt;\n\n# example\nkubectl label node onyxia-w01 ingress-node=true\n\n# to un-label a node, you can use the below command\nkubectl label node &lt;nodename&gt; &lt;labelname&gt;-\n\n# example\nkubectl label node worker2 public-\n\n# after labeling, you will see new pod of nginx gets created.\nkubectl get all -n ingress-nginx -w\nkubectl get pods -n ingress-nginx -w\n</code></pre>"},{"location":"container/k8s/deploy_k8s_with_kubeadm/04.Post_k8s_cluster_installation/#33-deploy-the-ingress-nginx-controller-service","title":"3.3 Deploy the ingress nginx controller service","text":"<p>You can use the below commands to deploy the ingress nginx controller service</p> <pre><code># we want it to run is the namespace ingress-nginx, so we create a namespace\nkubectl create namespace ingress-nginx\n\n# add ingress-nginx helm repo\nhelm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx\n\n# update the repo content\nhelm repo update\n\n# list available release \nhelm search repo\n\n# output example\nNAME                            CHART VERSION   APP VERSION     DESCRIPTION\ningress-nginx/ingress-nginx     4.13.0          1.13.0          Ingress controller for Kubernetes using NGINX a\n</code></pre>"},{"location":"container/k8s/deploy_k8s_with_kubeadm/04.Post_k8s_cluster_installation/#331-configure-the-ingress-nginx-controller","title":"3.3.1 Configure the ingress-nginx controller","text":"<p>With the above ingress-nginx repo, we can install an <code>ingress-nginx controller</code> service in our cluster.</p> <p>You can find the full doc https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/</p> <p>You can find the values.yaml template here https://github.com/kubernetes/ingress-nginx/blob/main/charts/ingress-nginx/values.yaml</p>"},{"location":"container/k8s/deploy_k8s_with_kubeadm/04.Post_k8s_cluster_installation/#332-a-minimum-config-example","title":"3.3.2 A minimum config example","text":"<p>Note the below ingress_values.yaml is an example of how our cluster configures the ingress-nginx controller. </p> <pre><code>controller:\n  watchIngressWithoutClass: true\n  allowSnippetAnnotations: false\n  config:\n    error-log-level: \"info\"\n    ignore-invalid-headers: \"false\"\n    proxy-request-buffering: \"off\"\n    proxy-body-size: \"0\"\n    large-client-header-buffers: \"4 16k\"\n\n  hostNetwork: true\n  extraEnvs:\n    - name: MY_POD_IP\n      valueFrom:\n        fieldRef:\n          fieldPath: status.podIP\n  kind: DaemonSet\n  service:\n    enabled: true\n    type: ClusterIP\n  ingressClassResource:\n    name: nginx\n    enabled: true\n    default: true\n    controllerValue: \"k8s.io/ingress-nginx\"\n\nrbac:\n  create: true\npodSecurityPolicy:\n  enabled: false\n</code></pre> <p>With the above configuration, you can have a minimum running ingress controller</p>"},{"location":"container/k8s/deploy_k8s_with_kubeadm/04.Post_k8s_cluster_installation/#333-deploy-the-ingress-service","title":"3.3.3 Deploy the ingress service","text":"<pre><code># we deploy the ingress service with above\n# here the version is the helm chart version.\nhelm install ingress-nginx ingress-nginx/ingress-nginx -f ingress_values.yaml -n ingress-nginx --version v4.13.0\n\n# get all components of the ingress-nginx\nkubectl get all -n ingress-nginx\n\n# output example\nNAME                                 READY   STATUS    RESTARTS   AGE\npod/ingress-nginx-controller-lnd4s   1/1     Running   0          81s\n\nNAME                                         TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGE\nservice/ingress-nginx-controller             ClusterIP   10.96.43.173     &lt;none&gt;        80/TCP,443/TCP   81s\nservice/ingress-nginx-controller-admission   ClusterIP   10.111.211.231   &lt;none&gt;        443/TCP          81s\n\nNAME                                      DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR                              AGE\ndaemonset.apps/ingress-nginx-controller   1         1         1       1            1           ingress-node=true,kubernetes.io/os=linux   81s\n</code></pre> <p>After the pod of ingress service is created, you can try to send a request to the ip of <code>service/ingress-nginx-controller</code>.</p> <pre><code># In our example, the ip address of the service is 10.96.43.173, you can try below command\ncurl 10.96.43.173 \n\n# if you see below output, it means ingress-nginx is running and answering request\n&lt;html&gt;\n&lt;head&gt;&lt;title&gt;404 Not Found&lt;/title&gt;&lt;/head&gt;\n&lt;body&gt;\n&lt;center&gt;&lt;h1&gt;404 Not Found&lt;/h1&gt;&lt;/center&gt;\n&lt;hr&gt;&lt;center&gt;nginx&lt;/center&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <p>ingress nginx <code>cve-2025-1974</code>: https://kubernetes.io/blog/2025/03/24/ingress-nginx-cve-2025-1974/ Avoid the versions which are affected by this CVE.</p>"},{"location":"container/k8s/deploy_k8s_with_kubeadm/04.Post_k8s_cluster_installation/#334-test-ingress-with-an-application","title":"3.3.4 Test ingress with an application","text":"<p>You can try to deploy the <code>mario app</code> and check the certificate. </p> <p>The full manifest can be found here</p> <pre><code># copy the three yaml files in a folder, then run\nkubectl apply -f .\n</code></pre> <p>If your dns is configured to redirect queries to the ingress service, then you should be able to use the url to access the service.</p> <p>You will notice, ingress assigns a <code>fake certificat</code>. Because we have not configured a valid certificate for ingress.</p> <p>We need to replace this <code>fake certificate</code> with a <code>valid certificate</code>.</p>"},{"location":"container/k8s/deploy_k8s_with_kubeadm/04.Post_k8s_cluster_installation/#4-configure-nginx-with-a-custom-certificate-for-all-services","title":"4. Configure nginx with a custom certificate for all services","text":"<p>In this tutorial, we suppose you only have: - a <code>self-signed root CA certificate</code>. - a <code>wildcard certificate signed by the root CA</code>.</p> <p>The objectives are: - <code>Ingress controller</code> trusts the root CA, so it can validate certificates signed by it (for TLS termination). - All apps use the <code>wildcard certificate</code> (e.g., *.casd.local) signed by that internal root CA. - TLS is terminated at the ingress level, and the root CA is the trusted anchor.</p>"},{"location":"container/k8s/deploy_k8s_with_kubeadm/04.Post_k8s_cluster_installation/#41-check-your-certificates","title":"4.1 Check your certificates","text":"<p>You need to have the below certificates: - root ca: - wildcard certificate signed by ca - wildcard certificate <code>private key</code></p>"},{"location":"container/k8s/deploy_k8s_with_kubeadm/04.Post_k8s_cluster_installation/#42-create-a-tls-secret-with-the-wildcard-certificate","title":"4.2 Create a TLS secret with the wildcard certificate","text":"<p>Create a secret to host the certificate and private key.  we name the secret as  <code>casd-wildcard-certificate</code>, you can use the below command</p> <pre><code># general form\nkubectl create secret tls &lt;secret-name&gt; --namespace &lt;namespace-name&gt; --key=pathTo/ingress-tls.key --cert=pathTo/ingress-tls.crt -o yaml\n\n# example\nkubectl create secret tls casd-wildcard-certificate --key=wildcard-casd.key --cert=wildcard-casd.crt -o yaml -n ingress-nginx \n\n# view the content of the secret, the certificate and private value is in base64, you need to decode it to view the\n# value. No encryption at all, so we need to pay attention on who can view this secret.\nkubectl get secret casd-wildcard-certificate -o jsonpath='{.data}' -n ingress-nginx \n\n# you can also edit the value directly\nkubectl edit secret casd-wildcard-certificate -n ingress-nginx \n</code></pre>"},{"location":"container/k8s/deploy_k8s_with_kubeadm/04.Post_k8s_cluster_installation/#43-create-a-secret-for-root-ca","title":"4.3 Create a secret for root ca","text":"<pre><code># Create a Secret for the root CA\nkubectl create secret generic casd-root-ca \\\n  --from-file=ca.crt \\\n  -n ingress-nginx\n\n# check the created secret \nkubectl get secret casd-root-ca -o jsonpath='{.data}' -n ingress-nginx \n</code></pre>"},{"location":"container/k8s/deploy_k8s_with_kubeadm/04.Post_k8s_cluster_installation/#44-mount-root-ca-and-wildcard-certificate-into-nginx-controller","title":"4.4 Mount Root CA and wildcard certificate into NGINX controller","text":"<p>To tell the ingress to use the given certificate, you need to use extraArgs.default-ssl-certificate config. Below is a full example. Then you need to update the ingress controller with new configuration</p> <pre><code>controller:\n  # the ingress controller will process all Ingress resources that do not have an ingressClassName field.\n  watchIngressWithoutClass: true\n  allowSnippetAnnotations: false\n\n  # use node selector to install nginx on a specific node\n  # all nodes that have label ingress-node:\"true\" will have a replicas of the nginx \n  nodeSelector:\n    ingress-node: \"true\"\n\n  config:\n    error-log-level: \"info\"\n    ignore-invalid-headers: \"false\"\n    proxy-request-buffering: \"off\"\n    proxy-body-size: \"0\"\n    large-client-header-buffers: \"4 16k\"\n    # This tells NGINX to verify the TLS certificate presented by the upstream (backend) service.\n    # default value is off\n    proxy-ssl-verify: \"on\"\n    # Specifies the CA certificate NGINX should use to verify the backend service\u2019s TLS certificate\n    proxy-ssl-trusted-ca-file: \"/etc/nginx/certs/ca.crt\"\n    # tells NGINX which CA to use when verifying client certificates, i.e., when a client presents a certificate to authenticate itself.\n    ssl-trusted-ca-file: \"/etc/nginx/certs/ca.crt\"\n\n  hostNetwork: true\n\n  extraEnvs:\n    - name: MY_POD_IP\n      valueFrom:\n        fieldRef:\n          fieldPath: status.podIP\n\n  kind: DaemonSet\n\n  service:\n    enabled: true\n    type: ClusterIP\n\n  ingressClassResource:\n    name: nginx\n    enabled: true\n    default: true\n    controllerValue: \"k8s.io/ingress-nginx\"\n    # Parameters is a link to a custom resource containing additional\n    # configuration for the controller. This is optional if the controller\n    # does not require extra parameters.\n    parameters: {}\n\n  # Set global default TLS certificate (wildcard)\n  # no need to use  `- secretName: casd-test-tls-secret` in ingress.yaml\n  # to specify a custom certificate\n  # the default certificate should be a wildcard which covers your domain\n  extraArgs:\n    default-ssl-certificate: \"ingress-nginx/casd-wildcard-certificate\"\n\n  # Mount internal CA certificate\n  extraVolumeMounts:\n    - name: root-ca\n      mountPath: /etc/nginx/certs\n      readOnly: true\n\n  extraVolumes:\n    - name: root-ca\n      secret:\n        secretName: casd-root-ca\n\nrbac:\n  create: true\n\npodSecurityPolicy:\n  enabled: false\n</code></pre> <p>Make sure you have the wildcard and root-ca certificate secret in ingress-nginx name space.</p>"},{"location":"container/k8s/deploy_k8s_with_kubeadm/04.Post_k8s_cluster_installation/#45-update-existing-ingress-nginx-deployment","title":"4.5 Update existing ingress-nginx deployment","text":"<p>The best way to update a deployment (deployed via helm chart) is to modify the <code>values.yaml</code>. Then call the below command</p> <pre><code># general form\nhelm upgrade &lt;deployment-name&gt; &lt;chart-name&gt; -f &lt;config-file&gt; -n &lt;namespace&gt;\n\n# example\nhelm upgrade ingress-nginx ingress-nginx/ingress-nginx -f ingress_values.yaml -n ingress-nginx\n\n# to delete \nhelm delete ingress-nginx -n ingress-nginx\n</code></pre>"},{"location":"container/k8s/k8s_client_setup/01.Install_kubectl_and_helm/","title":"K8s clients","text":"<p>To interact with a k8s cluster, you need at lest two clients: - kubectl - helm</p>"},{"location":"container/k8s/k8s_client_setup/01.Install_kubectl_and_helm/#1-kubectl","title":"1. kubectl","text":"<p>kubectl is a command line tool for communicating with a Kubernetes cluster's control plane, using the Kubernetes API.</p> <p>For configuration, it looks for a file named <code>config</code> in the <code>$HOME/.kube</code> directory. You can specify other  kubeconfig files by setting the <code>KUBECONFIG</code> environment variable or by setting the <code>--kubeconfig</code> flag.</p>"},{"location":"container/k8s/k8s_client_setup/01.Install_kubectl_and_helm/#11-installation","title":"1.1 Installation","text":"<p>You can find the official doc here</p> <p>You can follow the below steps to install it. Below instruction are tested for x86-64 architecture.</p> <pre><code># 1. Download the binary with curl \ncurl -LO \"https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\"\n\n# 2. Get the hash of the binary\ncurl -LO \"https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl.sha256\"\n\n# 3. validate the binary by checking the hash\necho \"$(cat kubectl.sha256)  kubectl\" | sha256sum --check\n\n# 4. copy bin to your local bin\nsudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl\n\n# 5. check the installation\nkubectl version\n\n# output example\nClient Version: v1.31.2\nKustomize Version: v5.4.2\nThe connection to the server localhost:8080 was refused - did you specify the right host or port?\n</code></pre> <p>The default config is pointing to localhost:8080, we need to replace it with the k8s api server url. </p>"},{"location":"container/k8s/k8s_client_setup/01.Install_kubectl_and_helm/#12-configuration","title":"1.2 Configuration","text":"<p>As we mentioned, the default config file is located at ``. Below is an example of the config content. </p> <pre><code>apiVersion: v1\nclusters:\n- cluster:\n    certificate-authority-data: changeMe\n    server: https://k8s-master:6443\n  name: kubernetes\ncontexts:\n- context:\n    cluster: kubernetes\n    user: kubernetes-admin\n  name: kubernetes-admin@kubernetes\ncurrent-context: kubernetes-admin@kubernetes\nkind: Config\npreferences: {}\nusers:\n- name: kubernetes-admin\n  user:\n    client-certificate-data: changeMe\n    client-key-data: changeMe\n</code></pre> <p>You can notice the access control in the k8s cluster is RBAC.</p> <p>Normally, the admin of the k8s cluster will provide you the login(username), and the credential(e.g. password, token, etc.)</p> <p>You can find the official doc of API access control here</p>"},{"location":"container/k8s/k8s_client_setup/01.Install_kubectl_and_helm/#helm","title":"Helm","text":"<p>You can find the official installation doc here. You need to choose a version which is compatible with your k8s cluster and your local OS(e.g. linux-amd64, windows-amd64, etc.).</p> <p>The available version can be found here.</p> <p>For example, in below example, we choose version <code>3.16.2</code>.</p> <pre><code># get the source\nwget https://get.helm.sh/helm-v3.16.2-linux-amd64.tar.gz\n\n\ntar -xzvf helm-v3.16.2-linux-amd64.tar.gz\n\nchmod a+x linux-amd64/helm\n\nmv linux-amd64/helm /usr/local/bin/helm\n\n# add the bitnami repo\nhelm repo add bitnami https://charts.bitnami.com/bitnami\n\n# show available charts in the bitnami repo\nhelm search repo bitnami\n</code></pre> <p>Check Artifact Hub for all public available Helm chart repositories.</p>"},{"location":"container/k8s/k8s_client_setup/02.Helm_introduction/","title":"Helm introduction","text":"<p>Helm is a package manager for Kubernetes. It provides an easy way to <code>find, share, and manage</code> Kubernetes  configurations. With Helm, you can:</p> <ul> <li>Deploy applications quickly and consistently.</li> <li>Version control deployments, enabling rollbacks to previous versions.</li> <li>Configure applications with different environments or options, using values and templates.</li> <li>Package complex applications that contain multiple components into a single Helm chart. </li> </ul> <p>It has a client server architecture: - helm repo servers: A server which stores and distributes helm charts - helm client</p>"},{"location":"container/k8s/k8s_client_setup/02.Helm_introduction/#1-what-is-a-helm-chart","title":"1. What is a helm chart?","text":"<p>Helm uses a packaging format called charts.  It\u2019s essentially a collection of <code>YAML files and templates</code>  that define a Kubernetes application and its dependencies. Charts make it possible to bundle multiple  Kubernetes resources (like Deployments, Services, ConfigMaps, etc.) into a single package.</p> <p>Each Helm chart typically contains:</p> <ul> <li>Chart.yaml - Metadata about the chart, like its name, version, and description.</li> <li>values.yaml - Default configuration values that the chart uses. You can override these values when                       installing the chart, allowing for flexible configuration.</li> <li>Templates - A set of files defining Kubernetes resources (in YAML) with placeholders that get replaced                     based on values in <code>values.yaml</code>. Templates allow for dynamic configuration.</li> <li>README - Documentation explaining the chart, how to configure it, and any dependencies it has.</li> </ul> <p>Finally, <code>a running deployed instance of a chart</code> with a specific config is called a release.</p>"},{"location":"container/k8s/k8s_client_setup/02.Helm_introduction/#2-install-helm-client","title":"2. Install helm client","text":"<p>You can find the official installation doc here. You need to choose a version which is compatible with your k8s cluster and your local OS(e.g. linux-amd64, windows-amd64, etc.).</p> <p>The available version can be found here.</p> <p>For example, in below example, we choose version <code>3.16.2</code>.</p> <pre><code># get the source\nwget https://get.helm.sh/helm-v3.16.2-linux-amd64.tar.gz\n\n\ntar -xzvf helm-v3.16.2-linux-amd64.tar.gz\n\nchmod a+x linux-amd64/helm\n\nmv linux-amd64/helm /usr/local/bin/helm\n\n# add the bitnami repo\nhelm repo add bitnami https://charts.bitnami.com/bitnami\n</code></pre> <p>Check Artifact Hub for all public available Helm chart repositories.</p>"},{"location":"container/k8s/k8s_client_setup/02.Helm_introduction/#3-creating-your-own-chart","title":"3. Creating your own chart","text":"<p>Now let's create a new chart with name <code>hello-world</code></p> <pre><code># below command creates a chart skeleton\n# the name of the chart provided here (e.g. hello-world) \n# will be the directory's name where the chart is created and stored.\nhelm create hello-world\n\n# check the content of the generated hello-world folder\ntree -L 3 hello-world/\nhello-world/\n\u251c\u2500\u2500 charts\n\u251c\u2500\u2500 Chart.yaml\n\u251c\u2500\u2500 templates\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 deployment.yaml\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 _helpers.tpl\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 hpa.yaml\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 ingress.yaml\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 NOTES.txt\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 serviceaccount.yaml\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 service.yaml\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 tests\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 test-connection.yaml\n\u2514\u2500\u2500 values.yaml\n</code></pre> <p>Let's understand the relevance of these created files and folders:</p> <ul> <li>charts: This is an optional directory that may contain sub-charts</li> <li>Chart.yaml: This is the main file that contains the description of our chart</li> <li>templates: This is the directory where Kubernetes resources are defined as templates</li> <li>values.yaml: This is the file that contains the default config values for our chart</li> <li>.helmignore: This is where we can define patterns to ignore when packaging (similar in concept to .gitignore)</li> </ul> <p>You can find the generated chart skeleton in resources/harbor/helm/charts/hello-world.</p> <p>Here, we only modify the <code>values.yaml</code> to deploy it on a k8s cluster</p>"},{"location":"container/k8s/k8s_client_setup/02.Helm_introduction/#31-validating-a-chart","title":"3.1 Validating a chart","text":"<p>Before you deploy your chart, it's recommended that you valid your chart first (well-formed). You can use <code>helm lint</code> to do that. Below command is an example</p> <pre><code>helm lint ./hello-world\n</code></pre> <p>You can also render the generated k8s resource with the given default values.yaml</p> <pre><code>helm template ./hello-world\n</code></pre>"},{"location":"container/k8s/k8s_client_setup/02.Helm_introduction/#32-deploy-a-release-with-helm-chart","title":"3.2 Deploy a release with helm chart","text":"<p>Once we've verified the chart to be fine, finally, we can below command to install the chart into the Kubernetes cluster</p> <pre><code>helm install --name chart-sample ./hello-world\n\n# you can view the deployed release \nhelm ls -all \n\n# upgrade your release with new setup\nhelm upgrade hello-world ./hello-world\n\n# you can notice that after each upgrade, the revision number increase, so you can rollback\n# with any number that inferieur than current. Below example will rollback to 1\nhelm rollback hello-world 1\n\n# delete the release\nhelm uninstall hello-world\n</code></pre>"},{"location":"container/k8s/k8s_client_setup/02.Helm_introduction/#33-distributing-charts","title":"3.3 Distributing charts","text":"<p>Helm acts as a package manager for the Kubernetes application and makes installing, querying, upgrading, and deleting releases pretty seamless.</p> <p>In addition to this, we can also use <code>Helm to package, publish, and fetch Kubernetes applications as chart archives</code>.  We can also use the Helm CLI for this as it offers several commands to perform these activities. </p> <pre><code># after this command, you should see hello-world-0.1.0.tgz\nhelm package ./hello-world \n</code></pre>"},{"location":"container/k8s/k8s_client_setup/02.Helm_introduction/#331-use-github-as-helm-repo","title":"3.3.1 Use github as helm repo","text":"<p>Finally, we need a mechanism to work with shared repositories to collaborate. There are several sub-commands available within this command that we can use to <code>add, remove, update, list, or index chart repositories</code>. Let's see how we can use them.</p> <p>We can create a git repository and use that to function as our chart repository. The only requirement is that it should have an index.yaml file.</p> <p>We can create index.yaml for our chart repo:</p> <pre><code># This generates the index.yaml file, which we should push to the repository along with the chart archives.\nhelm repo index my-repo/ --url https://&lt;username&gt;.github.io/my-repo\n\n# After successfully creating the chart repository, subsequently, we can remotely add this repo:\nhelm repo add my-repo https://my-pages.github.io/my-repo\n\n# Now, we should be able to install the charts from our repo directly:\nhelm install my-repo/hello-world --name=hello-world\n</code></pre>"},{"location":"container/k8s/k8s_client_setup/02.Helm_introduction/#332-use-private-helm-repo","title":"3.3.2 Use private helm repo","text":""},{"location":"container/k8s/k8s_client_setup/03.Helm_use_private_repo/","title":"Helm client use private registry","text":"<p>In this tutorial, I will show how to use helm client to interact with a private chart registry. - Add the private repo to the helm client - Create a custom helm chart - publish the chart to the private repo - Deploy an instance by downloading the helm chart from the private repo.</p> <p>In this tutorial, the private registry is built by using the chartmuseum.</p>"},{"location":"container/k8s/k8s_client_setup/03.Helm_use_private_repo/#1-add-the-private-registry-to-the-helm-client","title":"1. Add the private registry to the helm client","text":"<p>In this example, the private registry uses the basic auth to authenticate users</p> <pre><code># add the registry to helm client\n# I named the repo as cm\nhelm repo add --username admin --password changeMe cm https://chart.casd.local/\n\n# look up available charts in the repo\nhelm search repo cm\n</code></pre>"},{"location":"container/k8s/k8s_client_setup/03.Helm_use_private_repo/#2-create-a-custom-helm-chart","title":"2. Create a custom helm chart","text":"<p>Now let's create a new chart with name <code>mario</code>. This chart will deploy the famous game <code>mario</code> as a web page game.</p> <pre><code># below command creates a chart skeleton\n# the name of the chart provided here (e.g. mario) \n# will be the directory's name where the chart is created and stored.\nhelm create mario\n\n# check the content of the generated mario folder\ntree -L 3 mario/\n\n# the architecture of the generated skeleton\nmario/\n\u251c\u2500\u2500 charts\n\u251c\u2500\u2500 Chart.yaml\n\u251c\u2500\u2500 templates\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 deployment.yaml\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 _helpers.tpl\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 hpa.yaml\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 ingress.yaml\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 NOTES.txt\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 serviceaccount.yaml\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 service.yaml\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 tests\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 test-connection.yaml\n\u2514\u2500\u2500 values.yaml\n</code></pre> <p>Let's understand the relevance of these created files and folders:</p> <ul> <li>charts: This is an optional directory that may contain sub-charts</li> <li>Chart.yaml: This is the main file that contains the description of our chart</li> <li>templates: This is the directory where Kubernetes resources are defined as templates</li> <li>values.yaml: This is the file that contains the default config values for our chart</li> <li>.helmignore: This is where we can define patterns to ignore when packaging (similar in concept to .gitignore)</li> </ul> <p>Suppose we have an origin deployment, service and ingress configuration as shown below.</p> <ul> <li>mario_deployment.yaml</li> </ul> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mario\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: mario\n  template:\n    metadata:\n      labels:\n        app: mario\n    spec:\n      containers:\n        - name: mario\n          image: reg.casd.local/casd/docker-supermario\n          ports:\n            - name: http\n              containerPort: 8080\n      imagePullSecrets:\n        - name: harbor-auth\n</code></pre> <ul> <li>mario_service.yaml</li> </ul> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: mario\nspec:\n  type: ClusterIP\n  ports:\n    - name: http\n      targetPort: 8080\n      port: 80\n  selector:\n    app: mario\n</code></pre> <ul> <li>mario_ingress.yaml</li> </ul> <pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: ingress-mario\nspec:\n  # tls:\n  #   - hosts:\n  #       - mario.kub.sspcloud.fr\n  rules:\n    - host: mario.casd.dev\n      http:\n        paths:\n          - path: /\n            pathType: Prefix\n            backend:\n              service:\n                name: mario\n                port:\n                  number: 80\n</code></pre> <p>In general, you need to at least modify the below files in the generated skeleton:  - <code>Chart.yaml</code>: name, description of the app. Pay attention of the value of <code>appVersion</code>, it will be used in the                   template <code>templates/deployment.yaml</code> as default image tag if the image tag value is empty in <code>values.yaml</code>.  - <code>templates/deployment.yaml</code>: You need to adapt the template based on the origin <code>deployment.yaml</code>. For example, the       <code>containerPort</code> value depends on how the image is build. In general, the default value will not work.  - <code>templates/service.yaml</code>: You need to adapt the template based on the origin <code>service.yaml</code>. For example, the       <code>targetPort</code> value depends on how the <code>deployment.yaml</code> is specified. You can't put a value which does not match.  - <code>templates/ingress.yaml</code>: You need to adapt the template based on the origin <code>ingress.yaml</code>.  - <code>values.yaml</code>: This stores all default value of the chart. If user provide nothing, the deployed instance will use                 the value in this file.</p> <p>You can find the complete chart example in src/k8s/helm/custom_chart/mario.</p> <p>Once, the chart is published, the user only need to modify the <code>values.yaml</code> to deploy it on a k8s cluster. If user need to modify the template, it means the chart is not well-designed.</p>"},{"location":"container/k8s/k8s_client_setup/03.Helm_use_private_repo/#31-validating-a-chart","title":"3.1 Validating a chart","text":"<p>Before you deploy your chart, it's recommended that you valid your chart first (well-formed).  You can use helm lint to do that. Below command is an example</p> <pre><code># validate the chart syntax\nhelm lint ./mario\n</code></pre> <p>You can also render the generated k8s resource with the given default values.yaml</p> <pre><code>helm template ./mario\n</code></pre>"},{"location":"container/k8s/k8s_client_setup/03.Helm_use_private_repo/#32-deploy-a-release-with-helm-chart","title":"3.2 Deploy a release with helm chart","text":"<p>Once we've verified the chart to be fine, finally, we can below command to install the chart into the Kubernetes cluster</p> <pre><code>helm install mario-test ./mario\n\n# you can view the deployed release \nhelm ls -n &lt;name-space&gt;\n\n# upgrade your release with new chart version\nhelm upgrade mario-test ./mario\n\n# you can notice that after each upgrade, the revision number increase, so you can rollback\n# with any number that inferior than current. Below example will rollback to 1\nhelm rollback mario-test 1\n\n# delete the release\nhelm uninstall mario-test\n</code></pre>"},{"location":"container/k8s/k8s_client_setup/03.Helm_use_private_repo/#4-publish-your-chart-to-private-registry","title":"4. Publish your chart to private registry","text":"<p>The below steps only works for registries built by <code>chartmuseum</code>.  There are two ways to push charts to ChartMuseum: - via the <code>api of chartMuseum</code> - via <code>helm cm-push plugin</code>, the easiest way is to use helm cm-push plugin. You can find the official github page here</p>"},{"location":"container/k8s/k8s_client_setup/03.Helm_use_private_repo/#41-publish-via-the-api","title":"4.1 Publish via the api","text":"<pre><code># package your chart source\ncd mario/\nhelm package .\n\n# this command will generate a .tgz file. The version comes from the version value of `Chart.yaml`\nmario-0.1.0.tgz \n\n# upload the binary to the registry\n# if you have setup an auto redirect from http to https, you must call https in the curl command, \n# otherwise you will get a 301 status error due to the redirection.\ncurl --data-binary \"@mario-0.1.0.tgz\" https://chart.casd.local/api/charts\n\n# If you\u2019ve signed your package and generated a provenance file, upload it with:\ncurl --data-binary \"@mario-0.1.0.tgz.prov\" https://chart.casd.local/api/prov\n\n# upload the package and provenance file at same time\ncurl -F \"chart=@mario-0.1.0.tgz\" -F \"prov=@mario-0.1.0.tgz.prov\" https://chart.casd.local/api/charts\n\n# check if a chart exists in the registry or not, this will return a list of all available charts\ncurl https://chart.casd.local/api/charts\n\n# delete a chart\ncurl -X DELETE https://chart.casd.local/api/charts/mario/0.1.0\n</code></pre>"},{"location":"container/k8s/k8s_client_setup/03.Helm_use_private_repo/#42-publish-via-cm-push-plugin","title":"4.2 Publish via cm-push plugin","text":"<p>The <code>cm-push plugin</code> is not installed by default, you need to install it first.</p> <pre><code># install the plugin\nhelm plugin install https://github.com/chartmuseum/helm-push\n\n# check the installed plugin\nhelm cm-push  --help\n\n# add your private chartmuseum as a repo\nhelm repo add --username admin --password changeMe cm https://chart.casd.local/\n\n# push the chart, with the plugin, you don't need to do helm package anymore\n# you can push the directory directly, the plugin will package the chart, then push\nhelm cm-push mario/ cm\n\n# Push .tgz package is still supported\nhelm cm-push mario-0.1.0.tgz cm\n\n# push with a custom version\nhelm cm-push mario/ --version=\"0.2.0\" cm\n\n# If your ChartMuseum install is configured with ALLOW_OVERWRITE=true, chart versions will be automatically overwritten upon re-upload.\n# Otherwise, the upload will be denied with message file already exist. Unless your install is configured with DISABLE_FORCE_OVERWRITE=true (ChartMuseum &gt; v0.7.1), you can use the --force/-f option to to force an upload to overwrite an existing chart\nhelm cm-push --force mario-0.2.1.tgz chartmuseum\n\n# push without adding chart repo. Below example shows how to push to an repo directly\nhelm cm-push mario-0.2.1.tgz http://chart.casd.local/\n</code></pre> <p>To check if the register is updated or not. You can follow the below commands</p> <pre><code># list all available repo\nhelm repo list\n\n# update the index of a repo\nhelm repo update\n\n# Search a chart on all the added repo with a give keyword\nhelm search repo &lt;repo-name&gt;\n\n# if you want to use regex, you need to use option -r\nhelm search repo -r \"*mario*\"\n\n# to further filter your result, you can add an grep after\nhelm search repo -r \"nginx\" | grep -i \"bitnami\"\n</code></pre>"},{"location":"container/k8s/k8s_client_setup/03.Helm_use_private_repo/#5-remove-the-private-registry","title":"5. Remove the private registry","text":"<pre><code># Remove a repo\nhelm repo remove &lt;repo-name&gt;\n</code></pre>"},{"location":"container/k8s/k8s_security/01.K8s_security_best_practices/","title":"k8s cluster security best practices","text":""},{"location":"container/k8s/k8s_security/01.K8s_security_best_practices/#1-secure-api-access","title":"1. Secure API Access","text":"<ul> <li>Use RBAC (Role-Based Access Control): Restrict permissions based on the principle of least privilege.</li> <li>Disable Anonymous Access: Ensure all API requests are authenticated.</li> <li>Enable Audit Logging: Monitor and log API activity to detect anomalies.</li> <li>Use Network Policies: Restrict API access to trusted sources.</li> </ul>"},{"location":"container/k8s/k8s_security/01.K8s_security_best_practices/#2-secure-authentication-authorization","title":"2. Secure Authentication &amp; Authorization","text":"<ul> <li>Use Strong Authentication: Rely on an identity provider (OIDC, Active Directory, etc.).</li> <li>Enable Multi-Factor Authentication (MFA): Strengthens access security.</li> <li>Limit Service Account Permissions: Avoid giving service accounts excessive privileges.</li> </ul>"},{"location":"container/k8s/k8s_security/01.K8s_security_best_practices/#3-secure-cluster-networking","title":"3. Secure Cluster Networking","text":"<ul> <li>Use Network Policies: Restrict pod-to-pod communication based on necessity.</li> <li>Enable Encryption in Transit: Use TLS for securing API server, ETCD, and service communications.</li> <li>Restrict External Access: Expose only necessary services using Ingress controllers.</li> </ul>"},{"location":"container/k8s/k8s_security/01.K8s_security_best_practices/#4-protect-etcd-database","title":"4. Protect ETCD Database","text":"<ul> <li>Enable Encryption at Rest: Encrypt sensitive data stored in ETCD.</li> <li>Restrict Access to ETCD: Allow access only to the API server and use strong authentication.</li> <li>Regular Backups: Ensure ETCD is backed up regularly and stored securely.</li> </ul>"},{"location":"container/k8s/k8s_security/01.K8s_security_best_practices/#5-secure-workloads-pods","title":"5. Secure Workloads &amp; Pods","text":"<ul> <li>Use Pod Security Standards (PSS) or Pod Security Admission (PSA): Restrict privileges for pods.</li> <li>Enable Seccomp and AppArmor: Use security profiles to limit system calls.</li> <li>Avoid Running as Root: Use runAsUser and runAsNonRoot to enforce non-root execution.</li> <li>Restrict Privileged Containers: Prevent containers from running with excessive privileges.</li> </ul>"},{"location":"container/k8s/k8s_security/01.K8s_security_best_practices/#6-secure-supply-chain-image-security","title":"6. Secure Supply Chain &amp; Image Security","text":"<ul> <li>Use Trusted Container Images: Always pull images from verified sources.</li> <li>Sign and Verify Images: Use tools like Cosign or Docker Content Trust.</li> <li>Scan Images for Vulnerabilities: Utilize tools like Trivy, Clair, or Anchore.</li> <li>Restrict Image Registries: Allow deployments only from trusted registries.</li> </ul>"},{"location":"container/k8s/k8s_security/01.K8s_security_best_practices/#7-limit-resource-access","title":"7. Limit Resource Access","text":"<ul> <li>Enforce Resource Quotas &amp; Limits: Prevent resource exhaustion by setting CPU/memory limits.</li> <li>Use Admission Controllers: Enforce security policies before workloads are created.</li> <li>Disable Default Service Account Auto-Mounting: Prevent unnecessary service account access.</li> </ul>"},{"location":"container/k8s/k8s_security/01.K8s_security_best_practices/#8-secure-logging-monitoring","title":"8. Secure Logging &amp; Monitoring","text":"<ul> <li>Use Security Information and Event Management (SIEM) Tools: Aggregate logs for real-time analysis.</li> <li>Enable Kubernetes Audit Logs: Detect unauthorized API actions.</li> <li>Monitor Containers and Nodes: Use Prometheus, Falco, or Sysdig for runtime security.</li> </ul>"},{"location":"container/k8s/k8s_security/01.K8s_security_best_practices/#9-protect-against-network-attacks","title":"9. Protect Against Network Attacks","text":"<ul> <li>Enable CNI Plugins with Security Features: Calico, Cilium, or Antrea provide additional security.</li> <li>Enforce Egress and Ingress Rules: Restrict network traffic using NetworkPolicies.</li> <li>Use Service Mesh for Encryption: Istio or Linkerd provide mutual TLS for service-to-service communication.</li> </ul>"},{"location":"container/k8s/k8s_security/01.K8s_security_best_practices/#10-keep-kubernetes-and-dependencies-updated","title":"10. Keep Kubernetes and Dependencies Updated","text":"<ul> <li>Regularly Patch and Upgrade Kubernetes: Stay up to date with the latest security patches.</li> <li>Upgrade Third-Party Plugins &amp; Dependencies: Keep Helm charts and other dependencies current.</li> </ul>"},{"location":"container/k8s/k8s_security/06.k8s_security/","title":"k8s network security","text":""},{"location":"container/k8s/k8s_security/06.k8s_security/#network-security","title":"network security","text":"<p><code>Container Network Interface (CNI)</code> is a framework for dynamically configuring networking resources.</p> <p>Check this page https://www.tigera.io/learn/guides/kubernetes-networking/kubernetes-cni/</p>"},{"location":"hadoop/Integrate_kerberos_in_hadoop_cluster/","title":"Integrate kerberos into a hadoop cluster","text":"<p>In this tutorial, we will show how to integrate kerberos into a hadoop cluster. The goal is to use the kerberos tickets to authenticate users, hosts(e.g. namenode, datanode, resourceManager, etc.) and services(e.g. hdfs, yarn). </p> <p>We have different strategy for different kinds of users. For service account, we will generate <code>.keytab</code> files to generate kerberos tickets automatically. For user account, a password maybe required to generate the ticket.</p>"},{"location":"hadoop/Integrate_kerberos_in_hadoop_cluster/#1-prerequisite","title":"1. Prerequisite","text":"<p>Before we start, we need to clarify the hadoop cluster context. Because the <code>AD/Ldap account</code> and <code>kerberos principal</code> naming conventions strongly depends on the cluster architecture.</p> <p>Suppose we have three servers, in each server we run different services: - spark-m01.casdds.casd: name-node(hdfs), resource-manager(yarn), history-server(spark) - spark-m02.casdds.casd: data-node(hdfs), node-manager(yarn) - spark-m03.casdds.casd: data-node(hdfs), node-manager(yarn)</p> <p>We suppose you already join these machines into the AD/krb realm. For more details, you can check this  doc </p>"},{"location":"hadoop/Integrate_kerberos_in_hadoop_cluster/#11-prepare-service-account-and-their-keytab","title":"1.1 Prepare service account and their keytab","text":"<p>By convention, we recommend you to create <code>a dedicated AD/Ldap account and kerberos principal for each service</code>.  This ensures <code>secure authentication</code> and <code>proper ticket management</code>. It's also easier to monitor access and avoid  unexpected situations. Technically, an AD/Ldap account can be associated with one or more kerberos principals.</p> <p>Below is a list of all AD/Ldap accounts and kerberos principal you need to create:</p> Service Hadoop Role Host Kerberos Principal AD account name HDFS NameNode spark-m01.casdds.casd nn/spark-m01.casdds.casd@CASDDS.CASD hdfs-nn HDFS DataNode spark-m02.casdds.casd dn/spark-m02.casdds.casd@CASDDS.CASD hdfs-dn1 HDFS DataNode spark-m03.casdds.casd dn/spark-m03.casdds.casd@CASDDS.CASD hdfs-dn2 HDFS HTTP Service spark-m01.casdds.casd http/spark-m01.casdds.casd@CASDDS.CASD http-nn HDFS HTTP Service spark-m02.casdds.casd http/spark-m02.casdds.casd@CASDDS.CASD http-dn1 HDFS HTTP Service spark-m03.casdds.casd http/spark-m03.casdds.casd@CASDDS.CASD http-dn2 YARN ResourceManager spark-m01.casdds.casd rm/spark-m01.casdds.casd@CASDDS.CASD yarn-rn YARN NodeManager spark-m02.casdds.casd nm/spark-m02.casdds.casd@CASDDS.CASD yarn-nm1 YARN NodeManager spark-m03.casdds.casd nm/spark-m03.casdds.casd@CASDDS.CASD yarn-nm2 Spark History Server spark-m01.casdds.casd jhs/spark-m01.casdds.casd@CASDDS.CASD spark-jhs HOST None spark-m01.casdds.casd host/spark-m01.casdds.casd@CASDDS.CASD spark-m01 HOST None spark-m02.casdds.casd host/spark-m02.casdds.casd@CASDDS.CASD spark-m02 HOST None spark-m03.casdds.casd host/spark-m03.casdds.casd@CASDDS.CASD spark-m03 <p>The AD account name cannot contain special character such as <code>@</code> and <code>.</code>, so we can't use the principal name as  AD account name. </p> <p>You can create an AD account in windows with the below command</p> <pre><code># create AD account and kerberos principal\nNew-ADUser -Name \"hdfs-nn\" -SamAccountName \"hdfs-nn\" -UserPrincipalName \"nn/spark-m01.casdds.casd@CASDDS.CASD\" -Enabled $true -PasswordNeverExpires $true -CannotChangePassword $true -ChangePasswordAtLogon $false -PassThru | Set-ADAccountControl -PasswordNotRequired $true\n\n# create corresponding keytab\nktpass -princ nn/spark-m01.casdds.casd@CASDDS.CASD -mapuser hdfs-nn -crypto ALL -ptype KRB5_NT_PRINCIPAL -pass Password! -out hdfs-nn.keytab\n</code></pre> <p>After you generate the required keytab files for all principals, you need to copy them to the target server. For example, for server <code>spark-m01.casdds.casd@CASDDS.CASD</code>, you need to copy the keytab file for principals: - nn/spark-m01.casdds.casd@CASDDS.CASD - HTTP/spark-m01.casdds.casd@CASDDS.CASD - rm/spark-m01.casdds.casd@CASDDS.CASD - jhs/spark-m01.casdds.casd@CASDDS.CASD - host/spark-m01.casdds.casd@CASDDS.CASD</p> <p>The general rule is straightforward, you need to check the host fqdn name in the principals </p> <p>You can test the validity of the keytab file by asking a kerberos ticket. Below command is an example</p> <pre><code>kinit -kt /etc/hdfs-nn.keytab nn/spark-m01.casdds.casd@CASDDS.CASD\n</code></pre> <p>To show the details of a keytab file, you can use the below command: </p> <pre><code>klist -e -k -t /etc/yarn.keytab\n\n# expected output\nKeytab name: FILE: /etc/yarn.keytab\n KVNO Timestamp         Principal\n   4 07/18/11 21:08:09 yarn/spark-m02.casdds.casd (AES-256 CTS mode with 96-bit SHA-1 HMAC)\n   4 07/18/11 21:08:09 yarn/spark-m02.casdds.casd (AES-128 CTS mode with 96-bit SHA-1 HMAC)\n   4 07/18/11 21:08:09 yarn/spark-m02.casdds.casd (ArcFour with HMAC/md5)\n   4 07/18/11 21:08:09 host/spark-m02.casdds.casd (AES-256 CTS mode with 96-bit SHA-1 HMAC)\n   4 07/18/11 21:08:09 host/spark-m02.casdds.casd (AES-128 CTS mode with 96-bit SHA-1 HMAC)\n   4 07/18/11 21:08:09 host/spark-m02.casdds.casd (ArcFour with HMAC/md5)\n</code></pre>"},{"location":"hadoop/Integrate_kerberos_in_hadoop_cluster/#12-merge-the-keytab-files","title":"1.2 Merge the keytab files","text":"<p>To avoid managing many keytab files, you can merge the multi keytab files into one by using <code>ktutil</code> tool.</p> <pre><code># start a ktuitl shell with sudo right\nsudo ktutil\n\n# load credentials from the keytab files\nrkt /tmp/yarnm02.keytab\nrkt /tmp/hostm02.keytab\n\n# output the loaded credential to a new keytable file\nwkt /tmp/merged.keytab\n\n# exit the ktuitl shell\nq\n</code></pre> <p>You can test the content of the merged keytab file with the below command</p> <pre><code>sudo klist -k /tmp/merged.keytab\n</code></pre>"},{"location":"hadoop/Integrate_kerberos_in_hadoop_cluster/#13-check-if-the-hadoop-servers-are-in-the-ad-dns","title":"1.3. Check if the hadoop servers are in the AD DNS","text":"<p>Normally, when the linux servers have joined the AD/Krb realm, their AD/DNS configuration are done automatically.</p> <p>Just to make sure, you can open the DNS manager on the <code>Domain controller</code> where AD/Krb is located. Below figure is an example of the <code>DNS manager GUI</code></p> <p></p> <p>You need to check the <code>value of FQDN and ip</code> for each server in <code>forward and reverse lookup zones</code>.</p> <p>Below figure is an example for the Forward loopup zone definition of a server</p> <p></p>"},{"location":"hadoop/Integrate_kerberos_in_hadoop_cluster/#14-check-kerberos-client","title":"1.4. Check kerberos client","text":"<p>Normally, you should have a valid krb5 client and config on each hadoop node.</p> <p>Below is an example of the krb5 client conf(<code>/etc/krb5.conf</code>).</p> <pre><code>[libdefaults]\ndefault_realm = CASDDS.CASD\ndefault_tkt_enctypes = aes256-cts-hmac-sha1-96 aes128-cts-hmac-sha1-96\ndefault_tgs_enctypes = aes256-cts-hmac-sha1-96 aes128-cts-hmac-sha1-96\npermitted_enctypes   = aes256-cts-hmac-sha1-96 aes128-cts-hmac-sha1-96\nkdc_timesync = 1\nccache_type = 4\nforwardable = true\nticket_lifetime = 24h\ndns_lookup_realm = true\ndns_lookup_kdc = true\n\n#allow_weak_crypto = true\n\n[realms]\nCASDDS.CASD = {\n    kdc = 10.50.5.64\n    admin_server = 10.50.5.64\n}\n\n[domain_realm]\n.CASDDS.CASD = CASDDS.CASD\nCASDDS.CASD = CASDDS.CASD\n</code></pre> <p>You can enable allow_weak_crypto = true, if the AD/Krb can't use advance crypto algorithm</p>"},{"location":"hadoop/Integrate_kerberos_in_hadoop_cluster/#2-enable-ssl-in-the-hadoop-cluster","title":"2. Enable SSL in the hadoop cluster","text":"<p>To secure communication between services in the hadoop cluster, we can enable SSL.</p>"},{"location":"hadoop/Integrate_kerberos_in_hadoop_cluster/#21-generate-certificate","title":"2.1 Generate certificate","text":"<p>Generate a key pair and store it in a java key store</p> <pre><code>sudo keytool -genkeypair \\\n  -alias hadoop \\\n  -keyalg RSA \\\n  -keysize 2048 \\\n  -validity 365 \\\n  -keystore /opt/hadoop/keystore.jks \\\n  -storepass changeit\n</code></pre> <p>Check the keystore content </p> <pre><code>sudo keytool -list -keystore /opt/hadoop/keystore.jks -storepass changeit\n</code></pre> <p>Export the certificate</p> <pre><code>sudo keytool -export -alias hadoop -keystore /opt/hadoop/keystore.jks -file /opt/hadoop/hadoop-cert.pem -storepass changeit\n</code></pre>"},{"location":"hadoop/Integrate_kerberos_in_hadoop_cluster/#22-configuration-of-ssl-in-hadoop-cluster","title":"2.2 Configuration of SSL in hadoop cluster","text":"<p>The ssl configuration file in hadoop cluster is <code>$HADOOP_HOME/etc/hadoop/ssl-server.xml</code> and  <code>$HADOOP_HOME/etc/hadoop/ssl-client.xml</code>. In our case, we only need to modify <code>ssl-server.xml</code>.</p> <p>Below is an example of the <code>ssl-server.xml</code></p> <pre><code>sudo vim ssl-server.xml\n</code></pre> <p>Add the below lines</p> <pre><code>&lt;configuration&gt;\n  &lt;property&gt;\n    &lt;name&gt;ssl.server.keystore.location&lt;/name&gt;\n    &lt;value&gt;/opt/hadoop/keystore.jks&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;ssl.server.keystore.password&lt;/name&gt;\n    &lt;value&gt;changeit&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;ssl.server.keystore.keypassword&lt;/name&gt;\n    &lt;value&gt;changeit&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;ssl.server.keystore.type&lt;/name&gt;\n    &lt;value&gt;jks&lt;/value&gt;\n    &lt;description&gt;(Optionnel) Format du keystore (par d\u00e9faut \u00ab jks \u00bb).&lt;/description&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;ssl.server.exclude.cipher.list&lt;/name&gt;\n    &lt;value&gt;\n      TLS_ECDHE_RSA_WITH_RC4_128_SHA,\n      SSL_DHE_RSA_EXPORT_WITH_DES40_CBC_SHA,\n      SSL_RSA_WITH_DES_CBC_SHA,\n      SSL_DHE_RSA_WITH_DES_CBC_SHA,\n      SSL_RSA_EXPORT_WITH_RC4_40_MD5,\n      SSL_RSA_EXPORT_WITH_DES40_CBC_SHA,\n      SSL_RSA_WITH_RC4_128_MD5\n    &lt;/value&gt;\n    &lt;description&gt;(Optionnel) Liste des suites de chiffrement faibles \u00e0 exclure.&lt;/description&gt;\n  &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre> <p>This needs to be done all nodes of the hadoop cluster</p>"},{"location":"hadoop/Integrate_kerberos_in_hadoop_cluster/#2-integrate-kerberos-in-to-hadoop-cluster","title":"2. Integrate kerberos in to Hadoop cluster","text":"<p>Here, we suppose you already have a working hadoop cluster, the below steps only shows how to integrate kerberos into Hadoop. If you want to learn how to deploy a hadoop cluster, you need to follow this  doc</p>"},{"location":"hadoop/Integrate_kerberos_in_hadoop_cluster/#21-edit-hadoop-envsh","title":"2.1 Edit hadoop-env.sh","text":"<p>The <code>hadoop-env.sh</code> file specifies all environment variables related to the hadoop cluster</p> <p>Below is a list of variables you need to check </p> <pre><code>export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64\nexport HADOOP_OPTS=\"-Djava.net.preferIPv4Stack=true -Djava.security.debug=gssloginconfig,configfile,configparser,logincontext\"\n# use krb client config \nexport HADOOP_OPTS=\"-Djava.security.krb5.conf=/etc/krb5.conf $HADOOP_OPTS\"\nexport HDFS_NAMENODE_USER=hadoop\nexport HDFS_DATANODE_USER=hadoop\nexport HDFS_SECONDARYNAMENODE_USER=hadoop\nexport JSVC_HOME=$(dirname $(which jsvc))\nexport HADOOP_CONF_DIR=/opt/hadoop/etc/hadoop\nexport HADOOP_SECURITY_LOGGER=INFO,RFAS,console\nexport JAVA_TOOL_OPTIONS=\"$JAVA_TOOL_OPTIONS --add-opens=java.base/sun.net.dns=ALL-UNNAMED\"\n</code></pre>"},{"location":"hadoop/Integrate_kerberos_in_hadoop_cluster/#22-updates-the-security-configuration-of-jdk","title":"2.2 Updates the security configuration of JDK","text":"<p>For kerberos interoperate well with JDK, we need to update the default security conf of the JDK. </p> <pre><code>sudo vim $JAVA_HOME/conf/security/java.security\n\n# in our case, we use openjdk in debian 11. We can use the absolute path\nsudo vim /usr/lib/jvm/java-11-openjdk-amd64/conf/security/java.security\n\n# you need to add the below lines\ncrypto.policy=unlimited\nsun.security.krb5.disableReferrals=true\n</code></pre> <p>By default, the <code>RC4</code> encryption algo is disabled, because it's weak. But some Windows server still uses it. You can find the line <code>jdk.jar.disabledAlgorithms</code> and <code>jdk.tls.disabledAlgorith</code>, then remove the <code>RC4</code> from the  disabled algo list.</p>"},{"location":"hadoop/Integrate_kerberos_in_hadoop_cluster/#23-update-the-hadoop-service-configuration","title":"2.3 Update the hadoop service configuration","text":""},{"location":"hadoop/Integrate_kerberos_in_hadoop_cluster/#231-for-name-nodes","title":"2.3.1 For Name nodes","text":"<p>For <code>Name nodes</code>, you need to edit the below config files: - core-site.xml - hdfs-site.xml - yarn-site.xml</p> <pre><code>sudo vim core-site.xml \n\n# add the below lines\n&lt;configuration&gt;\n  &lt;property&gt;\n    &lt;name&gt;hadoop.ssl.server.conf&lt;/name&gt;\n    &lt;value&gt;/opt/hadoop/etc/hadoop/ssl-server.xml&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;fs.defaultFS&lt;/name&gt;\n    &lt;value&gt;hdfs://spark-m01.casdds.casd:9000&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;hadoop.security.authentication&lt;/name&gt;\n    &lt;value&gt;kerberos&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;hadoop.security.authorization&lt;/name&gt;\n    &lt;value&gt;true&lt;/value&gt;\n  &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;hadoop.security.group.mapping&lt;/name&gt;\n        &lt;value&gt;org.apache.hadoop.security.ShellBasedUnixGroupsMapping&lt;/value&gt;\n    &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;hadoop.http.authentication.type&lt;/name&gt;\n    &lt;value&gt;kerberos&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;hadoop.http.authentication.kerberos.principal&lt;/name&gt;\n    &lt;value&gt;HTTP/spark-m01.casdds.casd@CASDDS.CASD&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;hadoop.http.authentication.kerberos.keytab&lt;/name&gt;\n    &lt;value&gt;/etc/httpm01.keytab&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;hadoop.http.filter.initializers&lt;/name&gt;\n    &lt;value&gt;org.apache.hadoop.security.AuthenticationFilterInitializer&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;hadoop.security.auth_to_local&lt;/name&gt;\n    &lt;value&gt;\n      RULE:[2:$1@$0](.*@casdds\\.casd)s/@casdds\\.casd//\n      RULE:[1:$1]\n      DEFAULT\n    &lt;/value&gt;\n    &lt;description&gt;Mapping du principal Kerberos vers le nom d\u2019utilisateur local.&lt;/description&gt;\n  &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre> <pre><code>sudo vim hdfs-site.xml\n\n# add the below lines\n&lt;configuration&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.https.server.keystore.resource&lt;/name&gt;\n    &lt;value&gt;ssl-server.xml&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.http.policy&lt;/name&gt;\n    &lt;value&gt;HTTPS_ONLY&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.https.port&lt;/name&gt;\n    &lt;value&gt;50470&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.data.transfer.protection&lt;/name&gt;\n    &lt;value&gt;authentication&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.secondary.https.port&lt;/name&gt;\n    &lt;value&gt;50490&lt;/value&gt;\n    &lt;description&gt;Port HTTPS pour le secondary-namenode.&lt;/description&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.https.address&lt;/name&gt;\n    &lt;value&gt;spark-m01.casdds.casd:50470&lt;/value&gt;\n    &lt;description&gt;Adresse HTTPS d\u2019\u00e9coute du Namenode.&lt;/description&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.encrypt.data.transfer&lt;/name&gt;\n    &lt;value&gt;true&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.replication&lt;/name&gt;\n    &lt;value&gt;3&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;\n    &lt;value&gt;file:///opt/hadoop/hadoop_tmp/hdfs/data&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;\n    &lt;value&gt;file:///opt/hadoop/hadoop_tmp/hdfs/data&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.permissions&lt;/name&gt;\n    &lt;value&gt;true&lt;/value&gt;\n    &lt;description&gt;Activation de la v\u00e9rification des permissions sur HDFS.&lt;/description&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.namenode.handler.count&lt;/name&gt;\n    &lt;value&gt;100&lt;/value&gt;\n    &lt;description&gt;Augmentation de la file d\u2019attente pour g\u00e9rer davantage de connexions clients.&lt;/description&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;ipc.server.max.response.size&lt;/name&gt;\n    &lt;value&gt;5242880&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.permissions.supergroup&lt;/name&gt;\n    &lt;value&gt;hadoop&lt;/value&gt;\n    &lt;description&gt;Nom du groupe des super-utilisateurs.&lt;/description&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.cluster.administrators&lt;/name&gt;\n    &lt;value&gt;hadoop&lt;/value&gt;\n    &lt;description&gt;ACL pour l\u2019acc\u00e8s aux servlets par d\u00e9faut de HDFS.&lt;/description&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.access.time.precision&lt;/name&gt;\n    &lt;value&gt;0&lt;/value&gt;\n    &lt;description&gt;D\u00e9sactivation de la mise \u00e0 jour des temps d\u2019acc\u00e8s pour les fichiers HDFS.&lt;/description&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.block.access.token.enable&lt;/name&gt;\n    &lt;value&gt;true&lt;/value&gt;\n    &lt;description&gt;Activation des tokens d\u2019acc\u00e8s pour s\u00e9curiser l\u2019acc\u00e8s aux datanodes.&lt;/description&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;ipc.server.read.threadpool.size&lt;/name&gt;\n    &lt;value&gt;5&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.namenode.http-address&lt;/name&gt;\n    &lt;value&gt;spark-m01.casdds.casd:9870&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.namenode.kerberos.principal&lt;/name&gt;\n    &lt;value&gt;hdfs/spark-m01.casdds.casd@CASDDS.CASD&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.namenode.keytab.file&lt;/name&gt;\n    &lt;value&gt;/etc/hdfsm01.keytab&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.secondary.namenode.kerberos.principal&lt;/name&gt;\n    &lt;value&gt;hdfs/spark-m01.casdds.casd@CASDDS.CASD&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.secondary.namenode.keytab.file&lt;/name&gt;\n    &lt;value&gt;/etc/hdfsm01.keytab&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.permissions.enabled&lt;/name&gt;\n    &lt;value&gt;true&lt;/value&gt;\n  &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre> <pre><code>sudo vim yarn-site.xml\n\n# add the below lines\n&lt;configuration&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;\n    &lt;value&gt;mapreduce_shuffle&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt;\n    &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;\n    &lt;value&gt;spark-m01.casdds.casd&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.nodemanager.resource.cpu-vcores&lt;/name&gt;\n    &lt;value&gt;2&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt;\n    &lt;value&gt;2048&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.scheduler.maximum-allocation-mb&lt;/name&gt;\n    &lt;value&gt;2048&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.scheduler.minimum-allocation-mb&lt;/name&gt;\n    &lt;value&gt;512&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.resourcemanager.principal&lt;/name&gt;\n    &lt;value&gt;yarn/spark-m01.casdds.casd@CASDDS.CASD&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.resourcemanager.keytab&lt;/name&gt;\n    &lt;value&gt;/etc/yarnm01.keytab&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.timeline-service.principal&lt;/name&gt;\n    &lt;value&gt;yarn/spark-m01.casdds.casd@CASDDS.CASD&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.timeline-service.keytab&lt;/name&gt;\n    &lt;value&gt;/etc/yarnm01.keytab&lt;/value&gt;\n  &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre>"},{"location":"hadoop/Integrate_kerberos_in_hadoop_cluster/#232-for-datanode","title":"2.3.2 For DataNode","text":"<p>For data nodes, you need to edit the below configuration files: - core-site.xml - hdfs-site.xml - yarn-site.xml</p> <pre><code>sudo vim core-site.xml\n\n# add the below lines\n&lt;configuration&gt;\n  &lt;property&gt;\n    &lt;name&gt;fs.defaultFS&lt;/name&gt;\n    &lt;value&gt;hdfs://spark-m01.casdds.casd:9000&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;hadoop.security.authentication&lt;/name&gt;\n    &lt;value&gt;kerberos&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;hadoop.security.authorization&lt;/name&gt;\n    &lt;value&gt;true&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;hadoop.ssl.server.conf&lt;/name&gt;\n    &lt;value&gt;ssl-server.xml&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;hadoop.security.auth_to_local&lt;/name&gt;\n    &lt;value&gt;\n      RULE:[2:$1@$0](.*@CASDDS\\.CASD)s/@CASDDS\\.CASD//\n      RULE:[1:$1]\n      DEFAULT\n    &lt;/value&gt;\n    &lt;description&gt;Mapping du principal Kerberos vers l\u2019utilisateur local.&lt;/description&gt;\n  &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre> <pre><code>sudo vim hdfs-site.xml\n\n# add the below lines\n&lt;configuration&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.https.server.keystore.resource&lt;/name&gt;\n    &lt;value&gt;ssl-server.xml&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.http.policy&lt;/name&gt;\n    &lt;value&gt;HTTPS_ONLY&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.https.port&lt;/name&gt;\n    &lt;value&gt;50470&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.data.transfer.protection&lt;/name&gt;\n    &lt;value&gt;authentication&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.secondary.https.port&lt;/name&gt;\n    &lt;value&gt;50490&lt;/value&gt;\n    &lt;description&gt;Port HTTPS pour le secondary-namenode.&lt;/description&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.https.address&lt;/name&gt;\n    &lt;value&gt;ip-10-50-5-203.casdds.casd:50470&lt;/value&gt;\n    &lt;description&gt;Adresse HTTPS d\u2019\u00e9coute du Namenode sur le DataNode.&lt;/description&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.encrypt.data.transfer&lt;/name&gt;\n    &lt;value&gt;true&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.replication&lt;/name&gt;\n    &lt;value&gt;3&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;\n    &lt;value&gt;file:///opt/hadoop/hadoop_tmp/hdfs/data&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;\n    &lt;value&gt;file:///opt/hadoop/hadoop_tmp/hdfs/data&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.datanode.kerberos.principal&lt;/name&gt;\n    &lt;value&gt;hdfs/spark-m02.casdds.casd@CASDDS.CASD&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.datanode.keytab.file&lt;/name&gt;\n    &lt;value&gt;/etc/hdfsm02.keytab&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.namenode.kerberos.principal&lt;/name&gt;\n    &lt;value&gt;hdfs/spark-m01.casdds.casd@CASDDS.CASD&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.namenode.keytab.file&lt;/name&gt;\n    &lt;value&gt;/etc/hdfsm01.keytab&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.permissions&lt;/name&gt;\n    &lt;value&gt;true&lt;/value&gt;\n    &lt;description&gt;Activation de la v\u00e9rification des permissions sur HDFS.&lt;/description&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.permissions.supergroup&lt;/name&gt;\n    &lt;value&gt;hadoop&lt;/value&gt;\n    &lt;description&gt;Nom du groupe des super-utilisateurs.&lt;/description&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;ipc.server.max.response.size&lt;/name&gt;\n    &lt;value&gt;5242880&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.block.access.token.enable&lt;/name&gt;\n    &lt;value&gt;true&lt;/value&gt;\n    &lt;description&gt;Activation des tokens d\u2019acc\u00e8s pour l\u2019acc\u00e8s aux datanodes.&lt;/description&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.datanode.data.dir.perm&lt;/name&gt;\n    &lt;value&gt;750&lt;/value&gt;\n    &lt;description&gt;Permissions requises sur les r\u00e9pertoires de donn\u00e9es.&lt;/description&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.access.time.precision&lt;/name&gt;\n    &lt;value&gt;0&lt;/value&gt;\n    &lt;description&gt;D\u00e9sactivation de la mise \u00e0 jour des temps d\u2019acc\u00e8s pour les fichiers HDFS.&lt;/description&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.cluster.administrators&lt;/name&gt;\n    &lt;value&gt;hadoop&lt;/value&gt;\n    &lt;description&gt;ACL pour l\u2019acc\u00e8s aux servlets par d\u00e9faut de HDFS.&lt;/description&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;ipc.server.read.threadpool.size&lt;/name&gt;\n    &lt;value&gt;5&lt;/value&gt;\n  &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre> <pre><code>sudo vim yarn-site.xml\n\n# add the below lines\n&lt;configuration&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;\n    &lt;value&gt;mapreduce_shuffle&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt;\n    &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.nodemanager.hostname&lt;/name&gt;\n    &lt;value&gt;spark-m02.casdds.casd&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;\n    &lt;value&gt;spark-m01.casdds.casd&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.nodemanager.resource.cpu-vcores&lt;/name&gt;\n    &lt;value&gt;2&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt;\n    &lt;value&gt;2048&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.scheduler.maximum-allocation-mb&lt;/name&gt;\n    &lt;value&gt;2048&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.scheduler.minimum-allocation-mb&lt;/name&gt;\n    &lt;value&gt;512&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.resourcemanager.principal&lt;/name&gt;\n    &lt;value&gt;yarn/spark-m01.casdds.casd@CASDDS.CASD&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.resourcemanager.keytab&lt;/name&gt;\n    &lt;value&gt;/etc/yarnm01.keytab&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.timeline-service.principal&lt;/name&gt;\n    &lt;value&gt;yarn/spark-m02.casdds.casd@CASDDS.CASD&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.timeline-service.keytab&lt;/name&gt;\n    &lt;value&gt;/etc/yarnm02.keytab&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.nodemanager.principal&lt;/name&gt;\n    &lt;value&gt;yarn/spark-m02.casdds.casd@CASDDS.CASD&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.nodemanager.keytab&lt;/name&gt;\n    &lt;value&gt;/etc/yarnm02.keytab&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.timeline-service.http-authentication.type&lt;/name&gt;\n    &lt;value&gt;kerberos&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt;\n    &lt;value&gt;true&lt;/value&gt;\n  &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre>"},{"location":"hadoop/Integrate_kerberos_in_hadoop_cluster/#refresh-user-to-group-mappings","title":"Refresh User to group mappings","text":"<pre><code>hdfs dfsadmin -refreshUserToGroupsMappings\n</code></pre>"},{"location":"hadoop/Integrate_kerberos_in_hadoop_cluster/#reference","title":"Reference","text":"<ul> <li>https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SecureMode.html</li> <li>http://docs.cloudera.com.s3-website-us-east-1.amazonaws.com/HDPDocuments/HDP3/HDP-3.1.5/security-reference/content/kerberos_nonambari_adding_security_information_to_configuration_files.html</li> </ul>"},{"location":"hadoop/Integrate_kerberos_in_hadoop_cluster/#repo-test","title":"Repo test","text":"<p>https://github.com/CASD-EU/admin_sys/tree/test/dev/roles</p>"},{"location":"hadoop/Integrate_kerberos_in_hadoop_cluster_fr/","title":"Integrate kerberos in hadoop cluster fr","text":""},{"location":"hadoop/Integrate_kerberos_in_hadoop_cluster_fr/#integration-de-kerberos-dans-un-cluster-hadoop","title":"Int\u00e9gration de Kerberos dans un cluster Hadoop","text":"<p>Cette documentation d\u00e9crit les \u00e9tapes pour s\u00e9curiser l\u2019authentification des composants d\u2019un cluster Hadoop (NameNode, DataNode, ResourceManager, etc.) \u00e0 l\u2019aide de Kerberos et SSL.</p>"},{"location":"hadoop/Integrate_kerberos_in_hadoop_cluster_fr/#1-contexte-et-architecture","title":"1. Contexte et architecture","text":"<ul> <li> <p>Cluster : 3 n\u0153uds (spark-m01, spark-m02, spark-m03) dans le domaine CASDDS.CASD</p> </li> <li> <p>spark-m01 : NameNode, ResourceManager, HistoryServer</p> </li> <li> <p>spark-m02 &amp; spark-m03 : DataNode, NodeManager</p> </li> <li> <p>But :</p> </li> <li> <p>Authentification forte via Kerberos</p> </li> <li>Chiffrement des communications via SSL/TLS</li> </ul>"},{"location":"hadoop/Integrate_kerberos_in_hadoop_cluster_fr/#2-prerequis","title":"2. Pr\u00e9requis","text":"<ol> <li> <p>AD/Kerberos</p> </li> <li> <p>Les serveurs Linux doivent \u00eatre joints au domaine AD/Kerberos <code>CASDDS.CASD</code></p> </li> <li> <p>Un contr\u00f4leur de domaine (KDC + DNS) configur\u00e9 pour forward/reverse lookup</p> </li> <li> <p>Logiciels</p> </li> <li> <p>Java\u00a011 (OpenJDK)</p> </li> <li>Hadoop 3.x</li> <li>Utilitaires Kerberos (<code>kinit</code>, <code>klist</code>, <code>ktpass</code>, <code>ktutil</code>)</li> <li>Keytool (Java)</li> </ol>"},{"location":"hadoop/Integrate_kerberos_in_hadoop_cluster_fr/#3-configuration-kerberos","title":"3. Configuration Kerberos","text":""},{"location":"hadoop/Integrate_kerberos_in_hadoop_cluster_fr/#31-creation-des-comptes-service-et-keytabs","title":"3.1. Cr\u00e9ation des comptes service et keytabs","text":"<p>Pour chaque service, cr\u00e9ez un compte AD d\u00e9di\u00e9 et g\u00e9n\u00e9rez un fichier <code>.keytab</code> :</p> Service R\u00f4le FQDN Principal Kerberos AD User HDFS NameNode NameNode spark-m01.casdds.casd <code>hdfs/spark-m01.casdds.casd@CASDDS.CASD</code> <code>hdfs-m01</code> HDFS DataNode DataNode spark-m02.casdds.casd <code>hdfs/spark-m02.casdds.casd@CASDDS.CASD</code> <code>hdfs-m02</code> HDFS DataNode DataNode spark-m03.casdds.casd <code>hdfs/spark-m03.casdds.casd@CASDDS.CASD</code> <code>hdfs-m03</code> HTTP HTTP Service spark-m01.casdds.casd <code>HTTP/spark-m01.casdds.casd@CASDDS.CASD</code> <code>http-m01</code> YARN RM ResourceManager spark-m01.casdds.casd <code>yarn/spark-m01.casdds.casd@CASDDS.CASD</code> <code>yarn-m01</code> YARN NM NodeManager spark-m0X.casdds.casd <code>yarn/spark-m0X.casdds.casd@CASDDS.CASD</code> <code>yarn-m0x</code> HOST Host principal spark-m0X.casdds.casd <code>host/spark-m0X.casdds.casd@CASDDS.CASD</code> <code>host-m0X</code> <p>Commande Windows (AD) :</p> <pre><code>New-ADUser -Name \"hdfs-m01\" -SamAccountName \"hdfs-m01\" \\\n  -UserPrincipalName \"hdfs/spark-m01.casdds.casd@CASDDS.CASD\" \\\n  -Enabled $true -PasswordNeverExpires $true -CannotChangePassword $true\n\nktpass -princ hdfs/spark-m01.casdds.casd@CASDDS.CASD \\\n  -mapuser hdfs-m01 -crypto ALL -ptype KRB5_NT_PRINCIPAL \\\n  -pass \"Password!\" -out hdfs-m01.keytab\n\nscp hdfs-m01.keytab user@spark-m0x.casdds.casd:/tmp/\n</code></pre> <p>Copiez chaque keytab sous <code>/etc/</code> sur le serveur correspondant, avec permissions <code>root:hadoop</code>, <code>chmod 640</code>.</p>"},{"location":"hadoop/Integrate_kerberos_in_hadoop_cluster_fr/#32-verification-des-keytabs","title":"3.2. V\u00e9rification des keytabs","text":"<pre><code># Authentication sans mot de passe\nkinit -kt /etc/hdfs-m01.keytab hdfs/spark-m01.casdds.casd@CASDDS.CASD\n# Afficher tickets\nklist\n# Lister contenu d'un keytab\nklist -e -k -t /etc/hdfs-m01.keytab\n</code></pre>"},{"location":"hadoop/Integrate_kerberos_in_hadoop_cluster_fr/#33-fusion-de-plusieurs-keytabs","title":"3.3. Fusion de plusieurs keytabs","text":"<pre><code>sudo ktutil\nrkt /tmp/yarn-m02.keytab\nrkt /tmp/host-m02.keytab\nwkt /etc/merged.keytab\nq\nsudo klist -k /etc/merged.keytab\n</code></pre>"},{"location":"hadoop/Integrate_kerberos_in_hadoop_cluster_fr/#4-configuration-du-client-kerberos-etckrb5conf","title":"4. Configuration du client Kerberos (/etc/krb5.conf)","text":"<pre><code>[libdefaults]\n  default_realm = CASDDS.CASD\n  default_tkt_enctypes = aes256-cts-hmac-sha1-96 aes128-cts-hmac-sha1-96\n  default_tgs_enctypes = aes256-cts-hmac-sha1-96 aes128-cts-hmac-sha1-96\n  permitted_enctypes = aes256-cts-hmac-sha1-96 aes128-cts-hmac-sha1-96\n  kdc_timesync = 1\n  ticket_lifetime = 24h\n  forwardable = true\n  dns_lookup_realm = true\n  dns_lookup_kdc = true\n  rdns = false\n  #allow_weak_crypto = true\n\n[realms]\n  CASDDS.CASD = {\n    kdc = @ip\n    admin_server = @ip\n  }\n\n[domain_realm]\n  .casdds.casd = CASDDS.CASD\n  casdds.casd = CASDDS.CASD\n</code></pre> <p>D\u00e9commentez <code>allow_weak_crypto = true</code> si n\u00e9cessaire pour RC4.</p>"},{"location":"hadoop/Integrate_kerberos_in_hadoop_cluster_fr/#5-securisation-ssltls","title":"5. S\u00e9curisation SSL/TLS","text":""},{"location":"hadoop/Integrate_kerberos_in_hadoop_cluster_fr/#51-generation-du-keystore-java","title":"5.1. G\u00e9n\u00e9ration du keystore Java","text":"<pre><code>sudo keytool -genkeypair \\\n  -alias hadoop -keyalg RSA -keysize 2048 -validity 365 \\\n  -keystore /opt/hadoop/keystore.jks -storepass changeit\nsudo keytool -list -keystore /opt/hadoop/keystore.jks -storepass changeit\nsudo keytool -export -alias hadoop \\\n  -file /opt/hadoop/hadoop-cert.pem -keystore /opt/hadoop/keystore.jks \\\n  -storepass changeit\n</code></pre>"},{"location":"hadoop/Integrate_kerberos_in_hadoop_cluster_fr/#52-configuration-ssl-serverxml","title":"5.2. Configuration <code>ssl-server.xml</code>","text":"<pre><code>&lt;configuration&gt;\n  &lt;property&gt;\n    &lt;name&gt;ssl.server.keystore.location&lt;/name&gt;\n    &lt;value&gt;/opt/hadoop/keystore.jks&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;ssl.server.keystore.password&lt;/name&gt;\n    &lt;value&gt;changeit&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;ssl.server.keystore.keypassword&lt;/name&gt;\n    &lt;value&gt;changeit&lt;/value&gt;\n  &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;ssl.server.keystore.type&lt;/name&gt;\n        &lt;value&gt;jks&lt;/value&gt;\n        &lt;description&gt;Optional. The keystore file format, default value is \"jks\".&lt;/description&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;ssl.server.exclude.cipher.list&lt;/name&gt;\n        &lt;value&gt;TLS_ECDHE_RSA_WITH_RC4_128_SHA,SSL_DHE_RSA_EXPORT_WITH_DES40_CBC_SHA,\n        SSL_RSA_WITH_DES_CBC_SHA,SSL_DHE_RSA_WITH_DES_CBC_SHA,\n        SSL_RSA_EXPORT_WITH_RC4_40_MD5,SSL_RSA_EXPORT_WITH_DES40_CBC_SHA,\n        SSL_RSA_WITH_RC4_128_MD5&lt;/value&gt;\n        &lt;description&gt;Optional. The weak security cipher suites that you want excludedfrom SSL communication.&lt;/description&gt;\n    &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre> <p>R\u00e9p\u00e9tez l\u2019op\u00e9ration sur tous les n\u0153uds.</p>"},{"location":"hadoop/Integrate_kerberos_in_hadoop_cluster_fr/#6-configuration-hadoop","title":"6. Configuration Hadoop","text":""},{"location":"hadoop/Integrate_kerberos_in_hadoop_cluster_fr/#61-hadoop-envsh","title":"6.1. <code>hadoop-env.sh</code>","text":"<pre><code>export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64\nexport HADOOP_OPTS=\"-Djava.net.preferIPv4Stack=true -Djava.security.debug=gssloginconfig,configfile,configparser,logincontext\"\nexport HADOOP_OPTS=\"-Djava.security.krb5.conf=/etc/krb5.conf $HADOOP_OPTS\"\nexport HDFS_NAMENODE_USER=hadoop\nexport HDFS_DATANODE_USER=hadoop\nexport HDFS_SECONDARYNAMENODE_USER=hadoop\nexport JSVC_HOME=$(dirname $(which jsvc))\nexport HADOOP_CONF_DIR=/opt/hadoop/etc/hadoop\nexport HADOOP_SECURITY_LOGGER=INFO,RFAS,console\nexport JAVA_TOOL_OPTIONS=\"$JAVA_TOOL_OPTIONS --add-opens=java.base/sun.net.dns=ALL-UNNAMED\"\n</code></pre>"},{"location":"hadoop/Integrate_kerberos_in_hadoop_cluster_fr/#62-politiques-de-securite-java","title":"6.2. Politiques de s\u00e9curit\u00e9 Java","text":"<pre><code># $JAVA_HOME/conf/security/java.security\ncrypto.policy = unlimited\nsun.security.krb5.disableReferrals = true\n# Retirer RC4 de jdk.jar.disabledAlgorithms / jdk.tls.disabledAlgorithms si besoin\n</code></pre>"},{"location":"hadoop/Integrate_kerberos_in_hadoop_cluster_fr/#63-configuration-des-services","title":"6.3. Configuration des services","text":""},{"location":"hadoop/Integrate_kerberos_in_hadoop_cluster_fr/#631-namenode-core-sitexml-hdfs-sitexml-yarn-sitexml","title":"6.3.1. NameNode (<code>core-site.xml</code>, <code>hdfs-site.xml</code>, <code>yarn-site.xml</code>)","text":"<pre><code>&lt;!-- core-site.xml --&gt;\n&lt;configuration&gt;\n  &lt;property&gt;\n    &lt;name&gt;hadoop.ssl.server.conf&lt;/name&gt;\n    &lt;value&gt;/opt/hadoop/etc/hadoop/ssl-server.xml&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;fs.defaultFS&lt;/name&gt;\n    &lt;value&gt;hdfs://spark-m01.casdds.casd:9000&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;hadoop.security.authentication&lt;/name&gt;\n    &lt;value&gt;kerberos&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;hadoop.security.authorization&lt;/name&gt;\n    &lt;value&gt;true&lt;/value&gt;\n  &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;hadoop.security.group.mapping&lt;/name&gt;\n        &lt;value&gt;org.apache.hadoop.security.ShellBasedUnixGroupsMapping&lt;/value&gt;\n    &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;hadoop.http.authentication.type&lt;/name&gt;\n    &lt;value&gt;kerberos&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;hadoop.http.authentication.kerberos.principal&lt;/name&gt;\n    &lt;value&gt;HTTP/spark-m01.casdds.casd@CASDDS.CASD&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;hadoop.http.authentication.kerberos.keytab&lt;/name&gt;\n    &lt;value&gt;/etc/http-m01.keytab&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;hadoop.http.filter.initializers&lt;/name&gt;\n    &lt;value&gt;org.apache.hadoop.security.AuthenticationFilterInitializer&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;hadoop.security.auth_to_local&lt;/name&gt;\n    &lt;value&gt;\n      RULE:[2:$1@$0](.*@casdds\\.casd)s/@casdds\\.casd//\n      RULE:[1:$1]\n      DEFAULT\n    &lt;/value&gt;\n    &lt;description&gt;Mapping du principal Kerberos vers le nom d\u2019utilisateur local.&lt;/description&gt;\n  &lt;/property&gt;\n&lt;/configuration&gt;\n&lt;!-- hdfs-site.xml --&gt;\n&lt;configuration&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.https.server.keystore.resource&lt;/name&gt;\n    &lt;value&gt;ssl-server.xml&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.http.policy&lt;/name&gt;\n    &lt;value&gt;HTTPS_ONLY&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.https.port&lt;/name&gt;\n    &lt;value&gt;50470&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.data.transfer.protection&lt;/name&gt;\n    &lt;value&gt;authentication&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.secondary.https.port&lt;/name&gt;\n    &lt;value&gt;50490&lt;/value&gt;\n    &lt;description&gt;Port HTTPS pour le secondary-namenode.&lt;/description&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.https.address&lt;/name&gt;\n    &lt;value&gt;spark-m01.casdds.casd:50470&lt;/value&gt;\n    &lt;description&gt;Adresse HTTPS d\u2019\u00e9coute du Namenode.&lt;/description&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.encrypt.data.transfer&lt;/name&gt;\n    &lt;value&gt;true&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.replication&lt;/name&gt;\n    &lt;value&gt;3&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;\n    &lt;value&gt;file:///opt/hadoop/hadoop_tmp/hdfs/data&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;\n    &lt;value&gt;file:///opt/hadoop/hadoop_tmp/hdfs/data&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.permissions&lt;/name&gt;\n    &lt;value&gt;true&lt;/value&gt;\n    &lt;description&gt;Activation de la v\u00e9rification des permissions sur HDFS.&lt;/description&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.namenode.handler.count&lt;/name&gt;\n    &lt;value&gt;100&lt;/value&gt;\n    &lt;description&gt;Augmentation de la file d\u2019attente pour g\u00e9rer davantage de connexions clients.&lt;/description&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;ipc.server.max.response.size&lt;/name&gt;\n    &lt;value&gt;5242880&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.permissions.supergroup&lt;/name&gt;\n    &lt;value&gt;hadoop&lt;/value&gt;\n    &lt;description&gt;Nom du groupe des super-utilisateurs.&lt;/description&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.cluster.administrators&lt;/name&gt;\n    &lt;value&gt;hadoop&lt;/value&gt;\n    &lt;description&gt;ACL pour l\u2019acc\u00e8s aux servlets par d\u00e9faut de HDFS.&lt;/description&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.access.time.precision&lt;/name&gt;\n    &lt;value&gt;0&lt;/value&gt;\n    &lt;description&gt;D\u00e9sactivation de la mise \u00e0 jour des temps d\u2019acc\u00e8s pour les fichiers HDFS.&lt;/description&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.block.access.token.enable&lt;/name&gt;\n    &lt;value&gt;true&lt;/value&gt;\n    &lt;description&gt;Activation des tokens d\u2019acc\u00e8s pour s\u00e9curiser l\u2019acc\u00e8s aux datanodes.&lt;/description&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;ipc.server.read.threadpool.size&lt;/name&gt;\n    &lt;value&gt;5&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.namenode.http-address&lt;/name&gt;\n    &lt;value&gt;spark-m01.casdds.casd:9870&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.namenode.kerberos.principal&lt;/name&gt;\n    &lt;value&gt;hdfs/spark-m01.casdds.casd@CASDDS.CASD&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.namenode.keytab.file&lt;/name&gt;\n    &lt;value&gt;/etc/hdfs-m01.keytab&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.secondary.namenode.kerberos.principal&lt;/name&gt;\n    &lt;value&gt;hdfs/spark-m01.casdds.casd@CASDDS.CASD&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.secondary.namenode.keytab.file&lt;/name&gt;\n    &lt;value&gt;/etc/hdfs-m01.keytab&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.permissions.enabled&lt;/name&gt;\n    &lt;value&gt;true&lt;/value&gt;\n  &lt;/property&gt;\n&lt;/configuration&gt;\n&lt;!-- yarn-site.xml --&gt;\n&lt;configuration&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;\n    &lt;value&gt;mapreduce_shuffle&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt;\n    &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;\n    &lt;value&gt;spark-m01.casdds.casd&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.nodemanager.resource.cpu-vcores&lt;/name&gt;\n    &lt;value&gt;2&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt;\n    &lt;value&gt;2048&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.scheduler.maximum-allocation-mb&lt;/name&gt;\n    &lt;value&gt;2048&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.scheduler.minimum-allocation-mb&lt;/name&gt;\n    &lt;value&gt;512&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.resourcemanager.principal&lt;/name&gt;\n    &lt;value&gt;yarn/spark-m01.casdds.casd@CASDDS.CASD&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.resourcemanager.keytab&lt;/name&gt;\n    &lt;value&gt;/etc/yarn-m01.keytab&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.timeline-service.principal&lt;/name&gt;\n    &lt;value&gt;yarn/spark-m01.casdds.casd@CASDDS.CASD&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.timeline-service.keytab&lt;/name&gt;\n    &lt;value&gt;/etc/yarn-m01.keytab&lt;/value&gt;\n  &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre>"},{"location":"hadoop/Integrate_kerberos_in_hadoop_cluster_fr/#632-datanode-core-sitexml-hdfs-sitexml-yarn-sitexml","title":"6.3.2. DataNode (<code>core-site.xml</code>, <code>hdfs-site.xml</code>, <code>yarn-site.xml</code>)","text":"<pre><code>&lt;!-- core-site.xml --&gt;\n&lt;configuration&gt;\n  &lt;property&gt;\n    &lt;name&gt;fs.defaultFS&lt;/name&gt;\n    &lt;value&gt;hdfs://spark-m01.casdds.casd:9000&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;hadoop.security.authentication&lt;/name&gt;\n    &lt;value&gt;kerberos&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;hadoop.security.authorization&lt;/name&gt;\n    &lt;value&gt;true&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;hadoop.ssl.server.conf&lt;/name&gt;\n    &lt;value&gt;ssl-server.xml&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;hadoop.security.auth_to_local&lt;/name&gt;\n    &lt;value&gt;\n      RULE:[2:$1@$0](.*@CASDDS\\.CASD)s/@CASDDS\\.CASD//\n      RULE:[1:$1]\n      DEFAULT\n    &lt;/value&gt;\n    &lt;description&gt;Mapping du principal Kerberos vers l\u2019utilisateur local.&lt;/description&gt;\n  &lt;/property&gt;\n&lt;/configuration&gt;\n&lt;!-- hdfs-site.xml --&gt;\n&lt;configuration&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.https.server.keystore.resource&lt;/name&gt;\n    &lt;value&gt;ssl-server.xml&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.http.policy&lt;/name&gt;\n    &lt;value&gt;HTTPS_ONLY&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.https.port&lt;/name&gt;\n    &lt;value&gt;50470&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.data.transfer.protection&lt;/name&gt;\n    &lt;value&gt;authentication&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.secondary.https.port&lt;/name&gt;\n    &lt;value&gt;50490&lt;/value&gt;\n    &lt;description&gt;Port HTTPS pour le secondary-namenode.&lt;/description&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.https.address&lt;/name&gt;\n    &lt;value&gt;ip-x.x.x.x.casdds.casd:50470&lt;/value&gt;  &lt;!-- @ip namdenode --&gt;\n    &lt;description&gt;Adresse HTTPS d\u2019\u00e9coute du Namenode sur le DataNode.&lt;/description&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.encrypt.data.transfer&lt;/name&gt;\n    &lt;value&gt;true&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.replication&lt;/name&gt;\n    &lt;value&gt;3&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;\n    &lt;value&gt;file:///opt/hadoop/hadoop_tmp/hdfs/data&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;\n    &lt;value&gt;file:///opt/hadoop/hadoop_tmp/hdfs/data&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.datanode.kerberos.principal&lt;/name&gt;\n    &lt;value&gt;hdfs/spark-m0x.casdds.casd@CASDDS.CASD&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.datanode.keytab.file&lt;/name&gt;\n    &lt;value&gt;/etc/hdfs-m0x.keytab&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.namenode.kerberos.principal&lt;/name&gt;\n    &lt;value&gt;hdfs/spark-m01.casdds.casd@CASDDS.CASD&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.namenode.keytab.file&lt;/name&gt;\n    &lt;value&gt;/etc/hdfs-m01.keytab&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.permissions&lt;/name&gt;\n    &lt;value&gt;true&lt;/value&gt;\n    &lt;description&gt;Activation de la v\u00e9rification des permissions sur HDFS.&lt;/description&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.permissions.supergroup&lt;/name&gt;\n    &lt;value&gt;hadoop&lt;/value&gt;\n    &lt;description&gt;Nom du groupe des super-utilisateurs.&lt;/description&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;ipc.server.max.response.size&lt;/name&gt;\n    &lt;value&gt;5242880&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.block.access.token.enable&lt;/name&gt;\n    &lt;value&gt;true&lt;/value&gt;\n    &lt;description&gt;Activation des tokens d\u2019acc\u00e8s pour l\u2019acc\u00e8s aux datanodes.&lt;/description&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.datanode.data.dir.perm&lt;/name&gt;\n    &lt;value&gt;750&lt;/value&gt;\n    &lt;description&gt;Permissions requises sur les r\u00e9pertoires de donn\u00e9es.&lt;/description&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.access.time.precision&lt;/name&gt;\n    &lt;value&gt;0&lt;/value&gt;\n    &lt;description&gt;D\u00e9sactivation de la mise \u00e0 jour des temps d\u2019acc\u00e8s pour les fichiers HDFS.&lt;/description&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;dfs.cluster.administrators&lt;/name&gt;\n    &lt;value&gt;hadoop&lt;/value&gt;\n    &lt;description&gt;ACL pour l\u2019acc\u00e8s aux servlets par d\u00e9faut de HDFS.&lt;/description&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;ipc.server.read.threadpool.size&lt;/name&gt;\n    &lt;value&gt;5&lt;/value&gt;\n  &lt;/property&gt;\n&lt;/configuration&gt;\n&lt;!-- yarn-site.xml --&gt;\n&lt;configuration&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;\n    &lt;value&gt;mapreduce_shuffle&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt;\n    &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.nodemanager.hostname&lt;/name&gt;\n    &lt;value&gt;spark-m0x.casdds.casd&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;\n    &lt;value&gt;spark-m01.casdds.casd&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.nodemanager.resource.cpu-vcores&lt;/name&gt;\n    &lt;value&gt;2&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt;\n    &lt;value&gt;2048&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.scheduler.maximum-allocation-mb&lt;/name&gt;\n    &lt;value&gt;2048&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.scheduler.minimum-allocation-mb&lt;/name&gt;\n    &lt;value&gt;512&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.resourcemanager.principal&lt;/name&gt;\n    &lt;value&gt;yarn/spark-m01.casdds.casd@CASDDS.CASD&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.resourcemanager.keytab&lt;/name&gt;\n    &lt;value&gt;/etc/yarn-m01.keytab&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.timeline-service.principal&lt;/name&gt;\n    &lt;value&gt;yarn/spark-m0x.casdds.casd@CASDDS.CASD&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.timeline-service.keytab&lt;/name&gt;\n    &lt;value&gt;/etc/yarn-m0x.keytab&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.nodemanager.principal&lt;/name&gt;\n    &lt;value&gt;yarn/spark-m0x.casdds.casd@CASDDS.CASD&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.nodemanager.keytab&lt;/name&gt;\n    &lt;value&gt;/etc/yarn-m0x.keytab&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.timeline-service.http-authentication.type&lt;/name&gt;\n    &lt;value&gt;kerberos&lt;/value&gt;\n  &lt;/property&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt;\n    &lt;value&gt;true&lt;/value&gt;\n  &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre>"},{"location":"hadoop/Integrate_kerberos_in_hadoop_cluster_fr/#7-validation-et-tests","title":"7. Validation et tests","text":"<ol> <li>Tester kinit sur chaque n\u0153ud/service</li> <li>D\u00e9marrer Hadoop en mode s\u00e9curis\u00e9 </li> <li>V\u00e9rifier que les services \u00e9coutent en HTTPS et que <code>klist</code> montre les tickets actifs</li> <li>Rafra\u00eechir les mappings utilisateurs-groupes :</li> </ol> <p><code>bash    hdfs dfsadmin -refreshUserToGroupsMappings</code></p>"},{"location":"hadoop/Integrate_kerberos_in_hadoop_cluster_fr/#8-references","title":"8. R\u00e9f\u00e9rences","text":"<ul> <li> <p>https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SecureMode.html</p> </li> <li> <p>http://docs.cloudera.com.s3-website-us-east-1.amazonaws.com/HDPDocuments/HDP3/HDP-3.1.5/security-reference/content/kerberos_nonambari_adding_security_information_to_configuration_files.html</p> </li> </ul>"},{"location":"hadoop/Integrate_kerberos_in_hadoop_cluster_fr/#9-repo-ansible","title":"9. Repo Ansible","text":"<ul> <li>https://github.com/CASD-EU/admin_sys/tree/test/dev/roles</li> </ul>"},{"location":"python/01.Pyenv-offline-config/","title":"Pyenv offline config","text":"<p>Pyenv is a greate tool to install python with internet. In this tutorial, we will show how to set up pyenv for offline usage.</p> <p>The official github page is here: https://github.com/pyenv/pyenv</p>"},{"location":"python/01.Pyenv-offline-config/#1-static-python-source-server","title":"1. Static python source server","text":"<p>Nginx config</p> <pre><code>server {\n  listen        80;\n  server_name   python-src.casd.local;\n  error_log     /var/logs/python-src.error.log;\n\n  location / {\n    autoindex on;\n    root  /data/python;\n  } \n\n}\n</code></pre>"},{"location":"python/01.Pyenv-offline-config/#2-install-pyenv-offline","title":"2. Install pyenv offline","text":"<p>There is an official offline installation script. You can find it here</p> <pre><code>#!/usr/bin/env bash\n\nset -e\n[ -n \"$PYENV_DEBUG\" ] &amp;&amp; set -x\n\nif [ -z \"$PYENV_ROOT\" ]; then\n  if [ -z \"$HOME\" ]; then\n    printf \"$0: %s\\n\" \\\n      \"Either \\$PYENV_ROOT or \\$HOME must be set to determine the install location.\" \\\n      &gt;&amp;2\n    exit 1\n  fi\n  PYENV_ROOT=\"${HOME}/.pyenv\"\nfi\n\ncolorize() {\n  if [ -t 1 ]; then printf \"\\e[%sm%s\\e[m\" \"$1\" \"$2\"\n  else echo -n \"$2\"\n  fi\n}\n\n# Checks for `.pyenv` file, and suggests to remove it for installing\nif [ -d \"${PYENV_ROOT}\" ]; then\n  { echo\n    colorize 1 \"WARNING\"\n    echo \": Can not proceed with installation. Kindly remove '.pyenv' from ${HOME} first.\"\n    echo\n  } &gt;&amp;2\n    exit 1\nfi\n\nconditional_mv() {\n  [ -d \"$2\" ] || mkdir -p \"$2\" &amp;&amp; mv \"$1\"/* \"$2\"\n}\n\nif ! command -v git 1&gt;/dev/null 2&gt;&amp;1; then\n  echo \"pyenv: Git is not installed, can't continue.\" &gt;&amp;2\n  exit 1\nfi\n\n# PYENV_PACKAGE_ARCHIVE is the path of pyenv compressed archive file.\nif [ -z \"$PYENV_PACKAGE_ARCHIVE\" ]; then\n  PYENV_PACKAGE_ARCHIVE=\"$(cd $(dirname \"$0\") &amp;&amp; pwd)/pyenv-package.tar.gz\"\nfi\n\nif [ ! -e \"$PYENV_PACKAGE_ARCHIVE\" ]; then\n  { echo\n    colorize 1 \"ERROR\"\n    echo \": file $PYENV_PACKAGE_ARCHIVE not exists.\"\n    echo\n  } &gt;&amp;2\n  exit 1\nfi\n\n# Decompress archive.\nTMP_DIR=$(mktemp -d)\n\ntar -xf \"$PYENV_PACKAGE_ARCHIVE\" -C \"$TMP_DIR\"\n\nconditional_mv \"$TMP_DIR/pyenv\"            \"${PYENV_ROOT}\"\nconditional_mv \"$TMP_DIR/pyenv-doctor\"     \"${PYENV_ROOT}/plugins/pyenv-doctor\"\nconditional_mv \"$TMP_DIR/pyenv-update\"     \"${PYENV_ROOT}/plugins/pyenv-update\"\nconditional_mv \"$TMP_DIR/pyenv-virtualenv\" \"${PYENV_ROOT}/plugins/pyenv-virtualenv\"\n\nrm -rf $TMP_DIR\n\n\nif ! command -v pyenv 1&gt;/dev/null; then\n  { echo\n    colorize 1 \"WARNING\"\n    echo \": seems you still have not added 'pyenv' to the load path.\"\n    echo\n  } &gt;&amp;2\n\n  { # Without args, `init` commands print installation help\n    \"${PYENV_ROOT}/bin/pyenv\" init || true\n    \"${PYENV_ROOT}/bin/pyenv\" virtualenv-init || true\n  } &gt;&amp;2\nfi\n</code></pre>"},{"location":"python/01.Pyenv-offline-config/#21-add-pyenv-to-your-bashrc","title":"2.1 Add pyenv to your bashrc","text":"<p>To add pyenv to your PATH, you need to add the following lines into your <code>.bashrc</code> or <code>.profile</code> </p> <pre><code>export PYENV_ROOT=\"$HOME/.pyenv\"\n[[ -d $PYENV_ROOT/bin ]] &amp;&amp; export PATH=\"$PYENV_ROOT/bin:$PATH\"\neval \"$(pyenv init -)\"\n\n# after adding the lines, you need to reload the bashrc file\n\nsource ~/.bashrc\n</code></pre>"},{"location":"python/01.Pyenv-offline-config/#22-remove-pyenv","title":"2.2 Remove pyenv","text":"<pre><code># remove the pyenv source\nrm -rf ~/.pyenv/\n\n# Remove pyenv initialization lines from your shell configuration file (.bashrc, .zshrc, etc.).\nexport PYENV_ROOT=\"$HOME/.pyenv\"\n[[ -d $PYENV_ROOT/bin ]] &amp;&amp; export PATH=\"$PYENV_ROOT/bin:$PATH\"\neval \"$(pyenv init -)\"\n\n# Reload the shell.\nsource ~/.bashrc\n\n# remove the python build dependencies if you no longer need them\nsudo yum remove gcc zlib-devel bzip2-devel readline-devel sqlite-devel openssl-devel\n</code></pre>"},{"location":"python/01.Pyenv-offline-config/#3-use-pyenv-to-install-python","title":"3. Use pyenv to install python","text":"<p>Once the pyenv is installed, you can check which python version is available for installation.</p> <pre><code># this will show the full list\npyenv install --list\n</code></pre> <p>The configuration of these python source is under {pyenv-root}/.pyenv/plugins/python-build/share/python-build</p> <p>For example, for python 3.12.7, you have the following config file</p> <pre><code>prefer_openssl3\nexport PYTHON_BUILD_CONFIGURE_WITH_OPENSSL=1\ninstall_package \"openssl-3.3.2\" \"https://github.com/openssl/openssl/releases/download/openssl-3.3.2/openssl-3.3.2.tar.gz#2e8a40b01979afe8be0bbfb3de5dc1c6709fedb46d6c89c10da114ab5fc3d281\" mac_openssl --if has_broken_mac_openssl\ninstall_package \"readline-8.2\" \"https://ftpmirror.gnu.org/readline/readline-8.2.tar.gz#3feb7171f16a84ee82ca18a36d7b9be109a52c04f492a053331d7d1095007c35\" mac_readline --if has_broken_mac_readline\nif has_tar_xz_support; then\n    install_package \"Python-3.12.7\" \"https://www.python.org/ftp/python/3.12.7/Python-3.12.7.tar.xz#24887b92e2afd4a2ac602419ad4b596372f67ac9b077190f459aba390faf5550\" standard verify_py312 copy_python_gdb ensurepip\nelse\n    install_package \"Python-3.12.7\" \"https://www.python.org/ftp/python/3.12.7/Python-3.12.7.tgz#73ac8fe780227bf371add8373c3079f42a0dc62deff8d612cd15a618082ab623\" standard verify_py312 copy_python_gdb ensurepip\nfi\n</code></pre> <p>You can notice the script downloads the source from <code>www.python.org</code>, and compile it locally. </p> <p>If you want to change the source, you need to modify this config file. Below is an example.</p> <p>Here we suppose that we have a private python source server under <code>python-src.casd.local</code>.</p> <pre><code>install_package \"Python-3.12.7\" \"http://python-src.casd.local/Python-3.12.7.tgz#73ac8fe780227bf371add8373c3079f42a0dc62deff8d612cd15a618082ab623\" standard verify_py312 copy_python_gdb ensurepip\n</code></pre> <p>The number after # in <code>Python-3.12.7.tgz#73ac8fe780227bf371add8373c3079f42a0dc62deff8d612cd15a618082ab623</code> is the checksum value of the python source with <code>SHA256</code>. You can find the corresponding value in this page</p> <p>Below is an extraction of the origin json file</p> <pre><code>\"SPDXID\": \"SPDXRef-PACKAGE-cpython\",\n      \"checksums\": [\n        {\n          \"algorithm\": \"SHA256\",\n          \"checksumValue\": \"73ac8fe780227bf371add8373c3079f42a0dc62deff8d612cd15a618082ab623\"\n        }\n      ],\n      \"downloadLocation\": \"https://www.python.org/ftp/python/3.12.7/Python-3.12.7.tgz\",\n</code></pre>"},{"location":"python/01.Pyenv-offline-config/#31-add-new-python-version","title":"3.1 Add new python version","text":"<p>There are two steps: 1. Download the python source file in the <code>python-src.casd.local</code> server 2. Update the pyenv available python build list.</p>"},{"location":"python/01.Pyenv-offline-config/#311-download-the-source","title":"3.1.1 Download the source","text":"<p>You can find all the official release here</p> <p>In our current setup. The server <code>python-src.casd.local</code> is located at <code>10.50.5.65</code>. </p> <p>The source is located at <code>/data/python</code>. And the <code>/data</code> is a mounted disk which is not in <code>fstab</code>. Need to mount after restart</p>"},{"location":"python/01.Pyenv-offline-config/#312-update-the-pyenv-python-build-list","title":"3.1.2 Update the pyenv python build list","text":"<p>All the available build configuration file are located at {pyenv-root}/.pyenv/plugins/python-build/share/python-build</p> <p>The easiest way to add new source is to modify the origin pyenv conf, just change the official python source url to your  private python source url.</p> <p>If the python version is new, and the pyenv does not have an origin config file. You can use the below template to add a new version</p> <pre><code>install_package \"Python-3.x.y\" \"http://python-src.casd.local/Python-3.x.y.tgz#&lt;checksum of Python-3.x.y&gt;\" standard verify_py3x copy_python_gdb ensurepip\n</code></pre> <p>To get the check sum, you can goto the spdx page https://www.python.org/ftp/python/3.x.y/Python-3.x.y.tgz.spdx.json</p> <p>Then search text such as <code>https://www.python.org/ftp/python/3.x.y/Python-3.x.y.tgz</code></p> <p>For example, for <code>3.13.0</code>, when you search <code>https://www.python.org/ftp/python/3.13.0/Python-3.13.0.tgz</code>, you should find the below lines. Take the checksum and put it behind the <code>#</code></p> <pre><code>\"SPDXID\": \"SPDXRef-PACKAGE-cpython\",\n      \"checksums\": [\n        {\n          \"algorithm\": \"SHA256\",\n          \"checksumValue\": \"12445c7b3db3126c41190bfdc1c8239c39c719404e844babbd015a1bc3fafcd4\"\n        }\n      ],\n      \"downloadLocation\": \"https://www.python.org/ftp/python/3.13.0/Python-3.13.0.tgz\",\n</code></pre>"},{"location":"python/01.Pyenv-offline-config/#32-missing-system-dependencies","title":"3.2 Missing system dependencies","text":"<p>As we mentioned before, the source will be compiled locally, so it requires some system dependencies </p> <pre><code>sudo apt install libsqlite3-dev\nsudo apt-get install libffi-dev\nsudo apt-get build-dep python-tk\n</code></pre>"},{"location":"python/02.Use_bandersnatch_to_build_private_pypi_repo/","title":"Use Bandersnatch to build a private pypi repository","text":"<p>Bandersnatch is a PyPI mirror client according to <code>PEP 381 + PEP 503 + PEP 691</code>. - PEP 381: Mirroring infrastructure for PyPI - PEP 691: JSON-based Simple API for Python Package Indexes Version features:   * bandersnatch &gt;=6.0 implements PEP691   * bandersnatch &gt;=4.0 supports Linux, MacOSX + Windows</p> <p>In this tutorial, we will use bandersnatch to mirror some python packages and server them as a <code>private pypi server</code>. The official GitHub repo of bandersnatch. The official doc is here</p>"},{"location":"python/02.Use_bandersnatch_to_build_private_pypi_repo/#1-install-bandersnatch","title":"1. Install bandersnatch","text":"<p>It's recommended to install bandersnatch on a virtual env with a reserved uid</p>"},{"location":"python/02.Use_bandersnatch_to_build_private_pypi_repo/#11-prepare-a-python-venv","title":"1.1 Prepare a Python venv","text":"<p>To Run below command, the user need to have sudoer right</p> <pre><code>sudo apt update\n\n# install python interpreter\nsudo apt-get install python3 -y\n\n# install pip\nsudo apt-get install python3-pip\n\n# install venv\nsudo apt-get install python3-venv\n\n# create a user bandersnatch\nsudo useradd -m bandersnatch -s /bin/bash\n\n# change current user to bandersnatch\nsudo su bandersnatch\n\n# go to the folder which you want to create the venv.\n# in this tutorial we choose ~/pypi/venv, to combine with our cron job script\nsudo mkdir -p ~/pypi/venv\n\n# change owner if you need, but optional\nsudo chown -R bandersnatch:root ~/pypi/venv\n\n# goto the venv folder\ncd ~/pypi/venv\n\n# create  a virtual env called bandersnatch\n# don't use sudo here\npython3 -m venv bandersnatch\n\n# test the virtual env\n# activate the venv\nsource bandersnatch/bin/activate\n\n# to exit the venv, just type \ndeactivate\n</code></pre>"},{"location":"python/02.Use_bandersnatch_to_build_private_pypi_repo/#12-install-the-package","title":"1.2  Install the package","text":"<pre><code># install the package\npip install bandersnatch\n\n# test the package\nbandersnatch --help\n</code></pre>"},{"location":"python/02.Use_bandersnatch_to_build_private_pypi_repo/#2-configure-bandersnatch","title":"2. Configure bandersnatch","text":"<p>When we run the command <code>bandersnatch mirror</code>, it will call a conf file that controls the mirror's behavior. By default, this file is located at /etc/bandersnatch.conf. And the default user may not have the right to create or edit this file.</p> <p>To avoid the access rights problem, we recommend you use the below config file path to host the config</p> <p>To run the below commands, we suppose your uid is bandersnatch</p> <pre><code># create a folder to host bandersnatch conf\nmkdir -p ~/pypi/conf\n\n# create a folder to host the mirrored packages\nmkdir -p ~/pypi/data\n\n# create a folder to host the log\nmkdir -p ~/pypi/log\n\n# create a folder to host the releases\nmkdir -p ~/pypi/export\n\n# create the config file\nvim ~/pypi/conf/bandersnatch.conf\n</code></pre> <p>Run <code>bandersnatch mirror</code> for the first time - it will create an empty configuration file for you in /etc/bandersnatch.conf. If you add some packages in it and run second time, It will populate your mirror with the current status of all PyPI packages. It takes many disk storage and long time to finish if you take all pypi packages. </p> <p>This page https://pypi.org/stats/ will give you an idea how much storage you need to complete the mirror. For mirror the top 100 projects, it requires 23.6TB.</p> <p>Now, put the below config file content in it.</p> <p>The default location should be <code>/etc/bandersnatch.conf</code>. But you can put this config file where you like. For example, in this tutorial, I put it in here <code>/home/bandersnatch/pypi/conf/bandersnatch.conf</code></p> <pre><code>[mirror]\njson = true\ndirectory = /home/bandersnatch/pypi/data\nmaster = https://pypi.org\nworkers = 4\ntimeout = 40\nstop-on-error= false\nhash-index = false\n\n[plugins]\nenabled =\n  exclude_platform\n  allowlist_project\n  allowlist_release\n\n[allowlist]\npackages =\n    pip\n    pandas\n    folium\n\n[blocklist]\nplatforms =\n     macos\n     freebsd\n     py2.4\n     py2.5\n     py2.6\n     py2.7\n</code></pre> <p>You will notice if you only mirror the above packages, you can not do the pip install correctly. Because packages also has dependencies. For example pandas require numpy to work, if you have pandas, but not numpy, pip install will fail. So you need to sync all the dependent packages of the required packages. To determine the complete package list is another challenge which we will address in another doc.</p> <p>Now we can start the mirroring of the packages</p> <pre><code># don't forget to activate the virtual env which contains the bandersnatch binary\n\n# in our case, we provide the path of the config file \nbandersnatch -c /home/bandersnatch/pypi/conf/bandersnatch.conf mirror\n</code></pre> <p>After running the above command, you will notice bandersnatch start to download the packages. It will create a  subdirectory under <code>/home/bandersnatch/pypi/data</code> called <code>web/</code>.  </p>"},{"location":"python/02.Use_bandersnatch_to_build_private_pypi_repo/#3-serve-the-package-as-a-web-server","title":"3. Serve the package as a web server","text":"<p>After the <code>bandersnatch mirror</code> command finished, you should see the following file and directory generated in the target folder which are defined in the <code>bandersnatch.conf</code>(directory = /home/bandersnatch/pypi/data).  - generation (file) - status (file) - web (directory which contains all the packages and index)</p> <p>All the packages are located in the <code>web</code> folder.</p> <p>To server the packages, we need to set up a web server. The configuration of the web server must respect <code>PEP691 support</code>. In this tutorial, we only show a nginx config example. Below is an example of the config. Here we suppose that pypi.casd.local is the server url.</p> <p>```nginx configuration server {     listen 80;     server_name pypi.casd.local;</p> <pre><code># redirect http request to https\nreturn 301 https://$host$request_uri;\n\n}\n</code></pre> <p>server {     listen 443 ssl;     server_name pypi.casd.local;     ssl_certificate /etc/ssl/certs/casd_k8s_wildcard.pem;     ssl_certificate_key /etc/ssl/private/wildcard_key.pem;</p> <pre><code>root /data/pypi/data/web;\nautoindex off;\ncharset utf-8;\nautoindex_exact_size off;\n\nlocation / {\n    try_files $uri $uri/ =404;\n}\n\nlocation /simple {\n    # Required for simple index files (like /simple/package-name)\n    try_files $uri $uri/ =404;\n}\n\n# Add caching headers (optional, helps with performance)\nlocation ~* \\.(whl|tar\\.gz|zip)$ {\n    expires 30d;\n    add_header Cache-Control \"public\";\n}\n\n# Enable gzip compression for faster responses\ngzip on;\ngzip_types text/plain application/xml application/json;\ngzip_proxied any;\n\n# Logging (optional)\naccess_log /var/log/nginx/pypi_access.log;\nerror_log /var/log/nginx/pypi_error.log;\n</code></pre> <p>}</p> <pre><code>Note that it is a good idea to have your webserver publish the HTML index files correctly with `UTF-8` as the charset. \nThe index pages will work without it but if humans look at the pages the characters will end up looking funny.\n\nMake sure that the webserver uses UTF-8 to look up Unicode path names. `nginx gets this right by default - not sure about others`.\n\n\n&gt; By default, pip only accept URL with **https**,  if your URL is in HTTP, you will have many problems. \n&gt; So we highly recommend you to add a certificate to your nginx config\n\n## 4. Test the Bandersnatch installation\n\n```shell\ncurl https://pypi.casd.local/simple\n</code></pre> <p>If you see the responce, then the server is up and running</p>"},{"location":"python/02.Use_bandersnatch_to_build_private_pypi_repo/#5-configure-pip-to-use-the-private-repo","title":"5 Configure pip to use the private repo","text":"<p>pip uses a conf file to list all the hosts which it can download the packages, if your private repo is not in this list pip will consider it as dangerous.</p> <p>The configuration of pip is different based on the pip version and OS.</p>"},{"location":"python/02.Use_bandersnatch_to_build_private_pypi_repo/#51-temporary-config","title":"5.1 Temporary Config","text":"<p>To test your pypi server, you can use the below command </p> <pre><code># general form, --index-url specifies where to lookup packages index\n# trusted-host: Marks your custom mirror as trusted. If your pypi server runs on http or the certificate is self-signed. It's mandatory to have this\npip install &lt;package-name&gt; --index-url &lt;repo-url&gt; --trusted-host &lt;repo-domain&gt;\n\n# for example, if the repo domain is pypi.casd.local and the repo URL is https://pypi.casd.local/simple\npip install pandas --index-url https://pypi.casd.local/simple --trusted-host pypi.casd.local\npip install ipykernel --index-url https://pypi.casd.local/simple --trusted-host pypi.casd.local\n</code></pre>"},{"location":"python/02.Use_bandersnatch_to_build_private_pypi_repo/#52-permanent-config","title":"5.2 Permanent Config","text":"<p>You can find the official pip config documentation here</p>"},{"location":"python/02.Use_bandersnatch_to_build_private_pypi_repo/#521-use-the-pipconf-recommended","title":"5.2.1 Use the pip.conf (Recommended)","text":"<p>pip has 3 \u201clevels\u201d of configuration files:</p> <ul> <li><code>global</code>: system-wide configuration file, shared across users. The path is <code>/etc/pip.conf</code></li> <li><code>user</code>: per-user configuration file. </li> <li><code>site</code>: per-environment configuration file; i.e. per-virtualenv.</li> </ul> <p>Below is an example of pip.conf. You need to place it in different path based on your requirements(e.g. global, user,)</p> <pre><code>[global]\ntimeout = 60\nindex-url = https://pypi.casd.local/simple\ntrusted-host = pypi.casd.local\n</code></pre>"},{"location":"python/02.Use_bandersnatch_to_build_private_pypi_repo/#5211-linux-config","title":"5.2.1.1 Linux config","text":"<p>The path of the pip config file in linux os:  - <code>global</code>: <code>/etc/pip.conf</code>  - <code>user</code>: <code>$HOME/.config/pip/pip.conf</code>  - <code>site</code>: <code>path/to/venv/pip.conf</code></p>"},{"location":"python/02.Use_bandersnatch_to_build_private_pypi_repo/#5212-windows-path","title":"5.2.1.2 windows path","text":"<p>The path of the pip config file in Windows os:  - <code>global</code>: <code>C:\\ProgramData\\pip\\pip.ini</code> (win7 and later, hidden but writeable)  - <code>user</code>: <code>%APPDATA%\\pip\\pip.ini</code>  - <code>site</code>: <code>%VIRTUAL_ENV%\\pip.ini</code></p>"},{"location":"python/02.Use_bandersnatch_to_build_private_pypi_repo/#522-use-the-pip-cli","title":"5.2.2 Use the pip CLI","text":"<p><code>pip</code> provides command line client which allows you to config pip. Base on the <code>pip</code> version, the command is a little different.</p>"},{"location":"python/02.Use_bandersnatch_to_build_private_pypi_repo/#5221-for-pip-100","title":"5.2.2.1  For pip &gt;= 10.0","text":"<pre><code># set the index server url\npip config set global.index-url http://pypi.casd.local/simple \n\n# If the server is in HTTP, you need to add the below line to force pip to accept the domain\npip config set global.trusted-host pypi.casd.local\n</code></pre>"},{"location":"python/02.Use_bandersnatch_to_build_private_pypi_repo/#5222-for-older-version","title":"5.2.2.2 For older version","text":"<pre><code>pip install --upgrade pip --index-url http://pypi.casd.local/simple --trusted-host pypi.casd.local\n</code></pre>"},{"location":"python/02.Use_bandersnatch_to_build_private_pypi_repo/#523-use-the-env-var","title":"5.2.3 Use the env var","text":"<p>For bash:</p> <pre><code>export PIP_INDEX_URL=http://pypi.yourdomain.com/simple\nexport PIP_TRUSTED_HOST=pypi.yourdomain.com\n</code></pre> <p>For cmd windows:</p> <pre><code>set PIP_INDEX_URL=http://pypi.yourdomain.com/simple\nset PIP_TRUSTED_HOST=pypi.yourdomain.com\n</code></pre> <p>For powershell windows:</p> <pre><code>$env:PIP_INDEX_URL = \"http://pypi.yourdomain.com/simple\"\n$env:PIP_TRUSTED_HOST = \"pypi.yourdomain.com\"\n</code></pre>"},{"location":"python/02.Use_bandersnatch_to_build_private_pypi_repo/#53-test-your-pip-config","title":"5.3 Test your pip config","text":"<p>After the configuration, you can check if your pip configuration</p> <pre><code># show all pip config\npip config list\n</code></pre> <p>note the pip config may be different from one venv to another.  the best practice is to activate the venv then check the pip config</p>"},{"location":"python/02.Use_bandersnatch_to_build_private_pypi_repo/#54-for-conda-virtual-env","title":"5.4 For conda virtual env","text":"<p>As conda also uses pip to install python packages, you can use the above pip config. </p> <p>To locate where is the conda env, you can use the below command</p> <pre><code># step 1: find the virtual env root path\nconda info --envs\n## You should see below output\n# conda environments:\n#\nbase                  *  /home/pengfei/anaconda3\nPyQT-CRUD-App            /home/pengfei/anaconda3/envs/PyQT-CRUD-App\n\n# step 2: create the pip.conf file\nvim /home/pengfei/anaconda3/envs/PyQT-CRUD-App/pip.conf\n\n# step3: add content to pip.conf\n[global]\nindex-url = https://pengfei.org/simple\ntrusted-host = pengfei.org\n\n# step4: check the conf\nconda activate PyQT-CRUD-App\n\npip config list\n# you should see below output\nglobal.index-url='https://pengfei.org/simple'\nglobal.trusted-host='pengfei.org'\n</code></pre>"},{"location":"python/02.Use_bandersnatch_to_build_private_pypi_repo/#6-troubles-in-bandersnatch","title":"6. Troubles in bandersnatch","text":""},{"location":"python/02.Use_bandersnatch_to_build_private_pypi_repo/#61-mirrored-files","title":"6.1 mirrored-files","text":"<p>Each time when you run bandersnatch mirror command, it will create a file called mirrored-files in the current directory.</p> <p>If you changed directory and run bandersnatch mirror command again, it will not be able to locate previous mirrored-files.  And it will not start the mirror process. As a result, no change will make.</p> <p>You can use the command bandersnatch mirror --force-check to overcome this. But sometimes, it does not work,  you need to remove the wrongly generated mirrored-files file, then rerun bandersnatch mirror --force-check</p>"},{"location":"python/02.Use_bandersnatch_to_build_private_pypi_repo/#62-no-auto-dependencies-checks","title":"6.2 No auto dependencies checks","text":"<p>There is no automatic dependencies checks. For example in the allow_list, if I put pandas, bandersnatch  will only mirror the package source or wheel file of pandas. All the pandas dependencies (e.g. python-dateutil, numpy, six)  will not be mirrored. When you installed, pip will show the error that it can find numpy, etc.</p> <p>So we need to determine the dependencies manually and add all dependencies to the allow_list.  </p> <p>The maintainer of the bandersnatch said, this will not be fixed. https://github.com/pypa/bandersnatch/issues/1472</p>"},{"location":"security/kerberos/01.Introduction/","title":"Introduction of Kerberos server","text":"<p>Kerberos is a secure authentication protocol that enables users and services to <code>authenticate without transmitting  passwords</code> over the network. It is built around a <code>trusted third-party authentication system</code>, using  <code>tickets and encryption keys</code> to ensure authentication.</p> <p>The Kerberos server knows \"secrets\" (encrypted passwords) for all clients and servers under its control.  These \"secrets\" are used to encrypt all the messages exchanged during authentication.</p>"},{"location":"security/kerberos/01.Introduction/#1-key-components-and-terms-of-kerberos","title":"1. Key components and terms of Kerberos","text":"<p>Below is a list of important components and terms of Kerberos: - Key Distribution Center(KDC): is responsible for checking user credentials and issuing Tickets - Realm: defines a administrative domain to restrict a security scope. It includes a <code>KDC</code> and a <code>list of Clients(e.g. users, hosts, services)</code> - Principal: is a unique identity in the Kerberos system, which can be a <code>user, host, or service</code>. - Ticket: a credential issued by KDC. - Keytab: A file that includes one or more principals and their keys.   </p>"},{"location":"security/kerberos/01.Introduction/#11-key-distribution-centerkdc","title":"1.1 Key Distribution Center(KDC)","text":"<p>Key Distribution Center, or KDC is the heart of the Kerberos authentication system. At a high level, it has three parts:</p> <ul> <li>A database: of the users, hosts and services (known as principals) that it knows about and their respective Kerberos passwords </li> <li>An authentication server (AS): which performs the initial authentication and issues a Ticket Granting Ticket (TGT)</li> <li>A Ticket Granting Server (TGS): that issues <code>subsequent service tickets</code> based on the initial TGT for <code>accessing specific hosts or services</code></li> </ul> <p>The KDC is typically hosted on a <code>Domain Controller (DC) in Active Directory (AD)</code> or a <code>Kerberos server</code> in <code>MIT/Heimdal implementations</code>.</p>"},{"location":"security/kerberos/01.Introduction/#12-realm","title":"1.2 Realm","text":"<p>A Kerberos realm defines the administrative domain. It includes a <code>KDC</code> and a <code>list of Clients(e.g. users, hosts, services)</code> The <code>realm name</code> usually matches the <code>organization\u2019s domain name, written in uppercase</code>. For example, if the organization domain name is <code>casd.eu</code>, the realm name should be <code>CASD.EU</code>.</p> <p>A realm can trust another realm (cross-realm authentication) for authentication across different domains.</p>"},{"location":"security/kerberos/01.Introduction/#13-principal","title":"1.3 Principal","text":"<p>A Principal is a unique identity in the Kerberos system, which can be:</p> <ul> <li>a user (e.g., user@CASD.EU).</li> <li>a host (e.g., host/server01.casd.eu@CASD.EU).</li> <li>a service (e.g., hdfs/namenode.casd.eu@CASD.EU).</li> </ul> <p>We must distinguish the difference between an account in AD/Ldap and a principal in Kerberos. An account in AD can be associated with multiple principals in Kerberos.</p>"},{"location":"security/kerberos/01.Introduction/#131-naming-convention-of-the-principal","title":"1.3.1 Naming convention of the principal","text":"<p>In theory, A principal in Kerberos 5 is of the following type: <code>component1/component2/.../componentN@REALM</code></p> <p>But, in practice a <code>maximum of two components</code> are used. So we recommend the below naming convention for principals.</p> <p>Principal for users, we use the uid of the user and roles of the user to build the principal. In below example, user1 has two principals, <code>user1@CASD.EU</code> has normal privileges, <code>user1/admin@CASD.EU</code> has admin privileges</p> <pre><code># general form for user principal\n&lt;uid&gt;/&lt;role&gt;@REALM\n\n# examples\nuser1@CASD.EU\nuser1/admin@CASD.EU\n</code></pre> <p>Principal for hosts(servers), we use the keyword <code>host</code> to indicate this principal provides a special service which give generic access to the machine (e.g. telnet, rsh, ssh). The second component is the <code>complete hostname (FQDN)</code>  of the machine.</p> <pre><code># general form for host principal, \nhost/&lt;host-fqdn&gt;@REALM\n\n# examples\nhost/server.casd.eu@CASD.EU\n</code></pre> <p>It is important that the <code>host-fqdn</code> exactly matches (in lower case letters) the DNS reverse resolution  of the application server's IP address</p> <pre><code># general form for service principal\n&lt;service-name&gt;/&lt;host-fqdn&gt;@REALM\n\n# examples\nimap/mbox.casd.eu@CASD.EU\nyarn/deb11_h01.casd.eu@CASD.EU\n</code></pre>"},{"location":"security/kerberos/01.Introduction/#14-ticket","title":"1.4 Ticket","text":"<p>A <code>kerberos ticket</code> is something a client presents to an application server to demonstrate the authenticity of its identity.  Tickets are issued by the <code>authentication server</code> and are encrypted using the secret key of the service they are  intended for. Since this key is a secret shared only between the <code>authentication server</code> and the <code>server providing  the service</code>, not even the client which requested the ticket can know it or change its contents.  The main information contained in a ticket includes:  - The requesting user's principal (generally the username);   - The principal of the service it is intended for;   - The IP address of the client machine from which the ticket can be used. In Kerberos 5 this field is optional and may       also be multiple to be able to run clients under NAT or multi-home.   - The date and time (in timestamp format) when the tickets validity commences;   - The ticket's maximum lifetime   - The session key (this has a fundamental role which is described below);</p>"},{"location":"security/kerberos/01.Introduction/#141-tickets-maximum-lifetime","title":"1.4.1 Ticket's maximum lifetime","text":"<p>Each ticket has an expiration (generally 10 hours). This is essential since the authentication server no longer  has any control over an already issued ticket. Even though the realm administrator can prevent the issuing of  new tickets for a certain user at any time, it cannot prevent users from using the tickets they already possess.  This is the reason for limiting the lifetime of the tickets to limit any abuse over time.</p>"},{"location":"security/kerberos/01.Introduction/#142-ticket-granting-tickettgt-vs-service-ticketst","title":"1.4.2 Ticket Granting Ticket(TGT) VS Service Ticket(ST)","text":"<p>Kerberos provides two types of tickets: - Ticket Granting Ticket(TGT): A ticket that proves the user identity to request other tickets; issued once per login session. - Service Ticket(ST): A ticket that grants access to a specific service; issued per service request.</p> <p>A <code>user principal</code> requests authentication from the <code>AS</code>. The AS returns a <code>TGT</code> that is <code>encrypted using the user  principal's Kerberos password</code>, which is known only to the user principal and the AS. The user principal decrypts the  TGT locally using its Kerberos password, and from that point forward, until the ticket expires, the user principal can  use the TGT to get <code>service tickets(ST)</code> from the <code>TGS</code>. </p>"},{"location":"security/kerberos/01.Introduction/#ticket-granting-ticket-tgt","title":"Ticket Granting Ticket (TGT)","text":"<ul> <li>Issued by the Authentication Service (AS) after a successful login.</li> <li>Encrypted with the user\u2019s password.</li> <li>Allows the user to request service tickets without entering credentials again.</li> <li>Has a validity period (e.g., 10 hours) and may be renewable.</li> </ul>"},{"location":"security/kerberos/01.Introduction/#service-ticket-st","title":"Service Ticket (ST)","text":"<ul> <li>Issued by the Ticket Granting Service (TGS) upon request.</li> <li>Allows access to a specific service (e.g., HDFS, Spark, SSH).</li> <li>Each service requires its own ticket.</li> <li>In general, the validity period of ST should be less than TGT </li> </ul>"},{"location":"security/kerberos/01.Introduction/#difference-between-a-ticket-granting-ticket-tgt-and-a-service-ticket-st","title":"Difference Between a Ticket Granting Ticket (TGT) and a Service Ticket (ST)","text":"Feature Ticket Granting Ticket (TGT) Service Ticket (ST) Purpose Proves the user\u2019s identity and allows them to request service tickets Grants access to a specific service (e.g., HDFS, Spark, SSH) Issued By Authentication Service (AS) within the KDC Ticket Granting Service (TGS) within the KDC Used For Requesting service tickets (STs) from the KDC Accessing a specific service Validity Period Typically valid for several hours (e.g., 10 hours) Shorter lifespan (usually same as or shorter than TGT) Encrypted With KDC\u2019s secret key Service\u2019s secret key Stored In User\u2019s credential cache (klist command shows it) Also stored in the credential cache but used for service authentication Authentication Flow First step in Kerberos authentication Second step after obtaining a TGT <p>Below is an example of viewing tickets in linux</p> <pre><code># example of viewing TGT and ST\nklist\n\n# example output\nTicket cache: FILE:/tmp/krb5cc_1000\nDefault principal: user@CASD.EU\n\nValid starting     Expires            Service principal\n03/25/25 12:00:00  03/25/25 22:00:00  krbtgt/CASD.EU@CASD.EU  (TGT)\n03/25/25 12:05:00  03/25/25 22:00:00  hdfs/namenode.casd.eu@CASD.EU (Service Ticket)\n</code></pre> <p>By default, in linux all krb tickets of a user are stored in a file /tmp/krb5cc_1000, where 1000 is the uid number  of the user.</p> <p>Below is an example of viewing tickets in windows</p> <pre><code># example of viewing TGT and ST\nklist\n\n# example output\nCredential cache: C:\\Users\\user\\krb5cc_user\nDefault principal: user@CASD.EU\n\nValid starting     Expires            Service principal\n03/25/25 12:00:00  03/25/25 22:00:00  krbtgt/CASD.EU@CASD.EU  (TGT)\n03/25/25 12:05:00  03/25/25 22:00:00  hdfs/namenode.casd.eu@CASD.EU (Service Ticket)\n</code></pre> <p>By default, in windows, all krb tickets of a user are stored in a file C:\\Users\\user\\krb5cc_user. </p> <ul> <li>The user principal is <code>user@CASD.EU</code></li> <li>The first ticket with service principal <code>(krbtgt/CASD.EU@CASD.EU)</code> is the TGT. </li> <li>The second ticket with service principal <code>(hdfs/namenode.casd.eu@CASD.EU)</code> is the Service Ticket for accessing HDFS.</li> </ul>"},{"location":"security/kerberos/01.Introduction/#15-keytab","title":"1.5 Keytab","text":"<p>A <code>.keytab</code> file stores the <code>encrypted credentials</code> for <code>non-interactive authentication</code>.</p> <p>It's often used by services and automated scripts to authenticate to Kerberos and request a ticket without user intervention.</p> <p>A <code>.keytab</code> file can contain <code>one or more encryption keys</code> linked to a Kerberos principal. </p>"},{"location":"security/kerberos/01.Introduction/#16-encryption-algos-and-keys","title":"1.6 Encryption algos and keys","text":"<p>As we explained before, Kerberos uses <code>symmetric encryption algorithms</code> to secure authentication (e.g. tickets and keytabs). It supports many algorithms to fits different hardware and OS requirements. Below are some supported algo - AES256-CTS-HMAC-SHA1-96 (Strongest, preferred) - AES128-CTS-HMAC-SHA1-96 - RC4-HMAC (Weaker, legacy)</p> <pre><code># to check the encryption algo of a ticket, you can use -e option\nklist -e \n</code></pre> <p>The algo <code>AES256-CTS-HMAC-SHA1-96</code> can be break down into three parts: - AES256: symmetric encryption algorithm which encrypts the shared secrets between user and KDC - CTS(Ciphertext Stealing): helps encrypt data of any size without an anomaly. Because encryption works on fixed blocks of data (e.g., 16 bytes at a time) - HMAC-SHA1-96: ensures the integrity of the ticket or credentials in the keytab file. HMAC (Hash-Based Message Authentication Code)</p>"},{"location":"security/kerberos/01.Introduction/#17-summary","title":"1.7 Summary","text":"<p>Below is a summary of import terms in Kerberos</p> Term Description Key Distribution Center(KDC) checking user credentials and issuing Tickets Realm The administrative domain that includes a KDC and a number of Clients. Principal The unique name of a user or service that authenticates against the KDC Ticket Granting Ticket(TGT) A ticket that proves the user identity to request other tickets Service Ticket(ST) A ticket that grants access to a specific service Keytab A file that includes one or more principals and their associated keys."},{"location":"security/kerberos/01.Introduction/#2-introduction-to-kerberos-authentication-protocol","title":"2. Introduction to Kerberos Authentication protocol","text":"<p>Kerberos is a network authentication protocol. It is designed to provide strong authentication for client/server  applications by using secret-key cryptography. It has the following characteristics:</p> <ul> <li> <p>It is secure: it never sends a password unless it is encrypted.</p> </li> <li> <p>Only a single login is required per session. Credentials defined at login are then passed between resources without the need for additional logins.</p> </li> <li> <p>The concept depends on a trusted third party  a Key Distribution Center (KDC). The KDC is aware of all systems in the network and is trusted by all of them.</p> </li> <li> <p>It performs mutual authentication, where a client proves its identity to a server, and a server proves its identity to the client.</p> </li> </ul> <p>Kerberos introduces the concept of a Ticket-Granting Server (TGS). A client that wishes to use a service has to  receive a ticket a time-limited cryptographic message giving it access to the server.  Kerberos also requires an Authentication Server (AS) to verify clients. The two servers combined make up a KDC. </p> <p>The following figure shows the sequence of events required for a client to gain access to a service using Kerberos  authentication. Each step is shown with the Kerberos message associated with it, as defined in RFC  4120 \u201cThe Kerberos Network Authorization Service (V5)\u201d.</p> <p></p> <ul> <li> <p>Step 1: The user logs on to the workstation and requests service on the host. The workstation sends a message to            the Authorization Server requesting a <code>ticket granting ticket (TGT)</code>.</p> </li> <li> <p>Step 2: The Authorization Server verifies the user\u2019s access rights in the user database and creates a TGT             and session key. The Authorization Sever encrypts the results using a key derived from the user\u2019s             password and sends a message back to the user workstation. The workstation prompts the user for a             password and uses the password to decrypt the incoming message. When decryption succeeds, the user will             be able to use the TGT to request a <code>service ticket</code>.</p> </li> <li> <p>Step 3: When the user wants access to a service, the workstation client application sends a request to the Ticket            Granting Service containing the client name, realm name and a timestamp. The user proves his identity by            sending an authenticator encrypted with the session key received in Step 2.</p> </li> <li> <p>Step 4: The TGS decrypts the ticket and authenticator, verifies the request, and creates a ticket for the             requested server. The ticket contains the client name and optionally the client IP address. It also              contains the realm name and ticket lifespan. The TGS returns the ticket to the user workstation.             The returned message contains two copies of a server session key  one encrypted with the client password,             and one encrypted by the service password.</p> </li> <li> <p>Step 5: The client application now sends a service request to the server containing the ticket received in Step            4 and an authenticator. The service authenticates the request by decrypting the session key. The server           verifies that the ticket and authenticator match, and then grants access to the service. This step as           described does not include the authorization performed by the Intel AMT device, as described later.</p> </li> <li> <p>Step 6: If mutual authentication is required, then the server will reply with a server authentication message.</p> </li> </ul>"},{"location":"security/kerberos/01.Introduction/#3-time-synchronization","title":"3. Time synchronization","text":"<p>To prevent <code>replay attacks</code>, Kerberos uses <code>timestamps</code> as part of its protocol definition. For timestamps to  work properly, the <code>clocks of the client and the server need to be in synch as much as possible</code>. Since the  clocks of two computers are often out of synch, administrators can establish a policy to establish the  maximum acceptable difference to Kerberos between a client's clock and server's clock. If the difference between  a client's clock and the server's clock is less than the maximum time difference specified in this policy, any timestamp used in a session between the two computers will be  considered authentic. The maximum difference is usually set to five minutes.</p> <p>Note that if a client application wishes to use a service that is \"Kerberized\" (the service is configured to perform    Kerberos authentication), the client must also be Kerberized so that it expects to support the necessary message responses. </p>"},{"location":"security/kerberos/01.Introduction/#reference","title":"Reference","text":"<ul> <li>https://software.intel.com/sites/manageability/AMT_Implementation_and_Reference_Guide/default.htm?turl=WordDocuments%2Fintroductiontokerberosauthentication.htm</li> <li>http://web.mit.edu/kerberos/www/.</li> </ul>"},{"location":"security/kerberos/02.Install_kerberos_server_client_for_debian_server/","title":"Install Kerberos server and client on debian","text":"<p>In this tutorial, we will install MIT Kerberos server and client on a debian 11 server.</p>"},{"location":"security/kerberos/02.Install_kerberos_server_client_for_debian_server/#1-prerequisite","title":"1. Prerequisite","text":""},{"location":"security/kerberos/02.Install_kerberos_server_client_for_debian_server/#11-setup-ntp-server","title":"1.1 Setup NTP server","text":"<p>As we mentioned above, kerberos is time sensitive, we need to use a Network Time Protocol (NTP) server to synchronize  the time. You can follow this page https://vitux.com/how-to-setup-ntp-server-and-client-on-debian-11/</p>"},{"location":"security/kerberos/02.Install_kerberos_server_client_for_debian_server/#12-dns-server-setup","title":"1.2 DNS server setup","text":"<p>Before installing the Kerberos server, a properly configured DNS server is needed for your domain.  Since the Kerberos Realm by convention matches the domain name.</p>"},{"location":"security/kerberos/02.Install_kerberos_server_client_for_debian_server/#13-some-basic-krb-information","title":"1.3 Some basic krb information","text":"<p>Realm: CASD.LOCAL KDC server url: kdc01.casd.local (10.50.5.57) backup KDC server url: kdc02.casd.local (not deployed for now) admin principal: pliu/admin user principal: hadoop</p> <p>It is strongly recommended that your network-authenticated users have their uid in a different range (say, starting at 5000) than that of your local users.</p>"},{"location":"security/kerberos/02.Install_kerberos_server_client_for_debian_server/#2-server-installation","title":"2. Server Installation","text":"<p>For the server side, we will install an <code>MIT kerberos V5</code>. As we mentioned above, a KDC requires an Authentication Server (AS) and Ticket-Granting Server (TGS) To manage the KDC server, we need some admin tools which will be provided by the krb5-admin-server</p> <pre><code># step 1:  install the krb5-kdc and krb5-admin-server packages.\nsudo apt install krb5-kdc krb5-admin-server\n\n# 1st prompt will ask you the default REALM name, enter CASD.LOCAL\n# 2nd prompt will ask you the url/ip of the kdc server url, enter kdc01.casd.local or ip, if you have two kdc server, you can use space to separate them.\n# 3rd prompt will ask you the url/ip of the admin server url, enter kdc01.casd.local or ip(we install it on the same). \n\n# step2: create a new realm\n# The default realm in step 1 is the configuration for connection. We need to create the realm\nsudo krb5_newrealm\n# suppose the reaml name is CASD.LOCAL\n\n# step3: create principals(user account) by using admin tools\n# login to admin tools \nsudo kadmin.local\n\n# create new principals (user accounts)\n# note the / in pliu/admin here is only for human, nothing special for kdc.\n# as we did not specify the realm, the default realm will be added to the principals\nkadmin.local: addprinc pliu/admin\nkadmin.local: addprinc hadoop\n\n# step4: Add the appropriate Access Control List (ACL) permissions for the new admin user.\nsudo vim /etc/krb5kdc/kadm5.acl\n# add below lines\npliu/admin@CASD.LOCAL  *\n# The above line grants pliu/admin the ability to perform any operation on all principals in the realm. You can \n# configure principals with more restrictive privileges.\n\n# step5: restart the krb5-admin-server for the new ACL to take affect\nsudo systemctl restart krb5-admin-server.service\n</code></pre> <p>In this setup, the KDC uses a local database to store user login/password; we can connect kerberos to a ldap server.</p>"},{"location":"security/kerberos/02.Install_kerberos_server_client_for_debian_server/#3-server-configuration","title":"3. Server configuration","text":"<p>There are three main config files you need to pay attention: - /etc/krb5.conf - /etc/krb5kdc/kdc.conf - /etc/krb5kdc/kadm5.acl</p>"},{"location":"security/kerberos/02.Install_kerberos_server_client_for_debian_server/#31-etckrb5conf-kerberos-client-general-configuration","title":"3.1 /etc/krb5.conf (Kerberos Client &amp; General Configuration)","text":"<p>This configuration file is <code>required</code> by both <code>krb clients</code> and the <code>KDC server</code> to specify general <code>Kerberos settings</code>. It has three key sections: - <code>[libdefaults]</code>: General Kerberos settings (default realm, ticket options). - <code>[realms]</code>: Defines realms and their corresponding KDC and admin server. - <code>[domain_realm]</code>: Maps domain names to Kerberos realms.</p> <p>Below is an example of the <code>krb5.conf</code></p> <pre><code>[libdefaults]\n    default_realm = CASD.EU\n    ticket_lifetime = 24h\n    renew_lifetime = 7d\n    forwardable = true\n    dns_lookup_kdc = false\n\n[realms]\n    CASD.EU = {\n        kdc = kdc.casd.eu\n        admin_server = kdc.casd.eu\n        default_domain = casd.eu\n    }\n\n[domain_realm]\n    .casd.eu = CASD.EU\n    casd.eu = CASD.EU\n</code></pre>"},{"location":"security/kerberos/02.Install_kerberos_server_client_for_debian_server/#32-etckrb5kdckdcconf-kdc-specific-configuration","title":"3.2 /etc/krb5kdc/kdc.conf (KDC-Specific Configuration)","text":"<p>This configuration file is only used by the KDC (Key Distribution Center). It controls <code>how the KDC manages  authentication, tickets, and encryption</code>.</p> <p>It has three key section: - <code>[kdcdefaults]</code>: Defines which ports the KDC listens on. - <code>[realms]</code>: KDC-specific settings for managing tickets, database, and encryption of a domain.</p> <pre><code>[kdcdefaults]\n    kdc_ports = 88\n    kdc_tcp_ports = 88\n\n[realms]\n    CASD.EU = {\n        database_name = /var/lib/krb5kdc/principal\n        admin_keytab = /etc/krb5kdc/kadm5.keytab\n        acl_file = /etc/krb5kdc/kadm5.acl\n        dict_file = /usr/share/dict/words\n        key_stash_file = /etc/krb5kdc/stash\n        max_life = 24h\n        max_renewable_life = 7d\n        supported_enctypes = aes256-cts-hmac-sha1-96:normal aes128-cts-hmac-sha1-96:normal\n    }\n</code></pre>"},{"location":"security/kerberos/02.Install_kerberos_server_client_for_debian_server/#33-etckrb5kdckadm5acl-acl-for-kdc","title":"3.3 /etc/krb5kdc/kadm5.acl (ACL for KDC)","text":"<p>The <code>/etc/krb5kdc/kadm5.acl</code> file controls who can manage Kerberos principals (users, services, and hosts).</p> <pre><code># general form \nprincipal  privilege\n\n# some example\n# the admin principal has full admin access  (can add/delete principal, reset passwords, etc.)\nadmin@CASD.EU  *\n# user1 can change their own password but nothing else\nuser1@CASD.EU  x\n# service/admin can add and change principals, but not delete them\nservice/admin@CASD.EU  ac\n</code></pre> Symbol Privilege * Full access a Add principal d Delete principal m Modify principal c Change password x Change own password"},{"location":"security/kerberos/02.Install_kerberos_server_client_for_debian_server/#4-client-installation","title":"4. Client installation","text":"<p>You will now need to configure a Linux system as a Kerberos client. This will allow access to any kerberized services  once a user has successfully logged into the system.</p> <pre><code># step1: install packages\nsudo apt install krb5-user \n\n# step2: Configure the krb client config\nsudo dpkg-reconfigure krb5-config\n# The dpkg-reconfigure adds entries to the /etc/krb5.conf file for your Realm. You should have entries similar to the following:\n[libdefaults]\n        default_realm = CASD.LOCAL\n...\n[realms]\n        CASD.LOCAL = {\n                kdc = 10.50.5.57\n                admin_server = 10.50.5.57\n        }\n\n# step3: Test the configuration by requesting a ticket using the kinit utility\nkinit pliu@CASD.LOCAL\n\n# step4: Check the generated ticket\nklist \n</code></pre> <p>if you want to use krb for ssh authentication, you need to install libpam-krb5 libpam-ccreds auth-client-config <code>sudo auth-client-config -a -p kerberos_example</code> use the <code>auth-client-config</code> to configure the <code>libpam-krb5</code> module  to request a ticket during login</p>"},{"location":"security/kerberos/02.Install_kerberos_server_client_for_debian_server/#41-kadmin","title":"4.1 kadmin","text":"<p>kadmin and kadmin.local are command-line interfaces to the Kerberos V5 administration system. They provide  nearly identical functionalities; the difference is that <code>kadmin.local directly accesses the KDC database</code>, while  <code>kadmin performs operations using kadmind</code>.</p> <p>With <code>sudo kadmin.local</code> you have the admin console in the krb server locally. You can also access the admin console  remotely. You can find the complete doc here.</p>"},{"location":"security/kerberos/02.Install_kerberos_server_client_for_debian_server/#42-kutil","title":"4.2 kutil","text":"<p>The ktutil command invokes a command interface from which an administrator can read, write, or edit  entries in a keytab or Kerberos V4 srvtab file. You can find the detailed documentation of ktutil</p> <p>Create a new keytab with existing principal and password. We can choose different encryption algorithm</p> <pre><code>ktutil:  add_entry -password -p pengfei@CASD.LOCAL -k 1 -e\n    aes128-cts-hmac-sha1-96\nPassword for pengfei@CASD.LOCAL:\nktutil:  add_entry -password -p pengfei@CASD.LOCAL -k 1 -e\n    aes256-cts-hmac-sha1-96\nPassword for pengfei@CASD.LOCAL:\nktutil:  write_kt keytab\nktutil:\n</code></pre> <p>Read an existing keytab</p> <pre><code>ktutil:  read_kt /etc/krb5.keytab \nktutil:  list\nslot KVNO Principal\n---- ---- ---------------------------------------------------------------------\n   1    2     host/sssd-test.casd.local@CASD.LOCAL\n   2    2     host/sssd-test.casd.local@CASD.LOCAL\n   3    2 auth-agent/sssd-test.casd.local@CASD.LOCAL\n   4    2 auth-agent/sssd-test.casd.local@CASD.LOCAL\n</code></pre>"},{"location":"security/kerberos/02.Install_kerberos_server_client_for_debian_server/#reference","title":"Reference","text":"<p>https://www.easyredmine.com/documentation-of-easy-redmine/article/how-to-set-up-kerberos-authentication https://blog.csdn.net/qq_43536701/article/details/109854270</p>"},{"location":"security/kerberos/03.Configure_kerberos_to_use_ldap/","title":"Set up kerberos to use OpenLdap as backend","text":"<p>kerberos can store user login and password. But often we already have OpenLDAP set up for other things,  such as storing users and groups, adding the <code>Kerberos attributes</code> can be beneficial, providing an <code>integrated story</code>.</p> <ul> <li> <p>Pros:</p> <ul> <li>OpenLDAP replication is faster and more robust than the native Kerberos one, based on a cron job</li> <li>Single source for user account management(e.g. pwd, groups, etc.)</li> </ul> </li> <li> <p>Cons:         - Setting up the LDAP backend isn\u2019t a trivial task and shouldn\u2019t be attempted by administrators without prior knowledge of OpenLDAP.         - since krb5kdc is single-threaded there may be <code>higher latency in servicing requests</code> when using the OpenLDAP backend</p> </li> </ul>"},{"location":"security/kerberos/03.Configure_kerberos_to_use_ldap/#prerequisite","title":"Prerequisite","text":"<p>Here, we suppose you already have  - openldap server  - kerberos server(e.g. kdc, admin-server)</p> <p>For the openldap server, we suppose  - the base cn: dc=casd,dc=local - the admin account: cn=admin,dc=casd,dc=local</p>"},{"location":"security/kerberos/03.Configure_kerberos_to_use_ldap/#1-configure-openldap-to-work-with-kerberos","title":"1. Configure Openldap to work with Kerberos","text":"<p>We need to install the below packages</p> <pre><code>sudo apt install krb5-kdc-ldap krb5-admin-server\n</code></pre> <ul> <li>krb5-kdc-ldap: This package provides the LDAP backend plugin for the Kerberos Key Distribution Center (KDC). It               allows Kerberos to use OpenLDAP or another LDAP server to store</li> <li>krb5-admin-server: This package provides the Kerberos admin service (kadmind), which allows administrators               to manage the Kerberos database remotely.</li> </ul>"},{"location":"security/kerberos/03.Configure_kerberos_to_use_ldap/#11-install-kerberos-schema-in-openldap-server","title":"1.1 Install kerberos schema in openldap server","text":"<p>Openldap needs a <code>Kerberos schema</code> to be able to store the necessary object classes and attributes that  allow LDAP to store Kerberos principals and related data, such as encryption keys, expiration dates, and policy information. </p> <p>Kerberos provides an integrated ldap backend as a database if you are in this situation. You don't need this step. </p> <p>After installing <code>krb5-kdc-ldap</code>, you should find the kerberos schema in <code>/usr/share/doc/krb5-kdc-ldap/kerberos.schema.gz</code></p> <pre><code># copy and unzip the schema\nsudo cp /usr/share/doc/krb5-kdc-ldap/kerberos.schema.gz /etc/ldap/schema/\nsudo gunzip /etc/ldap/schema/kerberos.schema.gz\n\n# convert the schema into ldif format, then load the schema to ldap server\nsudo apt install schema2ldif\nsudo ldap-schema-manager -i kerberos.schema\n# now you should see below output\n# SASL/EXTERNAL authentication started\n# SASL username: gidNumber=0+uidNumber=0,cn=peercred,cn=external,cn=auth\n# SASL SSF: 0\n# executing 'ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/ldap/schema/kerberos.ldif'\n# SASL/EXTERNAL authentication started\n# SASL username: gidNumber=0+uidNumber=0,cn=peercred,cn=external,cn=auth\n# SASL SSF: 0\n# adding new entry \"cn=kerberos,cn=schema,cn=config\"\n</code></pre>"},{"location":"security/kerberos/03.Configure_kerberos_to_use_ldap/#12-optimize-the-backend-db-index-of-ldap-server","title":"1.2 Optimize the backend db index of ldap server","text":"<p>With the new schema loaded, let\u2019s index an attribute often used in searches:</p> <pre><code>$ sudo ldapmodify -Q -Y EXTERNAL -H ldapi:/// &lt;&lt;EOF\ndn: olcDatabase={1}mdb,cn=config\nadd: olcDbIndex\nolcDbIndex: krbPrincipalName eq,pres,sub\nEOF\n\n# output example\nmodifying entry \"olcDatabase={1}mdb,cn=config\"\n</code></pre>"},{"location":"security/kerberos/03.Configure_kerberos_to_use_ldap/#13-create-kerberos-service-account-in-openldap","title":"1.3 Create kerberos service account in Openldap","text":"<p>As kerberos need to contact the Openldap server to perfrom operations, we need to create two service accounts:</p> <ul> <li>kdc-service: needs to have <code>read rights on the realm container, principal container and realm sub-trees</code>.                 If disable_last_success and disable_lockout are not set, however, then <code>kdc-service needs write                  access to the Kerberos container</code> just like the admin DN below.</li> <li>kadmind-service: needs to have read and write rights on the realm container, principal container and realm sub-trees</li> </ul> <p>You can use the below command to add the two service accounts.</p> <pre><code># we use the admin account to run the add script\nldapadd -x -D cn=admin,dc=casd,dc=local -W &lt;&lt;EOF\ndn: uid=kdc-service,dc=casd,dc=local\nuid: kdc-service\nobjectClass: account\nobjectClass: simpleSecurityObject\nuserPassword: {CRYPT}x\ndescription: Account used for the Kerberos KDC\n\ndn: uid=kadmin-service,dc=casd,dc=local\nuid: kadmin-service\nobjectClass: account\nobjectClass: simpleSecurityObject\nuserPassword: {CRYPT}x\ndescription: Account used for the Kerberos Admin server\nEOF\n\n# you will be prompted to enter the password of the two accounts\nEnter LDAP Password: \nadding new entry \"uid=kdc-service,dc=casd,dc=local\"\n\nadding new entry \"uid=kadmin-service,dc=casd,dc=local\"\n</code></pre> <p>You can always reset the password by using the below command</p> <pre><code>ldappasswd -x -D cn=admin,dc=casd,dc=local -W -S uid=kdc-service,dc=casd,dc=local\n# you will be prompted to enter the password\nNew password:   \nRe-enter new password: \nEnter LDAP Password:  \n</code></pre> <p>You can test these accounts</p> <pre><code>ldapwhoami -x -D uid=kdc-service,dc=casd,dc=local -W\n</code></pre>"},{"location":"security/kerberos/03.Configure_kerberos_to_use_ldap/#14-update-the-access-control-lists-acl-of-openldap-server","title":"1.4 update the Access Control Lists (ACL) of Openldap server","text":"<p>This step can be tricky, as it highly depends on what you have defined already.  By default, the slapd package configures your database with the following ACLs:</p> <pre><code>olcAccess: {0}to attrs=userPassword by self write by anonymous auth by * none\nolcAccess: {1}to attrs=shadowLastChange by self write by * read\nolcAccess: {2}to * by * read\n</code></pre> <p>We need to insert new rules before the final to * by * read one, to control access to the Kerberos related entries and attributes:</p> <pre><code># add acl for krb service accounts\n$ sudo ldapmodify -Q -Y EXTERNAL -H ldapi:/// &lt;&lt;EOF\ndn: olcDatabase={1}mdb,cn=config\nadd: olcAccess\nolcAccess: {2}to attrs=krbPrincipalKey\n  by anonymous auth\n  by dn.exact=\"uid=kdc-service,dc=casd,dc=local\" read\n  by dn.exact=\"uid=kadmin-service,dc=casd,dc=local\" write\n  by self write\n  by * none\n-\nadd: olcAccess\nolcAccess: {3}to dn.subtree=\"cn=kerberos,dc=casd,dc=local\"\n  by dn.exact=\"uid=kdc-service,dc=casd,dc=local\" read\n  by dn.exact=\"uid=kadmin-service,dc=casd,dc=local\" write\n  by * none\nEOF\n\n# output example\nmodifying entry \"olcDatabase={1}mdb,cn=config\"\n</code></pre> <p>Here, we define the dn of kerberos container as <code>cn=kerberos,dc=casd,dc=local</code>, all the entries related to kerberos which are generated automatically should be stored in the kerberos container.</p> <p>After the modification, the existing {2} rule become {4}.:</p> <pre><code>$ sudo slapcat -b cn=config\n\n# the output below was reformatted a bit for clarity\nolcAccess: {0}to attrs=userPassword\n    by self write\n    by anonymous auth\n    by * none\nolcAccess: {1}to attrs=shadowLastChange\n    by self write\n    by * read\nolcAccess: {2}to attrs=krbPrincipalKey by anonymous auth\n    by dn.exact=\"uid=kdc-service,dc=casd,dc=local\" read\n    by dn.exact=\"uid=kadmin-service,dc=casd,dc=local\" write\n    by self write\n    by * none\nolcAccess: {3}to dn.subtree=\"cn=kerberos,dc=casd,dc=local\"\n    by dn.exact=\"uid=kdc-service,dc=casd,dc=local\" read\n    by dn.exact=\"uid=kadmin-service,dc=casd,dc=local\" write\n    by * none\nolcAccess: {4}to * by * read\n</code></pre>"},{"location":"security/kerberos/03.Configure_kerberos_to_use_ldap/#2-configure-kerberos-to-use-openldap","title":"2. Configure kerberos to use openldap","text":""},{"location":"security/kerberos/03.Configure_kerberos_to_use_ldap/#21-install-or-reconfigure-kerberos","title":"2.1 Install or reconfigure kerberos","text":"<pre><code># to get a good starting point with /etc/krb5.conf, you can reconfigure kerberos\nsudo dpkg-reconfigure krb5-config\n</code></pre>"},{"location":"security/kerberos/03.Configure_kerberos_to_use_ldap/#22-configure-kerberos-to-use-openldap-as-backend","title":"2.2 Configure kerberos to use openldap as backend","text":"<p>Now edit /etc/krb5.conf by adding the <code>database_module</code> option to the <code>CASD.LOCAL</code> realm section:</p> <pre><code>[realms]\n    CASD.LOCAL = {\n        kdc = 10.50.5.57\n        admin_server = 10.50.5.57\n                default_domain = casd.local\n                database_module = openldap_ldapconf\n    }\n</code></pre> <p>Then add these two sections to complete the definition of <code>database_module = openldap_ldapconf</code>:</p> <pre><code>[dbdefaults]\n        ldap_kerberos_container_dn = cn=kerberos,dc=casd,dc=local\n\n[dbmodules]\n        openldap_ldapconf = {\n                db_library = kldap\n\n                # if either of these is false, then the ldap_kdc_dn needs to\n                # have write access\n                disable_last_success = true\n                disable_lockout  = true\n\n                # this object needs to have read rights on\n                # the realm container, principal container and realm sub-trees\n                ldap_kdc_dn = \"uid=kdc-service,dc=casd,dc=local\"\n\n                # this object needs to have read and write rights on\n                # the realm container, principal container and realm sub-trees\n                ldap_kadmind_dn = \"uid=kadmin-service,dc=casd,dc=local\"\n\n                ldap_service_password_file = /etc/krb5kdc/service.keyfile\n                ldap_servers = ldapi:///\n                ldap_conns_per_server = 5\n        }\n</code></pre>"},{"location":"security/kerberos/03.Configure_kerberos_to_use_ldap/#23-create-the-realm-in-openldap-server","title":"2.3 Create the realm in openldap server","text":"<p>Use the <code>kdb5_ldap_util</code> utility to create the realm in openldap server</p> <pre><code>sudo kdb5_ldap_util -D cn=admin,dc=casd,dc=local create -subtrees dc=casd,dc=local -r CASD.LOCAL -s -H ldapi:///\n\n# output example\nPassword for \"cn=admin,dc=casd,dc=local\": \nInitializing database for realm 'CASD.LOCAL'\nYou will be prompted for the database Master Password.\nIt is important that you NOT FORGET this password.\nEnter KDC database master key: \nRe-enter KDC database master key to verify: \n</code></pre> <p>after this command, you should see <code>cn=CASD.LOCAL,cn=kerberos,dc=casd,dc=local</code> in the openldap server.</p>"},{"location":"security/kerberos/03.Configure_kerberos_to_use_ldap/#24-create-a-stash-of-the-password-used-to-bind-to-the-ldap-server","title":"2.4 Create a stash of the password used to bind to the LDAP server.","text":"<pre><code>sudo kdb5_ldap_util -D cn=admin,dc=casd,dc=local stashsrvpw -f /etc/krb5kdc/service.keyfile uid=kdc-service,dc=casd,dc=local\nsudo kdb5_ldap_util -D cn=admin,dc=casd,dc=local stashsrvpw -f /etc/krb5kdc/service.keyfile uid=kadmin-service,dc=casd,dc=local\nsudo kdb5_ldap_util -D cn=admin,dc=casd,dc=local stashsrvpw -f /etc/krb5kdc/service.keyfile cn=admin,dc=casd,dc=local\n</code></pre> <p>The /etc/krb5kdc/service.keyfile file now contains clear text versions of the passwords used by the KDC to contact the LDAP server!</p>"},{"location":"security/kerberos/03.Configure_kerberos_to_use_ldap/#25-create-acl-file-for-admin-server","title":"2.5 create acl file for admin server","text":"<pre><code>$ sudo vim /etc/krb5kdc/kadm5.acl\n\n# add the below line\n*/admin@CASD.LOCAL       *\n\n# start or restart the krb services\nsudo systemctl start krb5-kdc.service krb5-admin-server.service\n</code></pre>"},{"location":"security/kerberos/03.Configure_kerberos_to_use_ldap/#26-test-the-binding","title":"2.6 Test the binding","text":"<p>Login to the krb admin </p> <pre><code># login to admin server\nsudo kadmin.local\n# now you will have a krb admin server prompt, you can use the kerberos admin command now\n# Below are some command examples, you can type ? to have all the command list\n\n# list the existing principals(user account)\nlist_principals\n\n# add new principals\naddprinc test\n</code></pre> <p>The above command will create an <code>test</code> principal with a DN of krbPrincipalName=test@CASD.LOCAL,cn=CASD.LOCAL,cn=krbContainer,dc=casd,dc=local.</p>"},{"location":"security/kerberos/03.Configure_kerberos_to_use_ldap/#27-use-the-existing-user-account-of-openldap-server","title":"2.7 Use the existing user account of openldap server","text":"<p>Let\u2019s say, however, that you already have a user in your directory, and it\u2019s in uid=pengfei,ou=people,dc=casd,dc=local.  How can you add the Kerberos attributes to it? You use the -x parameter to specify the location.  For the ldap_kadmin_dn to be able to write to it, we first need to update the ACLs:</p> <pre><code>sudo ldapmodify -Q -Y EXTERNAL -H ldapi:/// &lt;&lt;EOF\ndn: olcDatabase={1}mdb,cn=config\nadd: olcAccess\nolcAccess: {4}to dn.subtree=\u201cou=people,dc=casd,dc=local\u201d\n    by dn.exact=\u201duid=kdc-service,dc=casd,dc=local\u201d read\n    by dn.exact=\u201duid=kadmin-service,dc=casd,dc=local\u201d write\n    by * break\nEOF\n</code></pre> <p>Now you can create a principal which matches with an existing openldap user account. Suppose the dn of the user account is <code>uid=pengfei,ou=people,dc=casd,dc=local</code>.</p> <pre><code># login to admin server\nsudo kadmin.local\n\n# the kadmin-service must have write access on the target dn, otherwise you will get an Insufficient access error\naddprinc -x dn=uid=pengfei,ou=people,dc=casd,dc=local pengfei/admin\n\naddprinc -x dn=uid=test,ou=people,dc=casd,dc=local test\n\n# you can check the details of a principal by \ngetprinc pengfei/admin\n</code></pre> <p>if the <code>dn</code> exists, <code>kadmin.local</code> will just add the required Kerberos attributes to this existing entry. If it  didn\u2019t exist, <code>it would be created from scratch, with only the Kerberos attributes</code>.</p>"},{"location":"security/kerberos/03.Configure_kerberos_to_use_ldap/#3-test-the-principal-via-a-kerberos-client","title":"3. Test the principal via a kerberos client","text":"<p>Goto another server</p> <pre><code># step1: install packages\nsudo apt install krb5-user\n\n# if it's the first time, you will see three prompt\n# 1. enter default Realm: CASD.LOCAL\n# 2. enter kdc url: kdc01.casd.local or 10.50.5.57\n# 3. enter admin server url: kdc01.casd.local or 10.50.5.57\n\n# if you already have the client, you can re-configure the krb client, you should see the three prompt.\nsudo dpkg-reconfigure krb5-config\n\n# After the prompt, the config file `/etc/krb5.conf` file for your Realm. You should have entries similar to the following:\n[libdefaults]\n        default_realm = CASD.LOCAL\n...\n[realms]\n        CASD.LOCAL = {\n                kdc = 10.50.5.57\n                admin_server = 10.50.5.57\n        }\n\n# step3: Test the configuration by requesting a ticket using the kinit utility\nkinit pengfei/admin@CASD.LOCAL\n\n# step4: setup a default principal\nvim ~/.k5identity\npengfei/admin@CASD.LOCAL\n</code></pre>"},{"location":"security/kerberos/03.Configure_kerberos_to_use_ldap/#4-gssapi-for","title":"4. GSSAPI for","text":"<p>The below <code>olc_enable_gssapi.ldif</code> enables GSSAPI authentication in the openldap server</p> <pre><code>dn: cn=config\nchangetype: modify\nadd: olcAuthzRegexp\nolcAuthzRegexp: uid=([^,]+),cn=casd.local,cn=gssapi,cn=auth\n  uid=$1,ou=people,dc=casd,dc=local\n-\n#2. Configurer the domain SASL (Simple Authentication and Security Layer) of kerberos\nadd: olcSaslRealm\nolcSaslRealm: CASD.LOCAL\n</code></pre> <pre><code>$ldapmodify -QY EXTERNAL -H ldapi:/// -f olc_enable_gssapi.ldif\n</code></pre> <pre><code># login to admin server\nsudo kadmin.local\n\n# create a principal kerberos to connect to ldap\naddprinc -randkey ldap/ldap.casd.local@CASD.LOCAL\n\n# Update the Keytab: Export the principal to the keytab file so the LDAP server can use it:\nktadd -k /etc/krb5.keytab ldap/ldap.casd.local@CASD.LOCAL\n</code></pre> <p>Try to use your kerberos token to access the openldap server</p> <pre><code>ldapsearch -H ldap://ldap.casd.local -Y GSSAPI -b \"dc=casd,dc=local\"\n\nssh -o GSSAPIAuthentication=yes -o GSSAPIDelegateCredentials=yes test@10.50.5.92\n</code></pre>"},{"location":"security/kerberos/03.Configure_kerberos_to_use_ldap/#bkp","title":"bkp","text":"<pre><code>sudo apt install  krb5-pkinit libsasl2-modules-gssapi-mit\n</code></pre> <ul> <li> <p>krb5-pkinit: This package enables <code>PKINIT (Public Key Cryptography for Initial Authentication)</code> in Kerberos.            PKINIT allows Kerberos authentication <code>using X.509 certificates instead of passwords</code>, which is useful for            environments that require <code>smart card login</code> or <code>certificate-based authentication</code>.</p> </li> <li> <p>libsasl2-modules-gssapi-mit: This package provides the GSSAPI (Generic Security Services Application Program Interface)       module for SASL (Simple Authentication and Security Layer) using the MIT Kerberos implementation.</p> </li> </ul>"},{"location":"security/kerberos/04.Install_kerberos_server_client_for_windows_server/","title":"Install Kerberos server and client on windows","text":"<p>In windows, the <code>ActiveDirectory(AD)</code> implements the feature of both <code>Ldap and kerberos</code>. So if you enabled an AD in your Windows server, you automatically have a <code>KDC</code>.</p> <p>So you only need to follow the tutorial on how to install AD.</p>"},{"location":"security/kerberos/05.Configure_sssd_to_use_static_uid_gid/","title":"Configure sssd to use static uid, gid","text":"<p>POSIX (Portable Operating System Interface) is <code>UNIX/Linux standards for identity and access control</code>. A <code>POSIX</code>  account use specific attributes such as - uidNumber \u2013 Unique User ID (UID) - gidNumber \u2013 Primary Group ID (GID) - homeDirectory \u2013 User's home directory path  - loginShell \u2013 The default shell (e.g., /bin/bash)</p> <p>These attributes allow UNIX/Linux systems to recognize, authenticate users, and create user workspace.</p> <p>By default, AD does not use POSIX attributes for user and group.  Instead, AD relies on:</p> <ul> <li>Security Identifiers (SIDs): Every user and group has a <code>SID</code>, which is a unique identifier in Windows.</li> <li><code>sAMAccountName</code>: pliu (This is legacy login, )</li> <li>UserPrincipalName (UPN): pliu@casd.eu (authentication in modern windows server)</li> </ul>"},{"location":"security/kerberos/05.Configure_sssd_to_use_static_uid_gid/#1-default-behavior-when-sssd-uses-ad-as-authentication-backend","title":"1. Default behavior when sssd uses AD as authentication backend","text":"<p>The default behavior in <code>SSSD</code> and <code>Winbind</code> is to use <code>auto id mapping</code>. SSSD will dynamically generate UIDs and GIDs from the <code>AD objects's ObjectSID</code>. This will lead to inconsistent UIDs and GIDs across machines.</p> <p>In certain scenarios, it will create conflicting ACL in user home. For example, if a user with AD account with name <code>test</code> login to a linux server, a user home will be created <code>/home/test</code>. If the user account is deleted, and a new account <code>test</code> is created, when the new <code>test</code> user login to the linux server, it will user /home/test as home dir too. But the new and old <code>test</code> will have different uid. So the old files in /home/test will have old uid as owner, the new  <code>test</code> user can't access it. </p> <p>To avoid inconsistent UIDs and GIDs, we recommend you to use static uidNumber and gidNumber.</p>"},{"location":"security/kerberos/05.Configure_sssd_to_use_static_uid_gid/#2-configure-sssd-to-user-static-uidnumber-and-gidnumber","title":"2. Configure sssd to user static uidNumber and gidNumber.","text":"<p>To configure sssd to user static uidNumber and gidNumber, follow the below steps 1. Add posix attributes in AD 2. Configure sssd to read posix attributes</p>"},{"location":"security/kerberos/05.Configure_sssd_to_use_static_uid_gid/#21-adds-posix-attributes-in-ad","title":"2.1 Adds posix attributes in AD","text":"<p>If SSSD wants to use static uidNumber and gidNumber, the AD server must have those attributes. Before Windows server 2016. The AD server can use <code>rfc2307</code> schema, which allows us to create posix compatible user  accounts and groups. This feature has been removed since <code>Windows server 2016</code>. But you can still add attributes such as <code>uidNumber</code>, <code>gidNumber</code> to a user account or group. </p> <p>Open <code>AD users and groups gui</code>-&gt; on the toolbar, click on <code>view</code>-&gt; Select <code>advance features</code> -&gt; now when you double-click on  a user account, you will see a tab called </p> <p></p> <p></p> <p>The official doc can be found here.</p>"},{"location":"security/kerberos/05.Configure_sssd_to_use_static_uid_gid/#22-configure-sssd-to-read-posix-attributes","title":"2.2 Configure sssd to read posix attributes","text":"<p>Before changing your sssd configuration, make sure <code>AD Objects have gidNumber and uidNumber Attributes</code>.</p>"},{"location":"security/kerberos/05.Configure_sssd_to_use_static_uid_gid/#221-for-ad-windows-server-2016","title":"2.2.1 For AD &lt; Windows server 2016.","text":"<p>Configure the AD server to use <code>rfc2307</code> schema, and create posix compatible accounts and groups. Then add the below  conf in <code>/etc/sssd/sssd.conf</code></p> <pre><code>[domain/YOURDOMAIN]\nid_provider = ad\naccess_provider = ad\nldap_id_mapping = False\nldap_schema = rfc2307\n</code></pre>"},{"location":"security/kerberos/05.Configure_sssd_to_use_static_uid_gid/#221-for-ad-windows-server-2016_1","title":"2.2.1 For AD &gt;= Windows server 2016.","text":"<p>Add the below conf in <code>/etc/sssd/sssd.conf</code></p> <pre><code>[domain/YOURDOMAIN]\nid_provider = ad\naccess_provider = ad\nldap_id_mapping = False  # Important: Forces usage of uidNumber/gidNumber\nldap_user_uid_number = uidNumber\nldap_user_gid_number = gidNumber\nldap_group_gid_number = gidNumber\nenumerate = True  # Optional: Lists all users and groups\n</code></pre>"},{"location":"security/kerberos/05.Configure_sssd_to_use_static_uid_gid/#23-restart-sssd-and-check-uid-gid","title":"2.3 Restart sssd and check uid, gid","text":"<pre><code># restart sssd\nsystemctl restart sssd\n# clear sssd cache\nsss_cache -E\n\n# check user id and groups\nid &lt;uid&gt;\n\n# you should see the output id value matches the value which you deined in AD\n\n# check group id\ngetent group &lt;groupname&gt;\n</code></pre>"},{"location":"security/kerberos/Keytab_introduction/","title":"Keytab files","text":"<p>A .keytab file is a binary file that stores <code>Kerberos principal credentials in an encrypted format</code>.  It allows services and users to authenticate with a Kerberos Key Distribution Center (KDC) without  manually entering a password.</p>"},{"location":"security/kerberos/Keytab_introduction/#1-use-cases","title":"1. Use cases","text":"<p>We will use a keytab file for getting a kerberos ticket in the below scenarios:</p> <ul> <li> <p>Service-to-Service Authentication: The authentication between services must be automatically without manual input             of password. For example, Hadoop YARN ResourceManager or Spark job needs to authenticate to HDFS, it               uses a keytab to prove its identity</p> </li> <li> <p>Passwordless Login: A keytab file securely stores credentials and eliminates the need to hardcode                  passwords in scripts or configurations.</p> </li> </ul>"},{"location":"security/kerberos/Keytab_introduction/#2-lifecycle-of-a-keytab-file","title":"2. Lifecycle of a .keytab File","text":"<p>A .keytab file <code>does not expire on its own</code>, but the credentials inside it (Kerberos keys) can become invalid due to  password changes, key rotations, or policy settings in Active Directory (AD) or the Kerberos Key Distribution Center (KDC).  Below is the typical lifecycle: 1. Creation of the Keytab: The .keytab file is generated using <code>ktpass (Windows)</code> or <code>kadmin (Linux)</code>.       <code>It contains encrypted credentials for a Kerberos principal.</code> 2. Usage in passwordless Authentication: <code>kinit -kt &lt;keytab&gt; &lt;principal&gt;</code> command fetches a Kerberos ticket from the KDC. 3. Expiry, renew of Tickets: <code>TGTs expire</code> after a certain time (e.g., 10 hours). If the ticket is renewable, it Can be          renewed using <code>kinit -R</code>. Otherwise, a new ticket must be obtained using <code>kinit -kt &lt;keytab&gt; &lt;principal&gt;</code>. 4. Keytab becomes invalid, ask a new keytab:</p> <p>Below is a list of when you need to renew a .keytab file: 1. Users change the password: 2. Password/key rotation policies: For service accounts, the services do not change the password. But password/key                     rotation policies may be enforced. AD may change the password every 90 days. 3. Revocation: If a security breach has been discovered, the admin users will revoke existing credentials.</p>"},{"location":"security/kerberos/Keytab_introduction/#3-keytab-files-generation","title":"3. Keytab files generation","text":"<p>There are two ways to generate keytab files: - from the server side(KDC) - from the client side</p>"},{"location":"security/kerberos/Keytab_introduction/#31-from-the-kdc-side","title":"3.1 From the KDC side","text":""},{"location":"security/kerberos/Keytab_introduction/#311-for-adkrb-userswindows","title":"3.1.1 For AD/krb users(Windows):","text":"<pre><code># for a user account\nktpass -princ pliu@CASDDS.CASD -mapuser pliu -crypto ALL -ptype KRB5_NT_PRINCIPAL -pass * -out pliu-user.keytab\n\n# for a service account\nktpass -princ host/hadoop-client.casdds.casd@CASDDS.CASD -mapuser HADOOP-CLIENT$ -pass * -ptype KRB5_NT_PRINCIPAL -crypto AES256-SHA1 -out hadoop-client.keytab\n</code></pre> <ul> <li>In <code>-mapuser HADOOP-CLIENT$</code>, The $ indicates it's a service account (not a user). </li> <li><code>-pass *</code>: You will be prompted to enter a password, this password must match the actual AD account password.                 ktpass doesn\u2019t have the ability to fetch a user's existing password from Active Directory automatically.</li> </ul> <p>To automate the keytab generation, you can write a powershell which reset the AD account password at the same time.</p> <pre><code># get a new password from prompt\n$pass = Read-Host -AsSecureString \"Enter AD Password\"\n$plain = [Runtime.InteropServices.Marshal]::PtrToStringAuto(\n    [Runtime.InteropServices.Marshal]::SecureStringToBSTR($pass)\n)\n# reset AD account password with the new password\nSet-ADAccountPassword -Identity pliu -Reset -NewPassword (ConvertTo-SecureString $plain -AsPlainText -Force)\n\n# generate keytab with the new password\nktpass -princ pliu@CASDDS.CASD -mapuser pliu -crypto ALL -ptype KRB5_NT_PRINCIPAL -pass $plain -out pliu-user.keytab\n</code></pre>"},{"location":"security/kerberos/Keytab_introduction/#312-for-mit-kerberos-userslinux","title":"3.1.2 For MIT kerberos users(Linux):","text":"<pre><code># get a kadmin shell\nsudo kadmin.local\n\n# create a keytab for one principal\nktadd -k /tmp/pliu-user.keytab pliu@CASDDS.CASD\n\n# if the principal does not exist, you can create a new principal with\naddprinc -randkey pliu@CASDDS.CASD\n</code></pre>"},{"location":"security/kerberos/Keytab_introduction/#32-from-the-client-side","title":"3.2 From the client side","text":""},{"location":"security/kerberos/Keytab_introduction/#321-for-adkrb-userswindows","title":"3.2.1 For AD/krb users(Windows):","text":"<p>For windows user, we can use the <code>ktpass</code> command</p> <pre><code>ktpass -princ HTTP/client.example.com@EXAMPLE.COM ^\n       -mapuser clientuser ^\n       -crypto AES256-SHA1 ^\n       -ptype KRB5_NT_PRINCIPAL ^\n       -pass ActualUserPassword123! ^\n       -out C:\\Users\\YourName\\Desktop\\client.keytab ^\n       -kvno 0\n</code></pre> <ul> <li>-princ: The Kerberos principal (usually service/FQDN@REALM)</li> <li>-mapuser: AD username (can be service or regular user)</li> <li>-crypto: Encryption type</li> <li>-out: Path to save the keytab</li> <li>-pass: You must know the user's actual password</li> <li>-kvno 0: Lets the KDC auto-select the current Key Version Number</li> </ul> <p>Ktpass still needs to contact the KDC, you need to make sure DNS and time sync with the domain are correct.</p>"},{"location":"security/kerberos/Keytab_introduction/#322-for-mit-kerberos-userslinux","title":"3.2.2 For MIT kerberos users(Linux):","text":"<p>For linux kerberos client, you can use the ktutil tool. Below is an example</p> <pre><code># open ktutil shell\nktutil\n\n# add an kerberos entry(a principal, password pair)\naddent -password -p pliu@CASDDS.CASD -k 1 -e aes256-cts-hmac-sha1-96\n\n# output the kerberos entry to a keytab file\nwkt /home/pliu/pliu-user.keytab\n\n# you can read the kerberos entry in a keytab file with read_kt command\nread_kt /home/pliu/pliu-user.keytab\n\n# the above command will add the content of the keytab in the ktutil cache. When you write the cache to a keytab file\n# the content of all kerberos entry will be copied in the keytab file.\n\n# quit the ktutil shell \nq\n\n# test the keytab files\nklist -k /home/pliu/pliu-user.keytab\n\n# generate a ticket with the keytab\nkinit -kt pliu-user.keytab pliu@CASDDS.CASD\n</code></pre> <ul> <li>-password: prompt to ask user password</li> <li>-p: specify user principal</li> <li>-k: specify the key version number.</li> <li>-e: specify the encryption algorithm.</li> </ul>"},{"location":"security/keycloak/Install_keycloak/","title":"Install keycloak on debian 11","text":"<p>This tutorial shows how to install and config a keycloak server in a scripted manner. The objective is: </p> <ul> <li>enable installation automation without K8s cluster</li> <li>enable the usage of variables for supporting various environments</li> <li>enable idempotence (the script can be executed multiple times producing the same results)</li> </ul> <p>You can find the official doc https://www.keycloak.org/documentation.html</p> <p>Keycloak Operator can only be used in a Kubernetes based runtime.</p> <p>We will follow below key Steps  1. Installing and starting the Keycloak server 2. Connecting the Admin CLI 3. Configuring</p>"},{"location":"security/keycloak/Install_keycloak/#step-0-prerequisites","title":"Step 0 : Prerequisites","text":""},{"location":"security/keycloak/Install_keycloak/#create-user-account","title":"Create user account","text":"<p>For good practice, we should run the <code>keycloak.service</code> with a service account(e.g. specific User and Group).  In this tutorial, we decide to use <code>keycloak</code> as the username and group name.</p> <p>You can create the user and group using the <code>groupadd and useradd</code> commands. The following example creates the user, group,  and working directory for keycloak. These commands typically requires root (sudo) permissions.</p> <pre><code>sudo groupadd -r keycloak\n\nsudo useradd -r -g keycloak -d /opt/keycloak -s /sbin/nologin keycloak\n\nsudo mkdir -p /opt/keycloak\n\n# change the owner of the data folder\nsudo chown keycloak:keycloak /opt/keycloak\n</code></pre>"},{"location":"security/keycloak/Install_keycloak/#install-jdk","title":"Install jdk","text":"<p>Keycloak requires Java to work. You can check and verify that Java is installed with the following command. Base on the keycloak version, you need to install the required jdk version. In this tutorial, for keycloak 23.0.4, we use jdk-17</p> <pre><code># check if java installed\njava -version\n\n# install jdk 17 (debian 11)\nsudo apt install openjdk-17-jdk\n</code></pre>"},{"location":"security/keycloak/Install_keycloak/#step-1-installing-and-starting-the-keycloak-server","title":"Step 1: Installing and starting the Keycloak server","text":"<p>We can install the keycloak en mode: - bare metal - container(e.g. docker, k8s, etc.)</p>"},{"location":"security/keycloak/Install_keycloak/#installation-en-mode-bare-metal","title":"Installation en mode bare metal","text":"<p>Download of the Keycloak distribution.</p> <pre><code># fix the kc version which you want to download\nexport KC_VERSION=23.0.4\ncurl -LO  https://github.com/keycloak/keycloak/releases/download/\"${KC_VERSION}\"/keycloak-\"${KC_VERSION}\".zip\n\n# copy the bin into the working directory\nsudo mv keycloak-${KC_VERSION}.zip /opt/keycloak\n\n# unpacking the archive.\nunzip keycloak-${KC_VERSION}.zip\n\n# \ncd keycloak-${KC_VERSION}\n\n# add execute acl on bin folder\nsudo chmod o+x bin\n\n# This directory contains a Keycloak Quarkus application.\n# When we start the server for the first time, we have to set the admin user and the admin password:\n# You can notice all the config is done by setting env var not in a config file. Because it's designed with cloud native\nKEYCLOAK_ADMIN=admin KEYCLOAK_ADMIN_PASSWORD=YVqs7p4bJaim3rQ2FSI8 ./bin/kc.sh start-dev\n\n# When we start again, it is not necessary to set these variables, again. You can start the server with:\n./bin/kc.sh start-dev\n\n# start-dev runs the quarkus application in DEV-mode. Do not use this for Production.\n# By default, the Keycloak server is using the following ports. They are only served from the localhost loopback address 127.0.0.1:\n# 8080 for Keycloak using HTTP\n# One of the last lines from the log output is:\n# 2023-04-11 13:23:29,545 INFO  [io.quarkus] (main) Keycloak 21.0.2 on JVM (powered by Quarkus 2.13.7.Final) started in 4.418s. Listening on: http://0.0.0.0:8080\n# \n</code></pre> <p>We can now open the Administration Console from localhost and do the login with the just created admin user.</p> <p>The distribution also contains the <code>Admin CLI</code>. This is the shell script ./bin/kcadm.sh.</p> <p>We define the <code>environment variable KCADM for the kcadm.sh</code> script. </p> <pre><code># It must be the absolute path to the \n# kcadm.sh script from the above Keycloak installation.\n# general form\nexport KCADM=\"/path/to/keycloak/bin/kcadm.sh\"\n# in our tutorial\nexport KCADM=\"/opt/keycloak/keycloak-23.0.4/bin/kcadm.sh\"\nexport HOST_FOR_KCADM=localhost\n</code></pre>"},{"location":"security/keycloak/Install_keycloak/#installation-en-mode-docker-image","title":"Installation en mode docker image","text":"<p>To install and run Keycloak as a docker container a single command is necessary.</p> <pre><code>#  \nexport KC_VERSION=23.0.4\n\n# create a container\ndocker run -p 8080:8080 -e KEYCLOAK_ADMIN=admin -e KEYCLOAK_ADMIN_PASSWORD=admin quay.io/keycloak/keycloak:${KC_VERSION} start-dev\n</code></pre> <p>In the next steps we are using the Admin CLI script (kcadm.sh). It is also contained in the Keycloak docker image.  This means every call of the Admin CLI is executing the script from within the docker image.</p> <pre><code>docker run --rm --entrypoint /opt/keycloak/bin/kcadm.sh quay.io/keycloak/keycloak:${KC_VERSION}\n</code></pre> <p>We define the environment variable KCADM for the above command. Additionally, we mount the <code>$HOME/.keycloak</code> folder  from the docker host at <code>/opt/.keycloak</code>.</p> <pre><code>export KCADM=\"docker run --rm --entrypoint /opt/keycloak/bin/kcadm.sh -v ${HOME}/.keycloak:/opt/keycloak/.keycloak quay.io/keycloak/keycloak:${KC_VERSION}\"\n\n# When we executed $KCADM successfully the following output is shown:\nKeycloak Admin CLI\n\nUse 'kcadm.sh config credentials' command with username and password to start a session against a specific\nserver and realm.\n</code></pre> <p>When executing this script with a command (like config, create, get etc.) it connects to the Keycloak instance running  in another docker container. Depending on the docker environment you are using, the host name of the Keycloak instance  must be specified differently. For Docker Desktop environments the host name can be defined as <code>host.docker.internal</code>.</p> <pre><code>export HOST_FOR_KCADM=host.docker.internal\n</code></pre>"},{"location":"security/keycloak/Install_keycloak/#step2-starting-the-keycloak-server","title":"Step2: Starting the keycloak server","text":""},{"location":"security/keycloak/Install_keycloak/#in-development-mode","title":"In development mode","text":"<p>This mode offers convenient defaults for developers to get the keycloak server up and running quickly. </p> <pre><code># To start in development mode, enter the following command:\n\nbin/kc.[sh|bat] start-dev\n</code></pre> <p>You can write a little script to run the service on the background. Not recommended for the production usage</p> <pre><code>#!/bin/bash\nexport KEYCLOAK_ADMIN=admin\nexport KEYCLOAK_ADMIN_PASSWORD=YVqs7p4bJaim3rQ2FSI8\n\nnohup path/to/keycloak/bin/kc.sh start-dev --http_server_proxy edge  --hostname-strict=false --hostname=keycloak.casd.local &amp;\n</code></pre> <p>Development mode sets the following default configuration:</p> <ul> <li>HTTP is enabled</li> <li>Strict hostname resolution is disabled</li> <li>Cache is set to local (No distributed cache mechanism used for high availability)</li> <li>Theme-caching and template-caching is disabled</li> </ul>"},{"location":"security/keycloak/Install_keycloak/#in-production-mode","title":"In production mode","text":"<p>This mode follows a secure by default principle.</p> <pre><code>To start in production mode, enter the following command:\n\nbin/kc.[sh|bat] start\n</code></pre> <p>Without further configuration, this command will not start Keycloak and show you an error instead. This response is  done on purpose, because Keycloak follows a secure by default principle. Production mode expects a hostname to be  set up and an HTTPS/TLS setup to be available when started.</p> <p>Production mode sets the following defaults:</p> <ul> <li>HTTP is disabled as transport layer security (HTTPS) is essential </li> <li>Hostname configuration is expected </li> <li>HTTPS/TLS configuration is expected</li> </ul> <p>Before deploying Keycloak in a production environment, make sure to follow the steps outlined in Configuring  Keycloak for production.</p>"},{"location":"security/keycloak/Install_keycloak/#creating-the-initial-admin-user","title":"Creating the initial admin user","text":"<p>You can create the initial admin user by using the <code>web frontend</code>, which you access using a local connection  (localhost). You can instead create this user by using environment variables. Set <code>KEYCLOAK_ADMIN=&lt;username&gt;</code> for  the initial admin username and <code>KEYCLOAK_ADMIN_PASSWORD=&lt;password&gt;</code> for the initial admin password.</p> <p>Keycloak parses these values at first startup to create an initial user with administrative rights. Once the first  user with administrative rights exists, you can use the Admin Console or the command line tool kcadm.[sh|bat] to  create additional users.</p> <p>If the initial administrator already exists and the environment variables are still present at startup, an error  message stating the failed creation of the initial administrator is shown in the logs. Keycloak ignores the  values and starts up correctly.</p>"},{"location":"security/keycloak/Install_keycloak/#optimize-the-keycloak-startup","title":"Optimize the Keycloak startup","text":"<p>We recommend optimizing Keycloak to provide faster startup and better memory consumption before deploying Keycloak  in a production environment. </p> <p>By default, when you use the start or start-dev command, Keycloak runs a build command under the covers for  convenience reasons.</p> <p>You can run the build command explicitly. Below are some examples</p> <pre><code># get all build command options \nbin/kc.[sh|bat] build --help\n\n# Run a build to set the database to PostgreSQL before startup\nbin/kc.[sh|bat] \n\n# below is an example\nsudo ./bin/kc.sh build --db=postgres \n\n# after the build process, you can check the config of the build result\nsudo ./bin/kc.sh show-config\n</code></pre> <p>For example, you can add below conf in the <code>conf/keycloak.conf</code> file</p> <pre><code># Basic settings for running in production. Change accordingly before deploying the server.\n\n# Database\n\n# The database vendor.\ndb=postgres\n\n# The username of the database user.\ndb-username=keycloak\n\n# The password of the database user.\ndb-password=changeMe\n\n# The full database JDBC URL. If not provided, a default URL is set based on the selected database vendor.\ndb-url=jdbc:postgresql://localhost/keycloak\n\n# Observability\n\n# If the server should expose healthcheck endpoints.\n#health-enabled=true\n\n# If the server should expose metrics endpoints.\n#metrics-enabled=true\n\n# HTTP\n\n# The file path to a server certificate or certificate chain in PEM format.\nhttps-certificate-file=/opt/keycloak/keycloak-23.0.4/conf/wildcard-casd.pem\n\n# The file path to a private key in PEM format.\nhttps-certificate-key-file=/opt/keycloak/keycloak-23.0.4/conf/wildcard-casd.key\n\n# The http_server_proxy address forwarding mode if the server is behind a reverse http_server_proxy.\n#http_server_proxy=reencrypt\n\n# Do not attach route to cookies and rely on the session affinity capabilities from reverse http_server_proxy\n#spi-sticky-session-encoder-infinispan-should-attach-route=false\n\n# Hostname for the Keycloak server.\nhostname=keycloak.casd.local\n</code></pre> <p>After a successful build, you can start Keycloak and turn off the default startup behavior by entering the following command:</p> <pre><code>bin/kc.[sh|bat] start --optimized &lt;configuration-options&gt;\n</code></pre> <p>The <code>--optimized</code> parameter tells Keycloak to assume a pre-built, already optimized Keycloak image is used. As  a result, Keycloak avoids checking for and running a build directly at startup, which saves time.</p> <p>For more information you can visit this page. https://www.keycloak.org/server/configuration</p>"},{"location":"security/keycloak/Install_keycloak/#step3-connection-the-admin-cli","title":"Step3 : Connection the admin CLI","text":"<p>Now we connect the <code>Keycloak Admin CLI</code> to the API and authenticate with the user created previously. We use two  environment variables created in Step 1:</p> <ul> <li>$KCADM</li> <li>$HOST_FOR_KCADM</li> </ul> <p>Please make sure they are defined. Their definition is dependent on the runtime you have chosen.</p> <p>We log in to the master realm with the admin user. By using the options config credentials we request and maintain an  authenticated session, which is used for all further calls. Be aware the access and refresh tokens for this session will be stored in the file $HOME/.keycloak/kcadm.config.</p> <pre><code>$KCADM config credentials --server http://$HOST_FOR_KCADM:8080 --user admin --password YVqs7p4bJaim3rQ2FSI8 --realm master\n</code></pre> <p>To check the successful authentication and an authenticated session, we make a first request to the API.</p> <pre><code>$KCADM get serverinfo\n</code></pre> <p>The Keycloak server responds with a dump of information about its state and functionality. The same information is  also available within the Web Admin Console.</p>"},{"location":"security/keycloak/Install_keycloak/#step3-creating-a-systemd-service-file-for-keycloak","title":"Step3: Creating a SystemD Service File for Keycloak","text":"<p>If everythion goes well in step 1 and 2, it means we have a keycloak server ready. To facilitate the keycloak  service management, Now we will create a systemD service config file.</p>"},{"location":"security/keycloak/Install_keycloak/#configuration-directory-for-keycloak","title":"configuration directory for Keycloak","text":"<p>Create a configuration directory for Keycloak under /etc directory by the name keycloak.</p> <pre><code>$ cd /etc/\n$ sudo mkdir keycloak\n</code></pre> <p>The keycloak distribution contains a default config template which locate at <code>/path/to/keycloak/conf/keycloak.conf</code>  We can use it as our start point, so copy it to  <code>/etc/keycloak/</code> and rename it to keycloak.conf</p> <pre><code># in our example, our keycloak path is /opt/keycloak/keycloak-23.0.4\nsudo cp /opt/keycloak/keycloak-23.0.4/conf/keycloak.conf /etc/keycloak/keycloak.conf\n</code></pre>"},{"location":"security/keycloak/Install_keycloak/#create-a-systemd-service-for-keycloak","title":"Create a systemd service for keycloak","text":"<p>If you followed the above tutorial, you should have one keycloak server on mode bare-metal ready to run.</p> <p>To do a test run, you can use the below command.</p> <pre><code>sudo ./bin/kc.sh start --http_server_proxy edge --hostname-strict=false --http-port=8080 --log=file --log-file=/var/log/keycloak/keycloak.log\n</code></pre> <p>You can also create a systemd daemon to better control the keycloak service. </p> <pre><code># Create a file\nsudo vim /etc/systemd/system/keycloak.service\n\n# put the below content\n[Unit]\nDescription=Keycloak Server\nAfter=syslog.target network.target\nWants=network.target\n\n[Service]\nType=notify\nAmbientCapabilities=CAP_SYS_ADMIN\nUser=keycloak\nGroup=keycloak\nEnvironment=JAVA_HOME=/usr/lib/jvm/java-1.17.0-openjdk-amd64\n# this needs to be reviewed in production env\nExecStart=/opt/keycloak/current/bin/kc.sh start --proxy edge --hostname-strict=false --http-port=8080 --log=file --log-file=/var/log/keycloak/keycloak.log\n\n[Install]\nWantedBy=multi-user.target\n</code></pre> <p>You can now control the keycloak daemon with systemd</p> <pre><code>sudo systemctl start/status/stop/restart keycloak\n</code></pre>"},{"location":"security/keycloak/Install_keycloak/#set-a-reverse-proxy","title":"Set a reverse proxy","text":"<p>In this tutorial, I used nginx, you can use other product. Below is a nginx server config example. This works fine with direct grant request. If you use an app to integrate keycloak, you may encounter the  CORS header 'Access-Control-Allow-Origin' missing issue. To resolve this issue, you need to modify the  below config to add <code>Access-Control-Allow-Origin</code> in the http response header. For more details, check</p> <pre><code># set a backend upstream for keycloak server\nupstream keycloak_backend {\n    server 127.0.0.1:8080 fail_timeout=0;\n}\n\nserver {\n  listen 80;\n  server_name keycloak.casd.local;\n\n  # Redirect all traffic to SSL\n  rewrite ^ https://$host$request_uri? permanent;\n}\n\nserver {\n  listen 443 ssl default_server;\n\n  # enables SSLv3/TLSv1, but not SSLv2 which is weak and should no longer be used.\n  ssl_protocols SSLv3 TLSv1 TLSv1.1 TLSv1.2 TLSv1.3;\n\n  # disables all weak ciphers\n  ssl_ciphers ALL:!aNULL:!ADH:!eNULL:!LOW:!EXP:RC4+RSA:+HIGH:+MEDIUM;\n\n  server_name keycloak.casd.local;\n\n  ## Access and error logs.\n  access_log /var/log/nginx/access.log;\n  error_log  /var/log/nginx/error.log info;\n\n  ## Keep alive timeout set to a greater value for SSL/TLS.\n  keepalive_timeout 75 75;\n\n  ## See the keepalive_timeout directive in nginx.conf.\n  ## Server certificate and key.\n  ssl_certificate /opt/keycloak/keycloak-23.0.4/conf/wildcard-casd.pem;\n  ssl_certificate_key /opt/keycloak/keycloak-23.0.4/conf/wildcard-casd.key;\n  ssl_session_timeout  5m;\n\n  ## Strict Transport Security header for enhanced security. See\n  ## http://www.chromium.org/sts. I've set it to 2 hours; set it to\n  ## whichever age you want.\n\n  location / {\n        proxy_set_header Host $host;\n        proxy_set_header X-Forwarded-Host $host;\n        proxy_set_header X-Forwarded-Server $host;\n        proxy_set_header X-Forwarded-Port $mapped_server_port;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n        proxy_pass http://keycloak_backend;\n    }\n\n}\n</code></pre>"},{"location":"security/keycloak/Install_keycloak/#testing-the-keycloak-service","title":"Testing the keycloak service","text":""},{"location":"security/keycloak/Install_keycloak/#set-up-keycloak-client","title":"Set up keycloak client","text":"<ol> <li>Create a new realm(e.g. Data-catalog)</li> <li>Create a client inside the realm which you just created (e.g. open-metadata )</li> <li>In the <code>Capability config/Authentication flow</code> section, select two options <code>standard flow</code>, and <code>direct access grants</code></li> <li>In the <code>Capability config/Client authentication</code> section, enable it. This will set up a password for the <code>open-metadata</code> client</li> <li>Get the password from the <code>credentials</code> Tab.</li> </ol>"},{"location":"security/keycloak/Install_keycloak/#get-an-access-token","title":"Get an access token","text":"<p>This curl command will get a token from the <code>open-metadata</code> client in realm <code>Data-catalog</code>(generated by keycloak server).</p> <pre><code># \ncurl -k -X POST https://keycloak.casd.local/realms/Data-catalog/protocol/openid-connect/token \\\n     -H 'Content-Type: application/x-www-form-urlencoded' \\\n     -H 'Accept: application/json' \\\n     -d 'grant_type=password' \\\n     -d 'client_id=open-metadata' \\\n     -d 'client_secret=HZDISp4LEuLL96ozs6cN2p4HftHKY62P' \\\n     -d 'scope=openid' \\\n     -d 'username=jsnow' \\\n     -d 'password=jsnow'\n</code></pre>"},{"location":"security/keycloak/Install_keycloak/#verify-user-access-token","title":"Verify User access token","text":"<pre><code>curl -k -X GET https://keycloak.casd.local/realms/Data-catalog/protocol/openid-connect/userinfo \\\n     -H 'Content-Type: application/x-www-form-urlencoded' \\\n     -H 'Authorization: Bearer &lt;access-token&gt;'\n</code></pre> <p>If your token is not valid, you will not receive the user info. If everything goes well, you will have the below  response</p> <pre><code>{\n    \"sub\": \"d0618826-8b2f-4853-a216-5b342d2c0452\",\n    \"email_verified\": false,\n    \"name\": \"John Snow\",\n    \"preferred_username\": \"jsnow\",\n    \"given_name\": \"John\",\n    \"family_name\": \"Snow\",\n    \"email\": \"jsnow@casd.local\"\n}\n</code></pre> <p>Below are some useful urls</p> <pre><code># you can get the realm configuration with the below url\nhttps://keycloak.casd.local/realms/Data-catalog/.well-known/openid-configuration\n\n# you can get the token endpoint\nhttps://keycloak.casd.local/realms/examples/protocol/openid-connect/token\n</code></pre>"},{"location":"security/keycloak/Install_keycloak/#use-postman-to-test-the-above-request","title":"Use postman to test the above request","text":"<ol> <li>Create a new collection <code>keycloak API test</code></li> <li>Create a request <code>Get keycloak access token</code>, this will simulate the first curl request</li> <li>In <code>Get keycloak access token</code>, In http method, choose <code>POST</code>, in url, put <code>https://keycloak.casd.local/realms/Data-catalog/protocol/openid-connect/token</code>    In <code>Headers</code>, add two row <code>Content-Type:application/x-www-form-urlencoded</code>, <code>Accept:application/json</code>. In <code>Body</code>,    add the below rows <code>grant_type:password client_id:open-metadata client_secret:changeMe scope:openid username:jsnow password:jsnow</code></li> <li>Copy the access token in the response body</li> <li>Create a new request <code>Verify keycloak access token</code></li> <li>In http method, choose <code>GET</code>, in url, put <code>https://keycloak.casd.local/realms/Data-catalog/protocol/openid-connect/userinfo</code>    In <code>Authorization</code>, in <code>Type</code> choose <code>Bearer token</code>, Copy the access token in Token input line.</li> <li>After sending the request, you should receive the repose with user profile</li> </ol> <p>The default access token is only valid for 5 mins, so it's normal your token is no longer valid after 5 mins. You can  Change this in Keycloak -&gt; realm settings -&gt; token</p>"},{"location":"security/keycloak/Install_keycloak/#troubleshoot","title":"Troubleshoot","text":""},{"location":"security/keycloak/Install_keycloak/#css-loading-issue-after-hosting-keycloak-on-linux-with-nginx-as-proxy-server","title":"CSS loading issue after hosting keycloak on linux with nginx as proxy server","text":"<p>https://github.com/keycloak/keycloak/issues/12719</p>"},{"location":"security/keycloak/Install_keycloak/#cors-header-access-control-allow-origin-missing","title":"CORS header 'Access-Control-Allow-Origin' missing","text":"<p>You can find more info about this issue here: https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS/Errors/CORSMissingAllowOrigin</p> <p>You can also check this page https://www.stackhawk.com/blog/react-cors-guide-what-it-is-and-how-to-enable-it/</p> <p>The response to the CORS request is missing the required Access-Control-Allow-Origin header, which is used to determine  whether the resource can be accessed by content operating within the current origin.</p> <p>To correct this issue, you need to add the appropriate <code>Access-Control-Allow-Origin</code> values into the HTTP header.</p> <p>In this tutorial, we used the nginx as our reverse proxy. The below lines show a possible config for nginx. The idea is the nginx server checks the <code>origin value of the http request header</code>. Base on this value, it will set  the <code>Access-Control-Allow-Origin</code> on the http response header.</p> <pre><code># set default values for the cors values \n  set $cors_origin \"\";\n  set $cors_cred   true;\n  set $cors_header \"Content-Type\";\n  set $cors_method \"POST, GET\";\n\n# if requests comes from the allowed domain or subdomain, we assign certain core values \n# nginx create variables for http header, for example the origin header has the equivalent variable $http_origin in nginx \n  if ($http_origin ~* (https?://.*\\.mckinsey\\.com(:[0-9]+)?$)) {\n            set $cors_origin $http_origin;\n            set $cors_cred   true;\n            set $cors_header $http_access_control_request_headers;\n            set $cors_method $http_access_control_request_method;\n  }\n\n# if request comes from null origin, we set another group of core values\n if ($http_origin ~ 'null') {\n            set $cors_origin \"null\";\n            set $cors_cred   true;\n            set $cors_header $http_access_control_request_headers;\n            set $cors_method $http_access_control_request_method;\n  }\n\n# add header to the Http response\n  add_header Access-Control-Allow-Origin      $cors_origin;\n  add_header Access-Control-Allow-Credentials $cors_cred;\n  add_header Access-Control-Allow-Headers     $cors_header;\n  add_header Access-Control-Allow-Methods     $cors_method;\n\n  location / {\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header Host $http_host;\n        proxy_pass http://keycloak_backend;\n    }\n</code></pre>"},{"location":"security/keycloak/Install_keycloak/#bash-script-to-test-authorization-code-grant-of-keycloak","title":"Bash script to test Authorization Code grant of Keycloak","text":"<p>This following script expects <code>KEYCLOAK_URL</code>, <code>REDIRECT_URL</code> (it is the client application URL, in this case  it can be any URL), <code>REALM</code> (Keycloak realm), <code>CLIENTID</code> (client application created in Keycloak) and the <code>USERNAME</code>.</p> <pre><code>#!/bin/bash\n\n# This script will perform the following steps:\n#\n# 1. Initialize variables and functions.\n# 2. Prompt for the user's password.\n# 3. Obtain the authentication URL from Keycloak.\n# 4. Send username and password to Keycloak to receive a code URL.\n# 5. Extract the code from the received URL.\n# 6. Send the code to Keycloak to receive the Access Token.\n# 7. Decode and display the Access Token.\n# 8. Clean up the cookie file used for authentication.\n\n# Initialize variables\ninit() {\n    KEYCLOAK_URL=\"https://keycloak.casd.local\"\n    REDIRECT_URL=\"http://localhost:8080\"\n    USERNAME=\"jsnow\"\n    REALM=\"Data-catalog\"\n    CLIENTID=\"open-metadata\"\n}\n\n# Function to decode the access token\ndecode() {\n    jq -R 'split(\".\") | .[1] | @base64d | fromjson' &lt;&lt;&lt; \"$1\"\n}\n\n# Prompt for password\nread -rp \"Password: \" -s PASSWORD\necho \" \"\n\n# Initialize\ninit\n\n# Cookie file path\nCOOKIE=\"$(pwd)/cookie.jar\"\n\n# Step 1: Obtain the authentication URL\nAUTHENTICATE_URL=$(curl -sSL --get --cookie \"$COOKIE\" --cookie-jar \"$COOKIE\" \\\n    --data-urlencode \"client_id=${CLIENTID}\" \\\n    --data-urlencode \"redirect_uri=${REDIRECT_URL}\" \\\n    --data-urlencode \"scope=openid\" \\\n    --data-urlencode \"response_type=code\" \\\n    \"$KEYCLOAK_URL/realms/$REALM/protocol/openid-connect/auth\" | pup \"form#kc-form-login attr{action}\")\n\n# Convert &amp;amp; to &amp;\nAUTHENTICATE_URL=$(echo \"$AUTHENTICATE_URL\" | sed -e 's/\\&amp;amp;/\\&amp;/g')\n\necho \"Sending Username Password to the following authentication URL of Keycloak: $AUTHENTICATE_URL\"\necho \" \"\n\n# Step 2: Obtain the code URL\nCODE_URL=$(curl -sS --cookie \"$COOKIE\" --cookie-jar \"$COOKIE\" \\\n    --data-urlencode \"username=$USERNAME\" \\\n    --data-urlencode \"password=$PASSWORD\" \\\n    --write-out \"%{REDIRECT_URL}\" \\\n    \"$AUTHENTICATE_URL\")\n\necho \"Following URL with code received from Keycloak: $CODE_URL\"\necho \" \"\n\n# Extract code from URL\ncode=$(echo \"$CODE_URL\" | awk -F \"code=\" '{print $2}' | awk '{print $1}')\n\necho \"Extracted code: $code\"\necho \" \"\n\necho \"Sending code=$code to Keycloak to receive Access token\"\necho \" \"\n\n# Step 3: Obtain the Access Token\nACCESS_TOKEN=$(curl -sS --cookie \"$COOKIE\" --cookie-jar \"$COOKIE\" \\\n    --data-urlencode \"client_id=$CLIENTID\" \\\n    --data-urlencode \"redirect_uri=$REDIRECT_URL\" \\\n    --data-urlencode \"code=$code\" \\\n    --data-urlencode \"grant_type=authorization_code\" \\\n    \"$KEYCLOAK_URL/realms/$REALM/protocol/openid-connect/token\" | jq -r \".access_token\")\n\necho \" \"\n\n# Print decoded Access Token\necho \"Decoded Access Token: \"\ndecode \"$ACCESS_TOKEN\"\n\n# Clean up the cookie file\nrm \"$COOKIE\"\n</code></pre> <p>you can find the above bash script in ./src/keycloak/keycloak_auth_code.bash</p>"},{"location":"security/ldap/01.install_ldap/","title":"Install openldap server on debian 11/10","text":""},{"location":"security/ldap/01.install_ldap/#1-prepare-the-server","title":"1. Prepare the server","text":"<p>Before installing the ldap server, you need to prepare it.</p>"},{"location":"security/ldap/01.install_ldap/#11-configure-fqdn-hostname-for-your-server","title":"1.1  Configure FQDN hostname for your server","text":"<p>You need to create a FQDN hostname and add a record to file/etc/hosts.</p> <pre><code>sudo vim /etc/hosts\n10.50.5.57 ldap.casd.local\n\n# Configure hostname\nsudo hostnamectl set-hostname ldap.casd.local --static\n</code></pre>"},{"location":"security/ldap/01.install_ldap/#12-update-the-server","title":"1.2 Update the server","text":"<pre><code># fix the hashicorp repo key\ncurl -fsSL https://apt.releases.hashicorp.com/gpg | sudo gpg --yes --dearmor -o /usr/share/keyrings/hashicorp-archive-keyring.gpg\n\n echo \"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] https://apt.releases.hashicorp.com $(lsb_release -cs) main\" | sudo tee /etc/apt/sources.list.d/hashicorp.list &gt; /dev/null\n\nsudo apt -y update &amp;&amp; sudo apt -y upgrade\nsudo reboot\n</code></pre>"},{"location":"security/ldap/01.install_ldap/#2-install-the-openldap-package","title":"2. Install the openldap package","text":"<pre><code>sudo apt -y install slapd ldap-utils\n</code></pre> <ul> <li><code>slapd</code>: is the openldap server.</li> <li><code>ldap-utils</code>: is the ldap cli.</li> </ul> <p>After the above command, you will be prompted to enter the admin password for your LDAP directory</p> <p>The base dn of the ldap server will be generated base on your FQDN hostname. So if your fqdn is not right, don't continue just restart from step 1.</p>"},{"location":"security/ldap/01.install_ldap/#3-set-up-the-base-structure","title":"3. Set up the base structure","text":"<p>You can consider the ldap server as a database of your users and groups. To better organise them, we need to create some basic structures.</p>"},{"location":"security/ldap/01.install_ldap/#31-create-olc-admin-account","title":"3.1 Create olc admin account","text":"<p>Openldap has two admin accounts, the installation guide will help you to set up the <code>front-end</code> admin account(e.g. cn=admin, dc=casd, dc=loacl). There is a backend admin account <code>cn=admin,cn=config</code> which allows you to access the <code>ldap olc</code>(cn=config).</p> <pre><code># sudo su become root user\n# show the content of cn=config\nldapsearch -Y EXTERNAL -H ldapi:/// -b cn=config\n</code></pre> <p>Normally the <code>olcRootDN</code> entry is already created by default, all you need to do is to modify the <code>olcRootPW</code> You can use <code>slappasswd</code> to generate the ssha of your password.</p> <pre><code># we name this conf file as change_pwd_config.ldif\ndn: olcDatabase={0}config,cn=config\nchangetype: modify\nadd: olcRootPW\nolcRootPW: {SSHA}33aeJH8tsp6+NxNg9LIK9VjUtmhYTOnV\n</code></pre> <pre><code>ldapmodify -Y EXTERNAL -H ldapi:/// -f change_pwd_config.ldif\n</code></pre> <pre><code># we name this file as create_account_config.ldif\ndn: olcDatabase={0}config,cn=config\nchangetype: modify\nadd: olcRootDN\nolcRootDN: cn=admin,cn=config\n\ndn: olcDatabase={0}config,cn=config\nchangetype: modify\nadd: olcRootPW\nolcRootPW: {SSHA}33aeJH8tsp6+NxNg9LIK9VjUtmhYTOnV\n</code></pre> <pre><code>ldapadd -Y EXTERNAL -H ldapi:/// -f create_account_config.ldif\n</code></pre> <p>to access cn=config in <code>Apache Directory Studio</code>, the login will be <code>cn=admin,cn=config</code>, the password is the password in olcRootPW, the root tree will be <code>cn=config</code>. </p>"},{"location":"security/ldap/01.install_ldap/#32-enable-ldaps","title":"3.2 Enable ldaps","text":"<p>To set up ldaps, you need three files:   1. CA certificate (location: /etc/ssl/certs/mycacert.pem)   2. service certificate for ldap signed by CA certificate (location: /etc/ldap/ldap_cert.pem)   3. private key of the service certificate (location: /etc/ldap/ldap_pri_key.pem)</p> <p>you need to add the below config into <code>cn=config</code></p> <pre><code># certinfo.ldif\ndn: cn=config\nadd: olcTLSCACertificateFile\nolcTLSCACertificateFile: /etc/ssl/certs/mycacert.pem\n-\nadd: olcTLSCertificateFile\nolcTLSCertificateFile: /etc/ldap/ldap_cert.pem\n-\nadd: olcTLSCertificateKeyFile\nolcTLSCertificateKeyFile: /etc/ldap/ldap_pri_key.pem\n</code></pre> <pre><code>sudo ldapmodify -Y EXTERNAL -H ldapi:/// -f certinfo.ldif\n</code></pre> <p>To use LDAPS (LDAP over SSL), then you need to edit /etc/default/slapd and include <code>ldaps:///</code> in SLAPD_SERVICES like below:</p> <pre><code># open file\nsudo vim /etc/default/slapd\n\n# find the below line and add ldaps as authorized protocol\nSLAPD_SERVICES=\"ldap:/// ldapi:/// ldaps:///\"\n</code></pre> <pre><code># restart slapd\nsudo systemctl restart slapd\n\n# test the ldaps\nldapwhoami -x -H ldaps://ldap.casd.local\n</code></pre> <p>To use apache directory studio, in the network tab, you need to change the port to 636, and encryption method to ldaps.</p>"},{"location":"security/ldap/01.install_ldap/#33-add-some-basic-structure","title":"3.3 Add some basic structure","text":"<p>Below is an example, you can set up something more complex</p> <pre><code>dn: ou=people,dc=casd,dc=local\nobjectClass: organizationalUnit\nou: people\n\ndn: ou=groups,dc=casd,dc=local\nobjectClass: organizationalUnit\nou: groups\n</code></pre> <p>Load the above entry to the ldap server</p> <pre><code>sudo ldapadd -x -D cn=admin,dc=casd,dc=local -W -f basedn.ldif\n</code></pre>"},{"location":"security/ldap/01.install_ldap/#4-add-sample-user-account-and-group","title":"4. Add sample user account and group","text":""},{"location":"security/ldap/01.install_ldap/#41-add-a-new-user-account","title":"4.1 Add a new user account","text":"<ol> <li>Create a password hash for the user account</li> </ol> <pre><code>sudo slappasswd\nNew password:\nRe-enter new password:\n{SSHA}vjbMsVOMBOyB2/oZ1tiFGptF/ArMGwGH\n</code></pre> <ol> <li>Create a <code>user.ldif</code> file</li> </ol> <pre><code>dn: uid=pliuT,ou=people,dc=casd,dc=local\nobjectClass: inetOrgPerson\nobjectClass: posixAccount\nobjectClass: shadowAccount\ncn: Pengfei\nsn: Liu\nuserPassword: {SSHA}vjbMsVOMBOyB2/oZ1tiFGptF/ArMGwGH\nloginShell: /bin/bash\nhomeDirectory: /home/users/pliu\nuidNumber: 3000\ngidNumber: 3000\n</code></pre> <ol> <li>Add it to the ldap server</li> </ol> <pre><code>sudo ldapadd -x -D cn=admin,dc=casd,dc=local -W -f user.ldif\n</code></pre>"},{"location":"security/ldap/01.install_ldap/#42-add-a-new-group","title":"4.2 Add a new group","text":"<ol> <li>Create a <code>group.ldif</code></li> </ol> <pre><code>dn: cn=developers,ou=groups,dc=casd,dc=local\nobjectClass: posixGroup\ncn: developers\ngidNumber: 3000\nmemberUid: pliuT\n</code></pre> <ol> <li>Add it to the ldap server</li> </ol> <pre><code>sudo ldapadd -x -D cn=admin,dc=casd,dc=local -W -f group.ldif\n</code></pre>"},{"location":"security/ldap/01.install_ldap/#5-install-a-ldap-client","title":"5. Install a ldap client","text":"<p>We already have a ldap client in CLI which you can use after installing <code>ldap-utils</code>.</p> <pre><code>ldapsearch -x -LLL -b dc=casd,dc=local '(uid=pengfei)' cn gidNumber\n\n# sample output\ndn: uid=pengfei,ou=people,dc=casd,dc=local\ngidNumber: 4000\ncn: pengfei\n</code></pre>"},{"location":"security/ldap/01.install_ldap/#51-ldap-client-with-gui","title":"5.1 Ldap client with GUI","text":"<p>We have many choices for advance ldap client with GUI. But I recommend <code>Apache Directory Studio</code>.</p> <p>After download, unzip it and run the command <code>./ApacheDirectoryStudio</code></p> <p>Inside the GUI, create a new <code>ldap connection</code>, enter the server host name and port.</p> <p>Then enter the admin acount and password e.g. <code>cn=admin,dc=casd,dc=local</code>.</p> <p>If everything works well, you should see the content of the ldap server.</p>"},{"location":"security/ldap/01.install_ldap/#6-enable-saslgssapi-in-openldap","title":"6. Enable SASL/GSSAPI in openldap","text":"<p>GSSAPI (Generic Security Services API) allows OpenLDAP to authenticate users using Kerberos instead of  <code>simple binds with passwords</code>. This is commonly used in <code>Active Directory (AD) or MIT Kerberos</code> environments.</p> <p>To complete this config, you must have one kerberos server(kdc) up and running. Here, we suppose the kerberos server is running on a server with url such as <code>krb.casd.local</code> with a REALM called <code>CASD.LOCAL</code>.</p> <p>the realm name is case-sensitive, by convention, it should be all in upper-case. </p>"},{"location":"security/ldap/01.install_ldap/#61-install-required-packages","title":"6.1 Install required packages","text":"<pre><code>sudo apt update\nsudo apt install krb5-user libsasl2-modules-gssapi-mit\n</code></pre> <p>krb5-user: kerberos client which allows user to do kinit, klist, kdestroy libsasl2-modules-gssapi-mit:  SASL GSSAPI module for OpenLDAP to allow user kerberos ticket bind.</p>"},{"location":"security/ldap/01.install_ldap/#62-configure-kerberos-authentication","title":"6.2 Configure Kerberos Authentication","text":"<p>The kerberos client authentication config is located at <code>/etc/krb5.conf</code>. Below is an example of the basic config of the kerberos client.</p> <pre><code>[libdefaults]\n    default_realm = CASD.LOCAL\n        dns_lookup_realm = false\n        dns_lookup_kdc = true\n        ticket_lifetime = 24h\n        renew_lifetime = 7d\n        forwardable = true\n# The following krb5.conf variables are only for MIT Kerberos.\n        kdc_timesync = 1\n        ccache_type = 4\n        forwardable = true\n        proxiable = true\n\n\n[realms]\n    CASD.LOCAL = {\n        kdc = krb.casd.local\n        admin_server = krb.casd.local\n    }\n\n[domain_realm]\n       casd.local = CASD.LOCAL\n       .casd.local = .CASD.LOCAL\n</code></pre> <p>With the above conf, you should be able to test the connectivity of the kerberos client.</p> <pre><code># obtain a krb ticket from the kdc\nkinit &lt;user-principal&gt;\n\n# for example\nkinit pengfei@CASD.LOCAL\n\n# show the ticket\nklist\n\n# destroy the cached ticket\nkdestroy\n</code></pre>"},{"location":"security/ldap/01.install_ldap/#63-c","title":"6.3 C","text":""}]}