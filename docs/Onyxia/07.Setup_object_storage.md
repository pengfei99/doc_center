# 7. Setup Object storage

The Onyxia uses object storage to store data outside a pod (unlike block storage for pod disk attachement).

In this doc, we will deploy a MinIO cluster as the object storage.



## 7.2 Deploy minio cluster via helm chart

In k8s, MinIO is deployed with two layers:

- The [MinIO Operator](https://github.com/minio/operator/tree/master/helm/operator), which orchestrates and deploys one or multiple MinIO Tenants;
- The [MinIO Tenant](https://github.com/minio/operator/tree/master/helm/tenant), an isolated instance of object storage.

While the orchestrator provides common resources, the Tenant hosts the actual object storage instance. It also hosts the services for the object storage API and the web console.

As the MinIO Operator is fit for Kubernetes deployments and multi-tenancy, we chose to use it. We also chose to install the MinIO Operator through Helm, as it helps centralize the configuration.

To sum things up, the MinIO installation process goes as follows:

- [Deploying the MinIO Operator through Helm](/en/datalab/datalab-install/minio/minio-operator);
- [Deploying the MinIO Tenant through Helm](/en/datalab/datalab-install/minio/minio-tenant).


Disks need to be formatted beforehand. This is done by [deploying and using DirectPV](/en/datalab/datalab-install/object-storage/directpv).

## 7.3 Prerequisites

### 7.3.1 K8s version
For minio v4.0.0+, the Kubernetes infrastructure and the kubectl CLI tool must have the version of 1.19.0+.

**You need to have the necessary access to the cluster (cluster admin)** to complete below commands

### 7.3.2 k8s TLS certificate API

The MinIO Operator automatically generates TLS Certificate Signing Requests (CSR) and uses the Kubernetes `certificates.k8s.io` TLS certificate management API to create signed TLS certificates.

The MinIO Operator therefore requires that the Kubernetes **kube-controller-manager** configuration include the following configuration settings:

1. `--cluster-signing-key-file` - Specify the PEM-encoded RSA or ECDSA private key used to sign cluster-scoped certificates.

2. `--cluster-signing-cert-file` - Specify the PEM-encoded x.509 Certificate Authority certificate used to issue cluster-scoped certificates.

**The Operator cannot complete initialization if the k8s cluster is not configured to respond to a generated CSR.**

To verify whether the kube-controller-manager has the required settings, use the following command. Replace $CLUSTER-NAME with the name of the Kubernetes cluster:

```shell
kubectl get pod kube-controller-manager-$CLUSTERNAME -n kube-system -o yaml

# for example controlplane1
kubectl get pod kube-controller-manager-controlplane1 -n kube-system -o yaml
```

The output should contain below two lines:

```yaml
spec:
 containers:
 - command:
     - kube-controller-manager
     - ...
     - --cluster-signing-cert-file=/etc/kubernetes/pki/ca.crt
     - --cluster-signing-key-file=/etc/kubernetes/pki/ca.key
```
### 7.3.3 Install the MinIO Kubernetes Plugin

The `MinIO Kubernetes Plugin` provides a command for initializing the MinIO Operator.

**Krew** is a kubectl plugin manager developed by the `Kubernetes SIG CLI` group. 

Use below command to install Krew (must have git and kubectl)
```bash
# Step1 : Install Krew binary
(
  set -x; cd "$(mktemp -d)" &&
  OS="$(uname | tr '[:upper:]' '[:lower:]')" &&
  ARCH="$(uname -m | sed -e 's/x86_64/amd64/' -e 's/\(arm\)\(64\)\?.*/\1\2/' -e 's/aarch64$/arm64/')" &&
  KREW="krew-${OS}_${ARCH}" &&
  curl -fsSLO "https://github.com/kubernetes-sigs/krew/releases/latest/download/${KREW}.tar.gz" &&
  tar zxvf "${KREW}.tar.gz" &&
  ./"${KREW}" install krew
)
# Step2 : Add Krew to PATH
export PATH="${KREW_ROOT:-$HOME/.krew}/bin:$PATH"

# Step3 : Verify that Krew's install is successful by updating the plugin index
kubectl krew update
```

For more details, please read the [krew installation documentation](https://krew.sigs.k8s.io/docs/user-guide/setup/install/) for installation.

## 7.4 Formatting disks with DirectPV

A `StorageClass` needs to be prepared to provision the PVCs generated by the MinIO Operator when deploying a Tenant.

[DirectPV](https://github.com/minio/directpv) is a `CSI driver` developed by the MinIO team. At the most basic level, it is a distributed persistent volume manager, and not a storage system like SAN or NAS. DirectPV is used to discover, format, mount, schedule and monitor hard drives across servers.

For more details about directPV, please visit this [page](https://blog.min.io/introducing-directpv/)

**Befor you formatting disk, make sure you get the hard drive name right.**
In Below example, 
- `sda` is the system disk.
- `sdb` is the hard drive formated by ceph cluster
- `sdc` is not used.

So you can only format `sdc` in this worker. If you format other disk, you will destroy other service's data.

```shell
pliu@worker1:~$ lsblk -f
NAME   FSTYPE         FSVER LABEL UUID                                 FSAVAIL FSUSE% MOUNTPOINT
sda
├─sda1 vfat           FAT32       B052-39EE                             507.6M     1% /boot/efi
└─sda2 ext4           1.0         7bbbaa47-535d-4e32-968d-ea078a0dd460   99.6G    14% /
sdb    ceph_bluestore
sdc

```
### 7.4.1 Installing DirectPV

Install directPV. Tolerations and selectors are needed to target the object storage nodes and drives:

```bash
# Step 1: install DirectPV
kubectl krew install directpv

# Step 2: setup node-selector and tolerations on directpv deployment
kubectl directpv install --node-selector 'storage-node=true' --tolerations 'storage-node=true:NoSchedule'
```
The above command will create a new `namespace` called **direct-csi-min-io**. You should see below pods created in this namespace

```bash
kubectl get pods -n direct-csi-min-io
NAME                                 READY   STATUS    RESTARTS   AGE
direct-csi-min-io-69947d45bb-2cpr4   2/2     Running   0          92s
direct-csi-min-io-69947d45bb-8f5sh   2/2     Running   0          92s
direct-csi-min-io-69947d45bb-989gb   2/2     Running   0          92s

```
Now lets run below command
```bash
kubectl directpv drives ls --all

# The output
 DRIVE  CAPACITY  ALLOCATED  FILESYSTEM  VOLUMES  NODE  ACCESS-TIER  STATUS
```
The output is empty, because we have not labeled the workers with `storage-node=true`

Below command will label the worker

```bash
kubectl label node worker1 storage-node=true
kubectl label node worker2 storage-node=true
```

Now re-run below command:

```bash
kubectl directpv drives ls


 DRIVE     CAPACITY  ALLOCATED  FILESYSTEM      VOLUMES  NODE     ACCESS-TIER  STATUS
 /dev/sdb  512 GiB   -          ceph_bluestore  -        worker1  -            Available
 /dev/sdc  512 GiB   -          -               -        worker1  -            Available
 /dev/sdb  512 GiB   -          ceph_bluestore  -        worker2  -            Available
 /dev/sdc  512 GiB   -          -               -        worker2  -            Available

```

This time you can see, it detects 4 possible hard drive. As we explained before, `/dev/sdb` is reserved for ceph cluster. So we can only use `/dev/sdc`

### 7.4.2 Formatting disks

Select the drives to be formatted and managed by DirectPV. In our case, the following command selects the right disks:

```bash
# format the target disk
kubectl directpv drives format --drives "/dev/sdc"

# get the hard drives list
 kubectl directpv drives ls

# now you can see the status of /dev/sdc is ready. 
 DRIVE     CAPACITY  ALLOCATED  FILESYSTEM      VOLUMES  NODE     ACCESS-TIER  STATUS
 /dev/sdb  512 GiB   -          ceph_bluestore  -        worker1  -            Available
 /dev/sdc  512 GiB   -          xfs             -        worker1  -            Ready
 /dev/sdb  512 GiB   -          ceph_bluestore  -        worker2  -            Available
 /dev/sdc  512 GiB   -          xfs             -        worker2  -            Ready

```

The hard drives which have status `Ready` can now be automatically used for PVs and PVCs with MinIO.

## 7.5 Install minio operator

The **MinIO Operator** installs a `Custom Resource Document (CRD)` to support describing `MinIO tenants` as a Kubernetes object. See the MinIO Operator [CRD Reference](https://github.com/minio/operator/blob/master/docs/crd.adoc) for complete documentation on the MinIO CRD.

Run below command to install a minio k8s operator.

```shell
# update the plugin list
kubectl krew updata

# install the minio plugin
kubectl krew install minio

# check minio plugin version
kubectl minio version

# try to get all service in name space minio-operator
kubectl get pods -n minio-operator
NAME                              READY   STATUS    RESTARTS   AGE
console-c4cd64b8c-zvp2d           1/1     Running   0          16h
minio-operator-7d59b88ffb-4bsg6   1/1     Running   0          16h
minio-operator-7d59b88ffb-c9p69   1/1     Running   0          16h

```

If you want to custom the configuration, you can edit a `values.yaml`. The official example can be found [here](https://github.com/minio/operator/blob/master/helm/operator/values.yaml)


Below `operator-values.yaml` is a simple configuration example:

```yaml
# Selector and tolerations to deploy the Operator console on storage nodes
nodeSelector:
  storage-node: "true"
tolerations:
  - key: "storage-node"
    operator: "Equal"
    value: "true"
    effect: "NoSchedule"

# Exposing the console through an Ingress
console:
  ingress:
    enabled: true
    ingressClassName: "nginx"
    labels: { }
    annotations:
      # The following annotation is required to let MinIO communicate with the NGINX Ingress controller
      # when using external certificates. See Knowledge base: 8dc2998d-5699-4be6-bed0-b2384a87fe9e
      nginx.ingress.kubernetes.io/backend-protocol: "HTTPS"
      nginx.ingress.kubernetes.io/proxy-body-size: "0"
    tls:
      - hosts:
          - minio-operator-console.casd.local
    host: minio-operator-console.casd.local
    path: /
    pathType: Prefix
```
### 7.5.1 Minio Operator console

Minio operator provides a console (web GUI), you can use below command to temporarily forward traffic from the MinIO Operator Console service to your local machine:

```yaml
# this will return an access token which allows you to login to the web page
kubectl minio proxy
```

> By default, the operator console does not enable ingress. So if you want to have ingress, you need to enable it with above config.



You can follow this [tutorial](https://min.io/docs/minio/kubernetes/upstream/operations/install-deploy-manage/deploy-minio-tenant.html#minio-k8s-deploy-minio-tenant) to creat a minio tenant by using minio proxy. 


## 7.6 Install minio tenant

The `MinIO Tenant` is what supports the actual object storage instance. A MinIO Tenant deploys `multiple pool pods` on `storage nodes`, as well as the `REST API service` to contact the object storage and the `console service` to access its web UI.

In the above section, we used the `minio proxy` to deploy a minio tenant. But `GUI` configuration is hard to document. So we will use the classic helm chart to deploy a `minio tenant`.  

You can find the official default minio tenant config [values.yaml](https://github.com/minio/operator/blob/master/helm/tenant/values.yaml)

Below command use the MinIO Tenant Helm Chart and a configuration file [tenant-values.yaml](../resources/minio/k8s/tenant-values.yaml):

```bash
helm repo add minio https://operator.min.io/

# install helm chart
helm install minio --namespace casd-minio minio/tenant --values tenant-values.yaml

# update helm chart
helm upgrade minio minio/tenant -n casd-minio --values tenant-values.yaml 
```

> The MinIO Operator must be installed and running correctlly.

### 7.6.1 TLS SSL certificate configuration

With the above configuration, the helm chart will generate a `certificate` and `private key`. They are stored in a `secret`, which has name such as `<tenant-name>-tls`, in our case, it will be `casd-minio-tls`.

The content of the secert looks like below

```yaml
apiVersion: v1
kind: Secret
metadata:
 name: casd-minio-tls
 namespace: casd-minio
data:
 public.crt: LS0tLS1CRUdJTiBD...
 private.key: LS0tLS1CRUdJTiB...
```
This secret will be mounted as a volume callded `casd-minio-tls` on `/tmp/certs` on each pod(e.g. casd-minio-pool-0-0) of the minio tenant. 

The default minio setting is to put certs under `${user-home-who-run-minio}/.minio/certs`.
But the above helm chart will mount it under `/tmp/certs`

The content of certs folder

```shell
ls certs

# The public.crt is the certificate from the secert
# The private.key is the private key from the secert
# CAs folder host the root CA certificate which signes the certifcate
# By default it assume it's a autosigned, so it just put the public.crt in CAs.
CAs  private.key  public.crt

```

The official doc says that we could use


#### The work around

If you want to use a custom certificate, you need to overwrite the **secret casd-minio**. You need to replace the public.crt and private.key with your own certificate and private key in the `casd-minio-tls` secret. 



### 7.6.2 SSO (Keycloak) configuration

Minio support other OIDC sources, in this tutorial we only focus on the `Keycloak` configuration.
For minio to use keycloak, we need to do two things:

- Create a minio auth client in Keycloak (with policy claim)
- Configure minio to use the Keycloak auth client for authentication

#### 7.6.2.1 Create minio auth client in Keycloak

The official doc of [Keycloak configuration for minio](https://github.com/minio/minio/blob/master/docs/sts/keycloak.md) is not very useful for us, because we will use onyxia to connect to minio. 

##### Step 1 Create a new auth client for minio

1. To create a new auth **client**, you need to log in to keycloak admin console
2. Choose a realm (it's better to put it in the same realm of onyxia auth client)
3. Click on `Clients` (on the left side panel), then click on `create` (right side panel, on top of client list)
4. In `Client ID`, you put the name of this auth client. In our case we use `minio`. In `Root URL`, you put the url of the service which will use this auth client. In our case, it's `https://minio-console.casd.local`. Then click on `save`.

5. Now, you should see a larger form to fill. You need to pay attentions to 
  - Root URL: `https://minio-console.casd.local`
  - Valid Redirect URIs: `http://minio-console.casd.local/*` | `https://minio-console.casd.local/*`
  - Web-origins: `http://minio-console.casd.local`   | `https://minio-console.casd.local`
  Don't forget to change the `Access Type` from `public` to `confidential`. After this, you should see a new tab `Credentials`, in it you will find the `secret` to access this auth client.
6. In `advanced settings`, you can change the `access token lifespan`. 

Below figure is an example
![keycloak-minio-client.PNG](../images/keycloak-minio-client.PNG)

##### Step 2 Create a policy claim

To make the generated token to contain minio access policy. You need to create a **mapper** inside the minio's auth client which you just created

1. To create a new `mapper`, click on the minio auth client. On the right panel, click on `Mappers` (on top). Then click on `create`, it will popup a form which you need to fill.
2. Name: `policy`;   Mapper Type: `Hardcoded claim`; Token Claim Name: `policy`; Claim value: `stsonly`
3. `Add to ID Token` need to be `Enabled`     
4. Click on `save`. 

Below figure is an example
![keycloak-minio-client-claim-policy.PNG](../images/keycloak-minio-client-claim-policy.PNG)

> Note, this claim requires the minio server contains a policy named `stsonly`. We will show you how in below section.

#### 7.6.2.2 Configure minio to use the Keycloak

To enable oidc auth in minio, you need to modify below env var of the minio server.

```yaml
 Tenant:
  #...
  #... 
  env:
     # keycloak url realms name=casd-onyxia
    - name: MINIO_IDENTITY_OPENID_CONFIG_URL
      value: "https://auth.casd.local/auth/realms/casd-onyxia/.well-known/openid-configuration"
      # keycloak auth client id for minio
    - name: MINIO_IDENTITY_OPENID_CLIENT_ID
      value: "minio"
      # secret of the auth client(if it's confidential)
    - name: MINIO_IDENTITY_OPENID_CLIENT_SECRET
      value: "changeMe"
      # Token Claim Name
    - name: MINIO_IDENTITY_OPENID_CLAIM_NAME
      value: "policy"
    - name: MINIO_IDENTITY_OPENID_REDIRECT_URI
      value: "https://minio-console.casd.local/oauth_callback"
    - name: MINIO_IDENTITY_OPENID_SCOPES
      value: "openid, profile, email, roles"
    - name: MINIO_DOMAIN
      value: "minio.casd.local"
    - name: MINIO_BROWSER
      value: "on" # to turn-off browser
      # minio consol url
    - name: MINIO_BROWSER_REDIRECT_URL
      value: "https://minio-console.casd.local"
      # minio api url
    - name: MINIO_SERVER_URL
      value: "https://minio.casd.local"
```

### 7.6.3 Details on minio tenant configuration

In this tutorial, we only show the details on `certificate and SSO` configuration. For other configuration, you can visit [sys_admin/12.Minio_installation_details.md](./sys_admin/12.Minio_installation_details.md).



You can get a baseline of the configuration file by downloading the MinIO Tenant's Helm Chart repository's [default configuration file](https://github.com/minio/operator/blob/master/helm/tenant/values.yaml). Name the file `tenant-values.yaml`:


> Note that the Datalab cluster provides an already-prepared [file](https://github.com/InseeFrLab/paris-sspcloud/tree/master/apps/minio-datanode) for the Helm chart.


## 7.7 Minio client

### 7.7.1 The minio web console
If you have ingress configured, you should be able to access the minio web console via the configured [url (e.g. https://minio-console.casd.local)](https://minio-console.casd.local/).

### 7.7.2 The minio CLI

Minio also provide a command line client.

#### Install 
Download the `mc client` and install it to a location on your system PATH such as `/usr/local/bin`.

```shell
# get the minio client bin
wget https://dl.min.io/client/mc/release/linux-amd64/mc

# grant execution right
chmod +x mc

# move it to local bin
sudo mv mc /usr/local/bin/mc
```

#### Set server connection alias

Use `mc alias set` to create a new alias associated to your minio deployment. You can run `mc` commands against this alias:

```shell
# general form
mc alias set <alias-name> <cluster-url> <Access-key> <Secret-key>

# below is an example
mc alias set test https://minio-test.casd.local:9000 minio mypasswd

# check the alias status, this only works if you have admin rights
mc admin info test
```

#### Use minio client

The use of minio client can be divided in two parts.
- minio client: the official doc can be found [here](https://min.io/docs/minio/linux/reference/minio-mc.html)
- minioa admin client: the official doc can be found [here](https://min.io/docs/minio/linux/reference/minio-mc-admin.html)



##### Use minio admin client to add access control policy
Onyxia currently uses a basic `userid` <> `bucketid` permissions system. Basically each user has access to the bucket with the id equals to it's `userid`. Below `stsonly.json` file is an example of such policy.

The policy is stored inside a json file. 
```json
{
    "Version": "2012-10-17",
    "Statement": [
     {
      "Effect": "Allow",
      "Action": [
       "s3:*"
      ],
      "Resource": [
       "arn:aws:s3:::${jwt:preferred_username}",
       "arn:aws:s3:::${jwt:preferred_username}/*"
      ]
     }
    ]
}
```

To apply the above policy, you can use below command

```shell
# use mc admin to create a policy, the keycloak claim will use this policy to generate jwt token
# with appropriate access rights. Below is a general form
mc admin policy add <cluster-alias-name> <policy-name> <rule-file-name>

# below is an example, note the name of the policy is `stsonly`, the keycloak claim value
# must have exactly the same value 
mc admin policy add s3 stsonly stsonly.json
```

If successful, you should be able to login to the minio console and create the bucket that has the same name as your user id.

Onyxia currently supports `id_token` but not `access_token`. This parameter is located in the `identity_openid` object as `claim_userinfo`.

```bash
mc admin config get s3 identity_openid

# you should see below output
# MINIO_IDENTITY_OPENID_CONFIG_URL=https://auth.casd.local/auth/realms/casd-onyxia/.well-known/openid-configuration
# MINIO_IDENTITY_OPENID_CLIENT_ID=minio
# MINIO_IDENTITY_OPENID_CLIENT_SECRET=changeMe
# MINIO_IDENTITY_OPENID_CLAIM_NAME=policy
# MINIO_IDENTITY_OPENID_REDIRECT_URI=https://minio-console.casd.local/oauth_callback
# MINIO_IDENTITY_OPENID_SCOPES=openid, profile, email, roles
identity_openid enable= display_name= config_url= client_id= client_secret= claim_name=policy claim_userinfo= role_policy= claim_prefix= redirect_uri= redirect_uri_dynamic=off scopes= vendor= keycloak_realm= keycloak_admin_url=
```

To disable it if it was enabled:

```bash
mc admin config set s3 identity_openid claim_userinfo=off
mc admin service restart s3
```

## 7.8 Integrate minIO in onyxia 

Onyxia provide an integrated minio console which allows you to upload, download files. To make this console works, we need to set two **mappers** inside `onyxia's keycloak auth client`:
- Audience: for minio authentication
- Policy claim: for minio access control policy

 `onyxia-client`

 ### 7.8.1 Set up an audience

To create an **audience** :
1. click on the `onyxia auth client`, in our case the name is `onyxia-client`. On the right panel, click on `Mappers` (on top). Then click on `create`, it will popup a form which you need to fill.
2. Name: `audience-minio`;   Mapper Type: `Audience`; Included Client Audience: `minio`
3. `Add to ID Token` need to be `Enabled`     
4. Click on `save`.

> Note if you named your minio auth client other than `minio`, you should change the `Included Client Audience` value accordingly.

Below figure is an example

![kc-onyxia-audience-minio.PNG](../images/kc-onyxia-audience-minio.PNG)

### 7.8.2 Set up policy claim

To create a **hardcoded claim** 
1. click on the `onyxia auth client`, in our case the name is `onyxia-client`. On the right panel, click on `Mappers` (on top). Then click on `create`, it will popup a form which you need to fill.
2. Name: `policy`;   Mapper Type: `Hardcoded claim`; Token Claim Name: `policy`; Claim value: `stsonly`
3. `Add to ID Token` need to be `Enabled`     
4. Click on `save`. 

Below figure is an exampl

![kc-onyxia-policy-claim.PNG](../images/kc-onyxia-policy-claim.PNG)

- You probably want to **extend token's duration** as the `5 minutes` default value is not enough for users to use the token inside their services. This can be done either `realm wide` (realm settings => tokens => access_token_lifespan) or `per client` (settings => advanced settings).
- If you intend to use **groups** or want to work around this bug : https://github.com/InseeFrLab/onyxia-web/issues/263, you may want to add a `groups` client scope with a `Group membership` mapper.

### 7.8.3 Link minio to Onyxia

To link minio server with Onyxia minio consol, we need to modify the Onyxia's UI configuration. The most important thing is to set `MINIO_URL: https://minio.casd.local`.

The complete configuration file `minio.yaml` can be found [here](../resources/onyxia/minio.yaml) 

To apply the new configuration, you need to run

```bash
helm upgrade onyxia inseefrlab/onyxia -f minio.yaml
```

## References

- [MinIO Operator repository Helm charts folder, for both operator and tenant](https://github.com/minio/operator/tree/master/helm)
- [MinIO Tenant Helm chart's README.md](https://github.com/minio/operator/blob/master/helm/tenant/README.md)
- [MinIO Tenant Helm chart default values file](https://github.com/minio/operator/blob/master/helm/tenant/values.yaml)
- [Install mimio on debian](https://www.digitalocean.com/community/tutorials/how-to-set-up-minio-object-storage-server-in-standalone-mode-on-ubuntu-20-04)

